{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nationwide_AAnalytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP0QHtQkR8JpTthgdLOQeN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunasil98/Nationwide_AAnalytics./blob/main/Nationwide_AAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BjP1XHsFWE",
        "outputId": "8e7146a5-e8c6-4ba1-e7bd-537bfe92f649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ILL098FirGT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D,Conv2D, MaxPooling1D, BatchNormalization\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, classification_report\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from keras.layers.core import Dense, Activation  \n",
        "from keras.layers.recurrent import LSTM\n",
        "import tensorflow.keras.utils as conv_utils\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnK2gTZri-u2",
        "outputId": "2aceee1e-e631-4b47-a011-3d6c80e04dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv('/content/drive/MyDrive/Nationwide_AAnalytics/TRAIN_SET_2021.csv')\n",
        "df_2 = pd.read_csv('/content/drive/MyDrive/Nationwide_AAnalytics/TEST_SET_2021.csv')"
      ],
      "metadata": {
        "id": "IPVCdTx1jBuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb0eZ9GJj9St",
        "outputId": "cdea7711-7703-4eea-d305-970087e98ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RESTAURANT_SERIAL_NUMBER            15673\n",
              "RESTAURANT_PERMIT_NUMBER             8654\n",
              "RESTAURANT_NAME                      8317\n",
              "RESTAURANT_LOCATION                  4963\n",
              "RESTAURANT_CATEGORY                    31\n",
              "ADDRESS                              4784\n",
              "CITY                                   27\n",
              "STATE                                  13\n",
              "ZIP                                  2483\n",
              "CURRENT_DEMERITS                       54\n",
              "CURRENT_GRADE                          16\n",
              "EMPLOYEE_COUNT                         53\n",
              "MEDIAN_EMPLOYEE_AGE                 15293\n",
              "MEDIAN_EMPLOYEE_TENURE              15376\n",
              "INSPECTION_TIME                     14271\n",
              "INSPECTION_TYPE                         5\n",
              "INSPECTION_DEMERITS                    64\n",
              "VIOLATIONS_RAW                      11397\n",
              "RECORD_UPDATED                       4941\n",
              "LAT_LONG_RAW                         4718\n",
              "FIRST_VIOLATION                        68\n",
              "SECOND_VIOLATION                       73\n",
              "THIRD_VIOLATION                        80\n",
              "FIRST_VIOLATION_TYPE                   11\n",
              "SECOND_VIOLATION_TYPE                   6\n",
              "THIRD_VIOLATION_TYPE                    4\n",
              "NUMBER_OF_VIOLATIONS                   27\n",
              "NEXT_INSPECTION_GRADE_C_OR_BELOW        8\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1['CURRENT_GRADE'].value_counts()\n",
        "# Next step will give value for A =3;B =2; C = 1; and make average of value for each zip code\n",
        "#Make the other non count because I could not figure out what mean X, O,N, and I believe the rest is only spelling mistake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RixdoSC98ZGd",
        "outputId": "22bb9236-7733-456e-9f78-4b7091a7c7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A             14915\n",
              "B               215\n",
              "C               104\n",
              "X                75\n",
              "O                32\n",
              "N                13\n",
              "7                 2\n",
              "K                 1\n",
              "U                 1\n",
              "NASA              1\n",
              "I                 1\n",
              ".\\<><1@#&|        1\n",
              "A+                1\n",
              "VPN               1\n",
              "UPN               1\n",
              "EIEIO             1\n",
              "Name: CURRENT_GRADE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1[['ZIP_CODE', 'ZC']] = df_1['ZIP'].str.split('-', 1, expand=True)\n",
        "print(df_1[['ZIP','ZIP_CODE','ZC']].head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_792KA_Bu3L",
        "outputId": "75b529be-79bd-4f34-a9b2-7630c52842de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ZIP ZIP_CODE    ZC\n",
            "0   89169-2617    89169  2617\n",
            "1   89108-4588    89108  4588\n",
            "2   89130-3505    89130  3505\n",
            "3   89101-1517    89101  1517\n",
            "4   89169-6574    89169  6574\n",
            "5   89103-5420    89103  5420\n",
            "6   89147-8396    89147  8396\n",
            "7   89119-2318    89119  2318\n",
            "8        89005    89005  None\n",
            "9   89109-4345    89109  4345\n",
            "10       89101    89101  None\n",
            "11  89121-5074    89121  5074\n",
            "12  89109-4574    89109  4574\n",
            "13  89183-4013    89183  4013\n",
            "14  89121-7315    89121  7315\n",
            "15       89103    89103  None\n",
            "16  89109-4333    89109  4333\n",
            "17  89015-7367    89015  7367\n",
            "18  89119-6309    89119  6309\n",
            "19       89130    89130  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame()\n",
        "a['ZIP_CODE'] = df_1['ZIP_CODE']\n",
        "a['Grade'] = df_1['CURRENT_GRADE']\n",
        "a = a.drop(a[a['Grade'] == 'X' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'O' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'N' ].index)\n",
        "a = a.drop(a[a['Grade'] == '7' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'VPN' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'UPN' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'U' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'NASA' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'K' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'I' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'EIEIO' ].index)\n",
        "a = a.drop(a[a['Grade'] == 'A+' ].index)\n",
        "a = a.drop(a[a['Grade'] == '.\\<><1@#&|' ].index)\n",
        "a = a.drop(a[a['ZIP_CODE'] == '9.87898E+15'].index)"
      ],
      "metadata": {
        "id": "PcBZy-cbCddb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a['Grade'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t_WXLc8KHC5",
        "outputId": "fcab320d-7c17-46e6-cefb-8661263cfb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A    14914\n",
              "B      215\n",
              "C      104\n",
              "Name: Grade, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a['Points']= a['Grade'].apply(lambda x :3 if x == 'A' else 2 if x == \"B\" else 1 )\n",
        "a[a['Grade'] == 'A']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q-Jd-IWiC00n",
        "outputId": "c34d1015-bfc0-4f4e-9fa0-0f0cc2311918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e4a905d-dba1-4cc7-9f0d-cc71f28258e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ZIP_CODE</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89169</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>89108</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>89130</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89101</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89169</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15668</th>\n",
              "      <td>89114</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15669</th>\n",
              "      <td>89030</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15670</th>\n",
              "      <td>89109</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15671</th>\n",
              "      <td>89005</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15672</th>\n",
              "      <td>89029</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14914 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e4a905d-dba1-4cc7-9f0d-cc71f28258e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e4a905d-dba1-4cc7-9f0d-cc71f28258e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e4a905d-dba1-4cc7-9f0d-cc71f28258e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ZIP_CODE Grade  Points\n",
              "0        89169     A       3\n",
              "1        89108     A       3\n",
              "2        89130     A       3\n",
              "3        89101     A       3\n",
              "4        89169     A       3\n",
              "...        ...   ...     ...\n",
              "15668    89114     A       3\n",
              "15669    89030     A       3\n",
              "15670    89109     A       3\n",
              "15671    89005     A       3\n",
              "15672    89029     A       3\n",
              "\n",
              "[14914 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.groupby(a['ZIP_CODE']).mean()\n",
        "a = a.sort_values(by='Points', ascending=True)\n",
        "a= a.iloc[:5]\n",
        "x = a.index\n",
        "y = a['Points']"
      ],
      "metadata": {
        "id": "4dl2LkFFDBII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "ymCY53DLnrrw",
        "outputId": "d514376d-6bb0-4483-9a25-ec857a8a8a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = pd. DataFrame()\n",
        "b['FIRST_VIOLATION'] = df_1['FIRST_VIOLATION']\n",
        "b['Points'] = 1\n",
        "b = b.drop(b[b['FIRST_VIOLATION'] == 8675309.0].index)\n",
        "b = b.groupby(b['FIRST_VIOLATION']).sum()\n",
        "b = b.sort_values(by='Points', ascending=False)\n",
        "b_plot = b.iloc[0:5]\n",
        "y_b = b_plot[\"Points\"]\n",
        "x_b = b_plot.index"
      ],
      "metadata": {
        "id": "DqN-cfp_yQKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = pd. DataFrame()\n",
        "c['SECOND_VIOLATION'] = df_1['SECOND_VIOLATION']\n",
        "c['Points'] = 1\n",
        "c = c.groupby(c['SECOND_VIOLATION']).sum()\n",
        "c = c.sort_values(by='Points', ascending=False)\n",
        "c_plot = c.iloc[0:5]\n",
        "y_c = c_plot[\"Points\"]\n",
        "x_c = c_plot.index"
      ],
      "metadata": {
        "id": "foUrf4sw80Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd. DataFrame()\n",
        "d['THIRD_VIOLATION'] = df_1['THIRD_VIOLATION']\n",
        "d['Points'] = 1\n",
        "d = d.groupby(d['THIRD_VIOLATION']).sum()\n",
        "d = d.sort_values(by='Points', ascending=False)\n",
        "d_plot = d.iloc[0:5]\n",
        "#d_plot = d_plot.sort_values(by=d_plot.index, ascending=False)\n",
        "y_d = d_plot[\"Points\"]\n",
        "x_d = d_plot.index.sort_values()"
      ],
      "metadata": {
        "id": "u7Tnk8Nx80ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = pd.DataFrame({\n",
        "    'First': df_1['FIRST_VIOLATION'],\n",
        "    'Second': df_1['SECOND_VIOLATION'],\n",
        "    'Third': df_1['THIRD_VIOLATION']})\n",
        "total = total.stack().reset_index()\n",
        "total = total.drop(columns=['level_0', 'level_1'])\n",
        "total['Points'] = 1\n",
        "total = total.groupby(total[0]).sum()\n",
        "total = total.sort_values(by='Points', ascending=False)\n",
        "\n",
        "other = total.iloc[10:]\n",
        "T = other.sum()\n",
        "total.loc['Other'] = T\n",
        "\n",
        "total = total.sort_values(by='Points', ascending=False)\n",
        "total_plot = total.iloc[0:10]\n",
        "x_t = total_plot[\"Points\"].sort_values()\n",
        "y_t = total_plot.index\n"
      ],
      "metadata": {
        "id": "gAc4Leyn13Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2,2,1)\n",
        "plt.bar(x_b,y_b, tick_label = x_b, width  = 1.5)\n",
        "plt.title('First_Violation')\n",
        "plt.xlabel('Law N#')\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(x_c,y_c, facecolors=\"red\")\n",
        "plt.title('Second_Violation')\n",
        "plt.xlabel('Law N#')\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(x_d,y_d,label= x_d)\n",
        "plt.grid(True)\n",
        "#plt.bar(x_d,y_d,tick_label = x_d, width  = 1.5 )\n",
        "plt.xlabel('Law N#')\n",
        "plt.title('Third_Violation')\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.pie(x_t,labels  = y_t)\n",
        "#plt.bar(x_t,y_t,tick_label = x_d, width  = 0.75)\n",
        "plt.title('All',fontsize = 18)\n",
        "plt.xlabel('Law N#')\n",
        "\n",
        "\n",
        "plt.subplots_adjust(right = 2.5,top = 2, hspace = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "oy4iPT-UWudU",
        "outputId": "6a9df9e6-df8c-46cc-f38e-37a90a85a58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating the model**"
      ],
      "metadata": {
        "id": "nBUuPXME0V-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv('/content/drive/MyDrive/Nationwide_AAnalytics/TRAIN_SET_2021.csv')\n",
        "df_2 = pd.read_csv('/content/drive/MyDrive/Nationwide_AAnalytics/TEST_SET_2021.csv')\n"
      ],
      "metadata": {
        "id": "Tsx92qWb05HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD8WG-AshxJZ",
        "outputId": "f8db2da1-2aca-44d3-b825-fb83524c0bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15673 entries, 0 to 15672\n",
            "Data columns (total 28 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   RESTAURANT_SERIAL_NUMBER          15673 non-null  object \n",
            " 1   RESTAURANT_PERMIT_NUMBER          15673 non-null  object \n",
            " 2   RESTAURANT_NAME                   15608 non-null  object \n",
            " 3   RESTAURANT_LOCATION               15473 non-null  object \n",
            " 4   RESTAURANT_CATEGORY               15543 non-null  object \n",
            " 5   ADDRESS                           15603 non-null  object \n",
            " 6   CITY                              15437 non-null  object \n",
            " 7   STATE                             15464 non-null  object \n",
            " 8   ZIP                               15614 non-null  object \n",
            " 9   CURRENT_DEMERITS                  15457 non-null  float64\n",
            " 10  CURRENT_GRADE                     15365 non-null  object \n",
            " 11  EMPLOYEE_COUNT                    15580 non-null  float64\n",
            " 12  MEDIAN_EMPLOYEE_AGE               15639 non-null  float64\n",
            " 13  MEDIAN_EMPLOYEE_TENURE            15376 non-null  float64\n",
            " 14  INSPECTION_TIME                   15490 non-null  object \n",
            " 15  INSPECTION_TYPE                   15452 non-null  object \n",
            " 16  INSPECTION_DEMERITS               15419 non-null  object \n",
            " 17  VIOLATIONS_RAW                    15508 non-null  object \n",
            " 18  RECORD_UPDATED                    15554 non-null  object \n",
            " 19  LAT_LONG_RAW                      15658 non-null  object \n",
            " 20  FIRST_VIOLATION                   15461 non-null  float64\n",
            " 21  SECOND_VIOLATION                  15588 non-null  float64\n",
            " 22  THIRD_VIOLATION                   15612 non-null  float64\n",
            " 23  FIRST_VIOLATION_TYPE              15527 non-null  object \n",
            " 24  SECOND_VIOLATION_TYPE             15406 non-null  object \n",
            " 25  THIRD_VIOLATION_TYPE              15500 non-null  object \n",
            " 26  NUMBER_OF_VIOLATIONS              15504 non-null  object \n",
            " 27  NEXT_INSPECTION_GRADE_C_OR_BELOW  15633 non-null  object \n",
            "dtypes: float64(7), object(21)\n",
            "memory usage: 3.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.corr(method ='kendall')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "U0rZ2FpNhKfu",
        "outputId": "d271f45e-739b-4a18-8aef-d63b3834db3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94fdda0d-51ce-4ced-a6f7-670d880ca02c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CURRENT_DEMERITS</th>\n",
              "      <th>EMPLOYEE_COUNT</th>\n",
              "      <th>MEDIAN_EMPLOYEE_AGE</th>\n",
              "      <th>MEDIAN_EMPLOYEE_TENURE</th>\n",
              "      <th>FIRST_VIOLATION</th>\n",
              "      <th>SECOND_VIOLATION</th>\n",
              "      <th>THIRD_VIOLATION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CURRENT_DEMERITS</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011425</td>\n",
              "      <td>0.006118</td>\n",
              "      <td>-0.005776</td>\n",
              "      <td>-0.013863</td>\n",
              "      <td>-0.028295</td>\n",
              "      <td>-0.036217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMPLOYEE_COUNT</th>\n",
              "      <td>0.011425</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000863</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.000209</td>\n",
              "      <td>-0.004777</td>\n",
              "      <td>-0.002778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEDIAN_EMPLOYEE_AGE</th>\n",
              "      <td>0.006118</td>\n",
              "      <td>0.000863</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>0.004703</td>\n",
              "      <td>0.006280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEDIAN_EMPLOYEE_TENURE</th>\n",
              "      <td>-0.005776</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009831</td>\n",
              "      <td>0.005533</td>\n",
              "      <td>0.008546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIRST_VIOLATION</th>\n",
              "      <td>-0.013863</td>\n",
              "      <td>-0.000209</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>0.009831</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.762723</td>\n",
              "      <td>0.692009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SECOND_VIOLATION</th>\n",
              "      <td>-0.028295</td>\n",
              "      <td>-0.004777</td>\n",
              "      <td>0.004703</td>\n",
              "      <td>0.005533</td>\n",
              "      <td>0.762723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.824638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THIRD_VIOLATION</th>\n",
              "      <td>-0.036217</td>\n",
              "      <td>-0.002778</td>\n",
              "      <td>0.006280</td>\n",
              "      <td>0.008546</td>\n",
              "      <td>0.692009</td>\n",
              "      <td>0.824638</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94fdda0d-51ce-4ced-a6f7-670d880ca02c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94fdda0d-51ce-4ced-a6f7-670d880ca02c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94fdda0d-51ce-4ced-a6f7-670d880ca02c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        CURRENT_DEMERITS  ...  THIRD_VIOLATION\n",
              "CURRENT_DEMERITS                1.000000  ...        -0.036217\n",
              "EMPLOYEE_COUNT                  0.011425  ...        -0.002778\n",
              "MEDIAN_EMPLOYEE_AGE             0.006118  ...         0.006280\n",
              "MEDIAN_EMPLOYEE_TENURE         -0.005776  ...         0.008546\n",
              "FIRST_VIOLATION                -0.013863  ...         0.692009\n",
              "SECOND_VIOLATION               -0.028295  ...         0.824638\n",
              "THIRD_VIOLATION                -0.036217  ...         1.000000\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'].value_counts().plot.pie(autopct = '%.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NtKpCowNaOb9",
        "outputId": "e1099200-b90b-4e02-8fb3-1ec88fa4bd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24709ee290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Give Value for column INSPECTION_TYPE\n",
        "df_1 = df_1.drop(df_1[df_1['INSPECTION_TYPE'] == '9/20/2011 14:25' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['INSPECTION_TYPE'] == 'This Value Intentionally Left Blank' ].index)\n",
        "print(df_1['INSPECTION_TYPE'].value_counts())\n",
        "df_1['INSPECTION_TYPE']= df_1['INSPECTION_TYPE'].apply(lambda x :3 if x == 'Routine Inspection' else 2 if x == \"Re-inspection\" else 1 if x == \"Routine Non-Inspection\" else np.nan )\n",
        "print(df_1['INSPECTION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbRufuqCq147",
        "outputId": "c620e24c-1305-4bda-8190-7062c02256e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Routine Inspection        14581\n",
            "Re-inspection               867\n",
            "Routine Non-Inspection        2\n",
            "Name: INSPECTION_TYPE, dtype: int64\n",
            "3.0    14581\n",
            "2.0      867\n",
            "1.0        2\n",
            "Name: INSPECTION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Give Value for column FIRST_VIOLATION_TYPE\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Major-ish' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'To Infinity and Beyond' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Bullwinkle' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Extra Crispy' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Radical' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Not Sure' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['FIRST_VIOLATION_TYPE'] == 'Excellent' ].index)\n",
        "print(df_1['FIRST_VIOLATION_TYPE'].value_counts())\n",
        "df_1['FIRST_VIOLATION_TYPE']= df_1['FIRST_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\" else np.nan )\n",
        "print(df_1['FIRST_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpvp7h-DumIv",
        "outputId": "da43dc36-adb2-488a-883a-81e643d4082e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critical                  7192\n",
            "Major                     6735\n",
            "Non-Major                 1588\n",
            "Imminent Health Hazard       3\n",
            "Name: FIRST_VIOLATION_TYPE, dtype: int64\n",
            "4.0    7192\n",
            "3.0    6735\n",
            "2.0    1588\n",
            "5.0       3\n",
            "Name: FIRST_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Give Value for column SECOND_VIOLATION_TYPE\n",
        "df_1 = df_1.drop(df_1[df_1['SECOND_VIOLATION_TYPE'] == 'Kitchen Nightmares' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['SECOND_VIOLATION_TYPE'] == 'Supercritical' ].index)\n",
        "print(df_1['SECOND_VIOLATION_TYPE'].value_counts())\n",
        "df_1['SECOND_VIOLATION_TYPE']= df_1['SECOND_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\"  else np.nan )\n",
        "print(df_1['SECOND_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqerOZrtvw9C",
        "outputId": "26b99f80-1575-41f3-9034-6bb5a6c21811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major                     7902\n",
            "Non-Major                 4504\n",
            "Critical                  2984\n",
            "Imminent Health Hazard       5\n",
            "Name: SECOND_VIOLATION_TYPE, dtype: int64\n",
            "3.0    7902\n",
            "2.0    4504\n",
            "4.0    2984\n",
            "5.0       5\n",
            "Name: SECOND_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Give Value for column THIRD_VIOLATION_TYPE\n",
        "print(df_1['THIRD_VIOLATION_TYPE'].value_counts())\n",
        "df_1['THIRD_VIOLATION_TYPE']= df_1['THIRD_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\"  else np.nan )\n",
        "print(df_1['THIRD_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSwOCQg_wUsj",
        "outputId": "893e0a9a-ca65-49e5-d0bc-c79ba5d21b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major                     7308\n",
            "Non-Major                 7277\n",
            "Critical                   867\n",
            "Imminent Health Hazard      37\n",
            "Name: THIRD_VIOLATION_TYPE, dtype: int64\n",
            "3.0    7308\n",
            "2.0    7277\n",
            "4.0     867\n",
            "5.0      37\n",
            "Name: THIRD_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### Give Value for column CURRENT_GRADE\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == '7' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'I' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'UPN' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'K' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'NASA' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'EIEIO' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'U' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'A+' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['CURRENT_GRADE'] == 'VPN' ].index)\n",
        "print(df_1['CURRENT_GRADE'].value_counts())\n",
        "df_1['CURRENT_GRADE']= df_1['CURRENT_GRADE'].apply(lambda x :5 if x == \"A\" else 4 if x == 'B' else 3 if x == \"C\" else 2 if x == \"X\" else 1 if x == \"O\" else 0 if x == \"N\" else np.nan )\n",
        "print(df_1['CURRENT_GRADE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hepB5IidxD17",
        "outputId": "8c8ca997-07e2-4c69-8c50-ec93975f4ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    14909\n",
            "B      215\n",
            "C      104\n",
            "X       75\n",
            "O       32\n",
            "N       13\n",
            "Name: CURRENT_GRADE, dtype: int64\n",
            "5.0    14909\n",
            "4.0      215\n",
            "3.0      104\n",
            "2.0       75\n",
            "1.0       32\n",
            "0.0       13\n",
            "Name: CURRENT_GRADE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1[['ZIP_CODE', 'ZC']] = df_1['ZIP'].str.split('-', 1, expand=True)\n",
        "df_1 = df_1.drop(df_1[df_1['INSPECTION_DEMERITS'] == 'Routine Inspection' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NUMBER_OF_VIOLATIONS'] == 'Nevada' ].index)"
      ],
      "metadata": {
        "id": "u6MP6WEkLBOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'].value_counts())\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == '3' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == '-3' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == 'Goat' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == '7' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == '9' ].index)\n",
        "df_1 = df_1.drop(df_1[df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'] == '4' ].index)\n",
        "print(df_1['NEXT_INSPECTION_GRADE_C_OR_BELOW'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grD7m8JL2f75",
        "outputId": "f0dfe584-5c1a-4f87-8f18-db28425d55f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     13135\n",
            "1      2479\n",
            "-3        1\n",
            "7         1\n",
            "Name: NEXT_INSPECTION_GRADE_C_OR_BELOW, dtype: int64\n",
            "0    13135\n",
            "1     2479\n",
            "Name: NEXT_INSPECTION_GRADE_C_OR_BELOW, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the NuN values\n",
        "Delete = df_1.loc[:,['CURRENT_DEMERITS','EMPLOYEE_COUNT','MEDIAN_EMPLOYEE_AGE',\t'MEDIAN_EMPLOYEE_TENURE','NUMBER_OF_VIOLATIONS','CURRENT_GRADE','INSPECTION_DEMERITS','FIRST_VIOLATION',\t'SECOND_VIOLATION',\t'THIRD_VIOLATION','INSPECTION_TYPE', 'THIRD_VIOLATION_TYPE','SECOND_VIOLATION_TYPE','FIRST_VIOLATION_TYPE','ZIP_CODE','NEXT_INSPECTION_GRADE_C_OR_BELOW']]\n",
        "print(Delete.isnull().sum())\n",
        "Delete = Delete.dropna()\n",
        "print(Delete.isnull().sum())\n",
        "Delete = Delete.apply(pd.to_numeric) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpFtf04v0a-a",
        "outputId": "6f46ef61-ef97-4049-f79c-6bac6ddd55be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CURRENT_DEMERITS                    215\n",
            "EMPLOYEE_COUNT                       93\n",
            "MEDIAN_EMPLOYEE_AGE                  34\n",
            "MEDIAN_EMPLOYEE_TENURE              297\n",
            "NUMBER_OF_VIOLATIONS                169\n",
            "CURRENT_GRADE                       308\n",
            "INSPECTION_DEMERITS                 253\n",
            "FIRST_VIOLATION                     212\n",
            "SECOND_VIOLATION                     84\n",
            "THIRD_VIOLATION                      61\n",
            "INSPECTION_TYPE                     220\n",
            "THIRD_VIOLATION_TYPE                173\n",
            "SECOND_VIOLATION_TYPE               267\n",
            "FIRST_VIOLATION_TYPE                146\n",
            "ZIP_CODE                             59\n",
            "NEXT_INSPECTION_GRADE_C_OR_BELOW     40\n",
            "dtype: int64\n",
            "CURRENT_DEMERITS                    0\n",
            "EMPLOYEE_COUNT                      0\n",
            "MEDIAN_EMPLOYEE_AGE                 0\n",
            "MEDIAN_EMPLOYEE_TENURE              0\n",
            "NUMBER_OF_VIOLATIONS                0\n",
            "CURRENT_GRADE                       0\n",
            "INSPECTION_DEMERITS                 0\n",
            "FIRST_VIOLATION                     0\n",
            "SECOND_VIOLATION                    0\n",
            "THIRD_VIOLATION                     0\n",
            "INSPECTION_TYPE                     0\n",
            "THIRD_VIOLATION_TYPE                0\n",
            "SECOND_VIOLATION_TYPE               0\n",
            "FIRST_VIOLATION_TYPE                0\n",
            "ZIP_CODE                            0\n",
            "NEXT_INSPECTION_GRADE_C_OR_BELOW    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Delete['NEXT_INSPECTION_GRADE_C_OR_BELOW'].value_counts().plot.pie(autopct = '%.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HVp7gyU562SV",
        "outputId": "d0e8bfde-09b0-4569-e2cc-5d2cc98cef9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f246c46e5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Delete.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvnNwG1biGe1",
        "outputId": "c70a1803-e29f-4e89-b00f-955ec78d12fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13204 entries, 0 to 15672\n",
            "Data columns (total 16 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   CURRENT_DEMERITS                  13204 non-null  float64\n",
            " 1   EMPLOYEE_COUNT                    13204 non-null  float64\n",
            " 2   MEDIAN_EMPLOYEE_AGE               13204 non-null  float64\n",
            " 3   MEDIAN_EMPLOYEE_TENURE            13204 non-null  float64\n",
            " 4   NUMBER_OF_VIOLATIONS              13204 non-null  int64  \n",
            " 5   CURRENT_GRADE                     13204 non-null  float64\n",
            " 6   INSPECTION_DEMERITS               13204 non-null  int64  \n",
            " 7   FIRST_VIOLATION                   13204 non-null  float64\n",
            " 8   SECOND_VIOLATION                  13204 non-null  float64\n",
            " 9   THIRD_VIOLATION                   13204 non-null  float64\n",
            " 10  INSPECTION_TYPE                   13204 non-null  float64\n",
            " 11  THIRD_VIOLATION_TYPE              13204 non-null  float64\n",
            " 12  SECOND_VIOLATION_TYPE             13204 non-null  float64\n",
            " 13  FIRST_VIOLATION_TYPE              13204 non-null  float64\n",
            " 14  ZIP_CODE                          13204 non-null  float64\n",
            " 15  NEXT_INSPECTION_GRADE_C_OR_BELOW  13204 non-null  int64  \n",
            "dtypes: float64(13), int64(3)\n",
            "memory usage: 1.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Delete.corr(method ='kendall')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "-rn884yGh19t",
        "outputId": "9bbc9d7f-a723-4a5a-83cf-0f21fbc08401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f4d51a0-edce-4562-be86-93b2a9546b60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CURRENT_DEMERITS</th>\n",
              "      <th>EMPLOYEE_COUNT</th>\n",
              "      <th>MEDIAN_EMPLOYEE_AGE</th>\n",
              "      <th>MEDIAN_EMPLOYEE_TENURE</th>\n",
              "      <th>NUMBER_OF_VIOLATIONS</th>\n",
              "      <th>CURRENT_GRADE</th>\n",
              "      <th>INSPECTION_DEMERITS</th>\n",
              "      <th>FIRST_VIOLATION</th>\n",
              "      <th>SECOND_VIOLATION</th>\n",
              "      <th>THIRD_VIOLATION</th>\n",
              "      <th>INSPECTION_TYPE</th>\n",
              "      <th>THIRD_VIOLATION_TYPE</th>\n",
              "      <th>SECOND_VIOLATION_TYPE</th>\n",
              "      <th>FIRST_VIOLATION_TYPE</th>\n",
              "      <th>ZIP_CODE</th>\n",
              "      <th>NEXT_INSPECTION_GRADE_C_OR_BELOW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CURRENT_DEMERITS</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007229</td>\n",
              "      <td>0.005577</td>\n",
              "      <td>-0.004554</td>\n",
              "      <td>0.059995</td>\n",
              "      <td>-0.208133</td>\n",
              "      <td>0.049022</td>\n",
              "      <td>-0.014754</td>\n",
              "      <td>-0.030390</td>\n",
              "      <td>-0.037912</td>\n",
              "      <td>-0.045760</td>\n",
              "      <td>0.045503</td>\n",
              "      <td>0.034159</td>\n",
              "      <td>0.006981</td>\n",
              "      <td>-0.000192</td>\n",
              "      <td>0.011287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMPLOYEE_COUNT</th>\n",
              "      <td>0.007229</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>0.011326</td>\n",
              "      <td>-0.005503</td>\n",
              "      <td>0.011636</td>\n",
              "      <td>0.004827</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>0.010122</td>\n",
              "      <td>0.015499</td>\n",
              "      <td>0.009323</td>\n",
              "      <td>-0.004562</td>\n",
              "      <td>-0.001425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEDIAN_EMPLOYEE_AGE</th>\n",
              "      <td>0.005577</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006824</td>\n",
              "      <td>0.004958</td>\n",
              "      <td>-0.011016</td>\n",
              "      <td>-0.000817</td>\n",
              "      <td>0.005753</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>0.008703</td>\n",
              "      <td>-0.001277</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>0.002391</td>\n",
              "      <td>0.001720</td>\n",
              "      <td>-0.010445</td>\n",
              "      <td>-0.009291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEDIAN_EMPLOYEE_TENURE</th>\n",
              "      <td>-0.004554</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>0.006824</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005353</td>\n",
              "      <td>-0.003395</td>\n",
              "      <td>-0.003017</td>\n",
              "      <td>0.008627</td>\n",
              "      <td>0.004715</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>-0.005204</td>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>-0.006270</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>-0.001835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUMBER_OF_VIOLATIONS</th>\n",
              "      <td>0.059995</td>\n",
              "      <td>0.011326</td>\n",
              "      <td>0.004958</td>\n",
              "      <td>-0.005353</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.074672</td>\n",
              "      <td>0.709866</td>\n",
              "      <td>-0.140653</td>\n",
              "      <td>-0.217759</td>\n",
              "      <td>-0.284156</td>\n",
              "      <td>0.070213</td>\n",
              "      <td>0.515829</td>\n",
              "      <td>0.476050</td>\n",
              "      <td>0.427141</td>\n",
              "      <td>0.012478</td>\n",
              "      <td>0.052998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CURRENT_GRADE</th>\n",
              "      <td>-0.208133</td>\n",
              "      <td>-0.005503</td>\n",
              "      <td>-0.011016</td>\n",
              "      <td>-0.003395</td>\n",
              "      <td>-0.074672</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.073056</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>0.023001</td>\n",
              "      <td>0.026646</td>\n",
              "      <td>0.038447</td>\n",
              "      <td>-0.071202</td>\n",
              "      <td>-0.060088</td>\n",
              "      <td>-0.052181</td>\n",
              "      <td>-0.003118</td>\n",
              "      <td>-0.041495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INSPECTION_DEMERITS</th>\n",
              "      <td>0.049022</td>\n",
              "      <td>0.011636</td>\n",
              "      <td>-0.000817</td>\n",
              "      <td>-0.003017</td>\n",
              "      <td>0.709866</td>\n",
              "      <td>-0.073056</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.231191</td>\n",
              "      <td>-0.304763</td>\n",
              "      <td>-0.322293</td>\n",
              "      <td>0.089294</td>\n",
              "      <td>0.627397</td>\n",
              "      <td>0.651267</td>\n",
              "      <td>0.603219</td>\n",
              "      <td>0.005182</td>\n",
              "      <td>0.046952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIRST_VIOLATION</th>\n",
              "      <td>-0.014754</td>\n",
              "      <td>0.004827</td>\n",
              "      <td>0.005753</td>\n",
              "      <td>0.008627</td>\n",
              "      <td>-0.140653</td>\n",
              "      <td>0.016014</td>\n",
              "      <td>-0.231191</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.762189</td>\n",
              "      <td>0.692614</td>\n",
              "      <td>-0.147195</td>\n",
              "      <td>-0.103653</td>\n",
              "      <td>-0.070106</td>\n",
              "      <td>-0.182741</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>-0.015298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SECOND_VIOLATION</th>\n",
              "      <td>-0.030390</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>0.004715</td>\n",
              "      <td>-0.217759</td>\n",
              "      <td>0.023001</td>\n",
              "      <td>-0.304763</td>\n",
              "      <td>0.762189</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.824993</td>\n",
              "      <td>-0.169034</td>\n",
              "      <td>-0.205541</td>\n",
              "      <td>-0.190454</td>\n",
              "      <td>-0.081473</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>-0.020109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THIRD_VIOLATION</th>\n",
              "      <td>-0.037912</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.008703</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>-0.284156</td>\n",
              "      <td>0.026646</td>\n",
              "      <td>-0.322293</td>\n",
              "      <td>0.692614</td>\n",
              "      <td>0.824993</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.166846</td>\n",
              "      <td>-0.250366</td>\n",
              "      <td>-0.117857</td>\n",
              "      <td>-0.029942</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>-0.016775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INSPECTION_TYPE</th>\n",
              "      <td>-0.045760</td>\n",
              "      <td>-0.001469</td>\n",
              "      <td>-0.001277</td>\n",
              "      <td>-0.005204</td>\n",
              "      <td>0.070213</td>\n",
              "      <td>0.038447</td>\n",
              "      <td>0.089294</td>\n",
              "      <td>-0.147195</td>\n",
              "      <td>-0.169034</td>\n",
              "      <td>-0.166846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.088553</td>\n",
              "      <td>0.052593</td>\n",
              "      <td>0.038039</td>\n",
              "      <td>0.010387</td>\n",
              "      <td>-0.006751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>THIRD_VIOLATION_TYPE</th>\n",
              "      <td>0.045503</td>\n",
              "      <td>0.010122</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.515829</td>\n",
              "      <td>-0.071202</td>\n",
              "      <td>0.627397</td>\n",
              "      <td>-0.103653</td>\n",
              "      <td>-0.205541</td>\n",
              "      <td>-0.250366</td>\n",
              "      <td>0.088553</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.604865</td>\n",
              "      <td>0.475557</td>\n",
              "      <td>0.007530</td>\n",
              "      <td>0.039841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SECOND_VIOLATION_TYPE</th>\n",
              "      <td>0.034159</td>\n",
              "      <td>0.015499</td>\n",
              "      <td>0.002391</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>0.476050</td>\n",
              "      <td>-0.060088</td>\n",
              "      <td>0.651267</td>\n",
              "      <td>-0.070106</td>\n",
              "      <td>-0.190454</td>\n",
              "      <td>-0.117857</td>\n",
              "      <td>0.052593</td>\n",
              "      <td>0.604865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.604024</td>\n",
              "      <td>0.002777</td>\n",
              "      <td>0.041042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIRST_VIOLATION_TYPE</th>\n",
              "      <td>0.006981</td>\n",
              "      <td>0.009323</td>\n",
              "      <td>0.001720</td>\n",
              "      <td>-0.006270</td>\n",
              "      <td>0.427141</td>\n",
              "      <td>-0.052181</td>\n",
              "      <td>0.603219</td>\n",
              "      <td>-0.182741</td>\n",
              "      <td>-0.081473</td>\n",
              "      <td>-0.029942</td>\n",
              "      <td>0.038039</td>\n",
              "      <td>0.475557</td>\n",
              "      <td>0.604024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005550</td>\n",
              "      <td>0.032687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZIP_CODE</th>\n",
              "      <td>-0.000192</td>\n",
              "      <td>-0.004562</td>\n",
              "      <td>-0.010445</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.012478</td>\n",
              "      <td>-0.003118</td>\n",
              "      <td>0.005182</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.010387</td>\n",
              "      <td>0.007530</td>\n",
              "      <td>0.002777</td>\n",
              "      <td>0.005550</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NEXT_INSPECTION_GRADE_C_OR_BELOW</th>\n",
              "      <td>0.011287</td>\n",
              "      <td>-0.001425</td>\n",
              "      <td>-0.009291</td>\n",
              "      <td>-0.001835</td>\n",
              "      <td>0.052998</td>\n",
              "      <td>-0.041495</td>\n",
              "      <td>0.046952</td>\n",
              "      <td>-0.015298</td>\n",
              "      <td>-0.020109</td>\n",
              "      <td>-0.016775</td>\n",
              "      <td>-0.006751</td>\n",
              "      <td>0.039841</td>\n",
              "      <td>0.041042</td>\n",
              "      <td>0.032687</td>\n",
              "      <td>0.001861</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f4d51a0-edce-4562-be86-93b2a9546b60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f4d51a0-edce-4562-be86-93b2a9546b60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f4d51a0-edce-4562-be86-93b2a9546b60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  CURRENT_DEMERITS  ...  NEXT_INSPECTION_GRADE_C_OR_BELOW\n",
              "CURRENT_DEMERITS                          1.000000  ...                          0.011287\n",
              "EMPLOYEE_COUNT                            0.007229  ...                         -0.001425\n",
              "MEDIAN_EMPLOYEE_AGE                       0.005577  ...                         -0.009291\n",
              "MEDIAN_EMPLOYEE_TENURE                   -0.004554  ...                         -0.001835\n",
              "NUMBER_OF_VIOLATIONS                      0.059995  ...                          0.052998\n",
              "CURRENT_GRADE                            -0.208133  ...                         -0.041495\n",
              "INSPECTION_DEMERITS                       0.049022  ...                          0.046952\n",
              "FIRST_VIOLATION                          -0.014754  ...                         -0.015298\n",
              "SECOND_VIOLATION                         -0.030390  ...                         -0.020109\n",
              "THIRD_VIOLATION                          -0.037912  ...                         -0.016775\n",
              "INSPECTION_TYPE                          -0.045760  ...                         -0.006751\n",
              "THIRD_VIOLATION_TYPE                      0.045503  ...                          0.039841\n",
              "SECOND_VIOLATION_TYPE                     0.034159  ...                          0.041042\n",
              "FIRST_VIOLATION_TYPE                      0.006981  ...                          0.032687\n",
              "ZIP_CODE                                 -0.000192  ...                          0.001861\n",
              "NEXT_INSPECTION_GRADE_C_OR_BELOW          0.011287  ...                          1.000000\n",
              "\n",
              "[16 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = Delete.loc[:,['NUMBER_OF_VIOLATIONS','CURRENT_GRADE',\t'INSPECTION_DEMERITS',\t'THIRD_VIOLATION_TYPE',\t'SECOND_VIOLATION_TYPE',\t'FIRST_VIOLATION_TYPE']]\n",
        "\n",
        "asw = Delete.loc[:,['NEXT_INSPECTION_GRADE_C_OR_BELOW']]"
      ],
      "metadata": {
        "id": "Lj2t6foV7ImD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = base.apply(pd.to_numeric) \n",
        "b_np = base.to_numpy()\n",
        "np.random.RandomState(seed=56).shuffle(b_np)\n",
        "\n",
        "asw = asw.apply(pd.to_numeric) \n",
        "asw_np = asw.to_numpy()\n",
        "np.random.RandomState(seed=56).shuffle(asw_np)\n",
        "asw.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF7N-titommv",
        "outputId": "5e78cac7-51d9-4e4f-c0f7-b1c31718d1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEXT_INSPECTION_GRADE_C_OR_BELOW    13204\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_ts, Y_tr, Y_ts = train_test_split(base, asw, test_size = 0.1)"
      ],
      "metadata": {
        "id": "yfc-SMasowFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(6,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#es_monitor = [EarlyStopping(patience=250, monitor='val_accuracy', verbose = 1, mode = 'min', restore_best_weights=True),\n",
        "#             ModelCheckpoint(mode = 'min', filepath='/content/drive/MyDrive/Nationwide_AAnalytics/Train_A', save_best_only=True) ] \n"
      ],
      "metadata": {
        "id": "1sL3TbL9HXVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **UNDER**"
      ],
      "metadata": {
        "id": "M1BB3StU9eSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the majority\n",
        "under = RandomUnderSampler(sampling_strategy = 1)\n",
        "x_un, y_un = under.fit_resample(base,asw)\n",
        "y_un.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2Evesz7Iou",
        "outputId": "ba1e0a26-9c55-457d-fe7b-20dc6f157c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEXT_INSPECTION_GRADE_C_OR_BELOW    4248\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_un.value_counts().plot.pie(autopct = '%.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "co8aYwi88yxw",
        "outputId": "776834db-ee32-484a-ab34-76a52da4ec0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f246c3f1c90>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_un, y_un, test_size = 0.1)\n"
      ],
      "metadata": {
        "id": "V5Ridqec0VR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,\n",
        "                    epochs=1000,\n",
        "                    validation_split = 0.1,\n",
        "                    #callbacks=[es_monitor]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6nwhrm80VMY",
        "outputId": "a5d46b54-2b8c-4ee4-f550-b23f1807050f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "108/108 [==============================] - 1s 3ms/step - loss: 2.0128 - accuracy: 0.4945 - val_loss: 0.8549 - val_accuracy: 0.4726\n",
            "Epoch 2/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.8093 - accuracy: 0.4863 - val_loss: 0.7588 - val_accuracy: 0.4935\n",
            "Epoch 3/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7628 - accuracy: 0.4951 - val_loss: 0.7211 - val_accuracy: 0.5039\n",
            "Epoch 4/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7409 - accuracy: 0.4855 - val_loss: 0.7080 - val_accuracy: 0.5117\n",
            "Epoch 5/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.4872 - val_loss: 0.7128 - val_accuracy: 0.4987\n",
            "Epoch 6/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.4948 - val_loss: 0.6990 - val_accuracy: 0.5091\n",
            "Epoch 7/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.4971 - val_loss: 0.6993 - val_accuracy: 0.5170\n",
            "Epoch 8/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7158 - accuracy: 0.4939 - val_loss: 0.7153 - val_accuracy: 0.5065\n",
            "Epoch 9/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.4922 - val_loss: 0.7055 - val_accuracy: 0.5039\n",
            "Epoch 10/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.4942 - val_loss: 0.7053 - val_accuracy: 0.5013\n",
            "Epoch 11/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.5023 - val_loss: 0.6921 - val_accuracy: 0.5065\n",
            "Epoch 12/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5006 - val_loss: 0.6992 - val_accuracy: 0.5117\n",
            "Epoch 13/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5006 - val_loss: 0.6919 - val_accuracy: 0.5013\n",
            "Epoch 14/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.4828 - val_loss: 0.7025 - val_accuracy: 0.4804\n",
            "Epoch 15/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.4910 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
            "Epoch 16/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.4895 - val_loss: 0.6969 - val_accuracy: 0.5144\n",
            "Epoch 17/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.4985 - val_loss: 0.6982 - val_accuracy: 0.5013\n",
            "Epoch 18/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.5047 - val_loss: 0.6961 - val_accuracy: 0.4987\n",
            "Epoch 19/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5035 - val_loss: 0.6887 - val_accuracy: 0.5013\n",
            "Epoch 20/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
            "Epoch 21/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.4881 - val_loss: 0.7097 - val_accuracy: 0.5013\n",
            "Epoch 22/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.4994 - val_loss: 0.6879 - val_accuracy: 0.4987\n",
            "Epoch 23/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.5148 - val_loss: 0.6900 - val_accuracy: 0.5065\n",
            "Epoch 24/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.4898 - val_loss: 0.6897 - val_accuracy: 0.5196\n",
            "Epoch 25/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.4988 - val_loss: 0.7176 - val_accuracy: 0.5039\n",
            "Epoch 26/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.4968 - val_loss: 0.7039 - val_accuracy: 0.5117\n",
            "Epoch 27/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5041 - val_loss: 0.6928 - val_accuracy: 0.5091\n",
            "Epoch 28/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.4887 - val_loss: 0.7266 - val_accuracy: 0.4883\n",
            "Epoch 29/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.4840 - val_loss: 0.6931 - val_accuracy: 0.4987\n",
            "Epoch 30/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.4878 - val_loss: 0.7098 - val_accuracy: 0.4961\n",
            "Epoch 31/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.4988 - val_loss: 0.6965 - val_accuracy: 0.4830\n",
            "Epoch 32/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4951 - val_loss: 0.7138 - val_accuracy: 0.5013\n",
            "Epoch 33/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5006 - val_loss: 0.6895 - val_accuracy: 0.5013\n",
            "Epoch 34/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4945 - val_loss: 0.6914 - val_accuracy: 0.5091\n",
            "Epoch 35/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.4881 - val_loss: 0.6919 - val_accuracy: 0.5039\n",
            "Epoch 36/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.4994 - val_loss: 0.7077 - val_accuracy: 0.4935\n",
            "Epoch 37/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5044 - val_loss: 0.6914 - val_accuracy: 0.5065\n",
            "Epoch 38/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.4959 - val_loss: 0.6963 - val_accuracy: 0.5117\n",
            "Epoch 39/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.5009 - val_loss: 0.7024 - val_accuracy: 0.4883\n",
            "Epoch 40/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.4855 - val_loss: 0.6883 - val_accuracy: 0.5117\n",
            "Epoch 41/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.4980 - val_loss: 0.6879 - val_accuracy: 0.5300\n",
            "Epoch 42/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.4892 - val_loss: 0.6953 - val_accuracy: 0.4726\n",
            "Epoch 43/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.4974 - val_loss: 0.7015 - val_accuracy: 0.4935\n",
            "Epoch 44/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4951 - val_loss: 0.7156 - val_accuracy: 0.4830\n",
            "Epoch 45/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5032 - val_loss: 0.6958 - val_accuracy: 0.5065\n",
            "Epoch 46/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.4878 - val_loss: 0.6878 - val_accuracy: 0.5326\n",
            "Epoch 47/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.4930 - val_loss: 0.7047 - val_accuracy: 0.4987\n",
            "Epoch 48/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.4994 - val_loss: 0.7033 - val_accuracy: 0.4961\n",
            "Epoch 49/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.4863 - val_loss: 0.7034 - val_accuracy: 0.4961\n",
            "Epoch 50/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.4840 - val_loss: 0.6957 - val_accuracy: 0.4935\n",
            "Epoch 51/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4924 - val_loss: 0.7218 - val_accuracy: 0.4778\n",
            "Epoch 52/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4994 - val_loss: 0.6872 - val_accuracy: 0.5222\n",
            "Epoch 53/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.4910 - val_loss: 0.7067 - val_accuracy: 0.4883\n",
            "Epoch 54/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.4977 - val_loss: 0.6943 - val_accuracy: 0.4935\n",
            "Epoch 55/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.4962 - val_loss: 0.7038 - val_accuracy: 0.4961\n",
            "Epoch 56/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.4849 - val_loss: 0.6867 - val_accuracy: 0.5274\n",
            "Epoch 57/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.4980 - val_loss: 0.6877 - val_accuracy: 0.5196\n",
            "Epoch 58/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.4994 - val_loss: 0.6910 - val_accuracy: 0.5274\n",
            "Epoch 59/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.5064 - val_loss: 0.6996 - val_accuracy: 0.4987\n",
            "Epoch 60/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.4936 - val_loss: 0.6915 - val_accuracy: 0.5274\n",
            "Epoch 61/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5038 - val_loss: 0.7150 - val_accuracy: 0.4856\n",
            "Epoch 62/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5041 - val_loss: 0.6912 - val_accuracy: 0.4987\n",
            "Epoch 63/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.4919 - val_loss: 0.7173 - val_accuracy: 0.4752\n",
            "Epoch 64/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5125 - val_loss: 0.7052 - val_accuracy: 0.4856\n",
            "Epoch 65/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5006 - val_loss: 0.6943 - val_accuracy: 0.4883\n",
            "Epoch 66/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.5170\n",
            "Epoch 67/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5131 - val_loss: 0.6962 - val_accuracy: 0.4961\n",
            "Epoch 68/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4962 - val_loss: 0.6884 - val_accuracy: 0.5117\n",
            "Epoch 69/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5015 - val_loss: 0.6879 - val_accuracy: 0.5274\n",
            "Epoch 70/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.4980 - val_loss: 0.7119 - val_accuracy: 0.4778\n",
            "Epoch 71/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5015 - val_loss: 0.6866 - val_accuracy: 0.5300\n",
            "Epoch 72/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4892 - val_loss: 0.6917 - val_accuracy: 0.4752\n",
            "Epoch 73/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4971 - val_loss: 0.6879 - val_accuracy: 0.5274\n",
            "Epoch 74/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5142 - val_loss: 0.6934 - val_accuracy: 0.4778\n",
            "Epoch 75/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4974 - val_loss: 0.6872 - val_accuracy: 0.5300\n",
            "Epoch 76/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5110 - val_loss: 0.7036 - val_accuracy: 0.4856\n",
            "Epoch 77/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5198 - val_loss: 0.6867 - val_accuracy: 0.5300\n",
            "Epoch 78/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5035 - val_loss: 0.6860 - val_accuracy: 0.5326\n",
            "Epoch 79/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.4965 - val_loss: 0.6988 - val_accuracy: 0.4830\n",
            "Epoch 80/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5099 - val_loss: 0.6883 - val_accuracy: 0.5326\n",
            "Epoch 81/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5073 - val_loss: 0.6945 - val_accuracy: 0.4752\n",
            "Epoch 82/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5009 - val_loss: 0.6897 - val_accuracy: 0.5170\n",
            "Epoch 83/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5125 - val_loss: 0.6959 - val_accuracy: 0.4935\n",
            "Epoch 84/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5017 - val_loss: 0.6896 - val_accuracy: 0.5222\n",
            "Epoch 85/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5038 - val_loss: 0.6918 - val_accuracy: 0.5013\n",
            "Epoch 86/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5192 - val_loss: 0.7212 - val_accuracy: 0.4752\n",
            "Epoch 87/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5128 - val_loss: 0.6910 - val_accuracy: 0.4856\n",
            "Epoch 88/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4936 - val_loss: 0.6881 - val_accuracy: 0.5274\n",
            "Epoch 89/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5038 - val_loss: 0.7117 - val_accuracy: 0.4804\n",
            "Epoch 90/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.4904 - val_loss: 0.6953 - val_accuracy: 0.4856\n",
            "Epoch 91/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.4968 - val_loss: 0.7029 - val_accuracy: 0.4856\n",
            "Epoch 92/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4994 - val_loss: 0.6904 - val_accuracy: 0.5039\n",
            "Epoch 93/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.4752\n",
            "Epoch 94/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5151 - val_loss: 0.6865 - val_accuracy: 0.5300\n",
            "Epoch 95/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5154 - val_loss: 0.6866 - val_accuracy: 0.5300\n",
            "Epoch 96/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.5070 - val_loss: 0.6906 - val_accuracy: 0.4909\n",
            "Epoch 97/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5038 - val_loss: 0.7163 - val_accuracy: 0.4804\n",
            "Epoch 98/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5047 - val_loss: 0.6959 - val_accuracy: 0.4830\n",
            "Epoch 99/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5067 - val_loss: 0.6886 - val_accuracy: 0.5274\n",
            "Epoch 100/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5160 - val_loss: 0.7005 - val_accuracy: 0.4830\n",
            "Epoch 101/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5102 - val_loss: 0.6873 - val_accuracy: 0.5300\n",
            "Epoch 102/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5113 - val_loss: 0.6876 - val_accuracy: 0.5300\n",
            "Epoch 103/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5110 - val_loss: 0.6868 - val_accuracy: 0.5300\n",
            "Epoch 104/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5145 - val_loss: 0.6864 - val_accuracy: 0.5300\n",
            "Epoch 105/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5203 - val_loss: 0.6869 - val_accuracy: 0.5326\n",
            "Epoch 106/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5035 - val_loss: 0.7035 - val_accuracy: 0.4856\n",
            "Epoch 107/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.4830\n",
            "Epoch 108/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4948 - val_loss: 0.6909 - val_accuracy: 0.4987\n",
            "Epoch 109/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5041 - val_loss: 0.6893 - val_accuracy: 0.5144\n",
            "Epoch 110/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5049 - val_loss: 0.6995 - val_accuracy: 0.4856\n",
            "Epoch 111/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5023 - val_loss: 0.7024 - val_accuracy: 0.4856\n",
            "Epoch 112/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5026 - val_loss: 0.6869 - val_accuracy: 0.5326\n",
            "Epoch 113/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5134 - val_loss: 0.6881 - val_accuracy: 0.5300\n",
            "Epoch 114/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5160 - val_loss: 0.6898 - val_accuracy: 0.5091\n",
            "Epoch 115/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5073 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
            "Epoch 116/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5099 - val_loss: 0.6921 - val_accuracy: 0.5065\n",
            "Epoch 117/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.5084 - val_loss: 0.7031 - val_accuracy: 0.4830\n",
            "Epoch 118/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5276 - val_loss: 0.7019 - val_accuracy: 0.4700\n",
            "Epoch 119/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6916 - val_accuracy: 0.5039\n",
            "Epoch 120/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5023 - val_loss: 0.6910 - val_accuracy: 0.4935\n",
            "Epoch 121/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5067 - val_loss: 0.7099 - val_accuracy: 0.4830\n",
            "Epoch 122/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5078 - val_loss: 0.6870 - val_accuracy: 0.5300\n",
            "Epoch 123/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5128 - val_loss: 0.6927 - val_accuracy: 0.4987\n",
            "Epoch 124/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5084 - val_loss: 0.6959 - val_accuracy: 0.4752\n",
            "Epoch 125/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5195 - val_loss: 0.7113 - val_accuracy: 0.4804\n",
            "Epoch 126/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4922 - val_loss: 0.6899 - val_accuracy: 0.5065\n",
            "Epoch 127/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5186 - val_loss: 0.6880 - val_accuracy: 0.5091\n",
            "Epoch 128/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5015 - val_loss: 0.6958 - val_accuracy: 0.4804\n",
            "Epoch 129/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5180 - val_loss: 0.7017 - val_accuracy: 0.4856\n",
            "Epoch 130/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5023 - val_loss: 0.6880 - val_accuracy: 0.5117\n",
            "Epoch 131/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.4959 - val_loss: 0.6896 - val_accuracy: 0.5274\n",
            "Epoch 132/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5067 - val_loss: 0.6870 - val_accuracy: 0.5326\n",
            "Epoch 133/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4956 - val_loss: 0.6886 - val_accuracy: 0.5300\n",
            "Epoch 134/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5128 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
            "Epoch 135/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5174 - val_loss: 0.6937 - val_accuracy: 0.5300\n",
            "Epoch 136/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.4977 - val_loss: 0.6877 - val_accuracy: 0.5274\n",
            "Epoch 137/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5238 - val_loss: 0.6894 - val_accuracy: 0.5248\n",
            "Epoch 138/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5052 - val_loss: 0.6961 - val_accuracy: 0.4883\n",
            "Epoch 139/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5140 - val_loss: 0.6890 - val_accuracy: 0.5196\n",
            "Epoch 140/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5029 - val_loss: 0.6990 - val_accuracy: 0.4830\n",
            "Epoch 141/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5105 - val_loss: 0.7030 - val_accuracy: 0.4830\n",
            "Epoch 142/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5029 - val_loss: 0.6937 - val_accuracy: 0.4961\n",
            "Epoch 143/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5122 - val_loss: 0.7039 - val_accuracy: 0.4830\n",
            "Epoch 144/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.4956 - val_loss: 0.6952 - val_accuracy: 0.4935\n",
            "Epoch 145/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5142 - val_loss: 0.6880 - val_accuracy: 0.5300\n",
            "Epoch 146/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5061 - val_loss: 0.6941 - val_accuracy: 0.4961\n",
            "Epoch 147/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6990 - val_accuracy: 0.4778\n",
            "Epoch 148/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4991 - val_loss: 0.6956 - val_accuracy: 0.4752\n",
            "Epoch 149/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5093 - val_loss: 0.6968 - val_accuracy: 0.4935\n",
            "Epoch 150/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5128 - val_loss: 0.6875 - val_accuracy: 0.5300\n",
            "Epoch 151/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5119 - val_loss: 0.6887 - val_accuracy: 0.5144\n",
            "Epoch 152/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5163 - val_loss: 0.6979 - val_accuracy: 0.4856\n",
            "Epoch 153/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4965 - val_loss: 0.6913 - val_accuracy: 0.5091\n",
            "Epoch 154/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6948 - val_accuracy: 0.4935\n",
            "Epoch 155/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5076 - val_loss: 0.6915 - val_accuracy: 0.5170\n",
            "Epoch 156/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5049 - val_loss: 0.7018 - val_accuracy: 0.4856\n",
            "Epoch 157/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5052 - val_loss: 0.6906 - val_accuracy: 0.5170\n",
            "Epoch 158/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5105 - val_loss: 0.6959 - val_accuracy: 0.4883\n",
            "Epoch 159/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5081 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
            "Epoch 160/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5070 - val_loss: 0.6953 - val_accuracy: 0.4883\n",
            "Epoch 161/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5160 - val_loss: 0.7035 - val_accuracy: 0.4830\n",
            "Epoch 162/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5192 - val_loss: 0.6882 - val_accuracy: 0.5222\n",
            "Epoch 163/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4948 - val_loss: 0.6882 - val_accuracy: 0.5196\n",
            "Epoch 164/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5116 - val_loss: 0.7011 - val_accuracy: 0.4883\n",
            "Epoch 165/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5076 - val_loss: 0.6875 - val_accuracy: 0.5222\n",
            "Epoch 166/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5026 - val_loss: 0.6928 - val_accuracy: 0.4961\n",
            "Epoch 167/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5044 - val_loss: 0.6955 - val_accuracy: 0.4804\n",
            "Epoch 168/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5128 - val_loss: 0.6963 - val_accuracy: 0.4883\n",
            "Epoch 169/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5035 - val_loss: 0.6875 - val_accuracy: 0.5248\n",
            "Epoch 170/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5227 - val_loss: 0.6877 - val_accuracy: 0.5196\n",
            "Epoch 171/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5084 - val_loss: 0.6991 - val_accuracy: 0.4804\n",
            "Epoch 172/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5096 - val_loss: 0.6941 - val_accuracy: 0.4830\n",
            "Epoch 173/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5215 - val_loss: 0.6942 - val_accuracy: 0.4987\n",
            "Epoch 174/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.7085 - val_accuracy: 0.4778\n",
            "Epoch 175/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5052 - val_loss: 0.7103 - val_accuracy: 0.4856\n",
            "Epoch 176/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5125 - val_loss: 0.6982 - val_accuracy: 0.4856\n",
            "Epoch 177/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.4971 - val_loss: 0.6897 - val_accuracy: 0.5091\n",
            "Epoch 178/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5177 - val_loss: 0.6910 - val_accuracy: 0.5039\n",
            "Epoch 179/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5041 - val_loss: 0.6929 - val_accuracy: 0.5039\n",
            "Epoch 180/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5047 - val_loss: 0.6941 - val_accuracy: 0.4961\n",
            "Epoch 181/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5116 - val_loss: 0.6879 - val_accuracy: 0.5300\n",
            "Epoch 182/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5009 - val_loss: 0.6913 - val_accuracy: 0.5144\n",
            "Epoch 183/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5081 - val_loss: 0.7045 - val_accuracy: 0.4883\n",
            "Epoch 184/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5151 - val_loss: 0.6913 - val_accuracy: 0.5013\n",
            "Epoch 185/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5131 - val_loss: 0.6974 - val_accuracy: 0.4804\n",
            "Epoch 186/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5041 - val_loss: 0.6902 - val_accuracy: 0.5013\n",
            "Epoch 187/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5055 - val_loss: 0.6975 - val_accuracy: 0.4830\n",
            "Epoch 188/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5067 - val_loss: 0.6877 - val_accuracy: 0.5222\n",
            "Epoch 189/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5038 - val_loss: 0.6903 - val_accuracy: 0.5144\n",
            "Epoch 190/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5196\n",
            "Epoch 191/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5003 - val_loss: 0.6903 - val_accuracy: 0.5222\n",
            "Epoch 192/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5122 - val_loss: 0.6875 - val_accuracy: 0.5300\n",
            "Epoch 193/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5087 - val_loss: 0.7033 - val_accuracy: 0.4856\n",
            "Epoch 194/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5099 - val_loss: 0.6956 - val_accuracy: 0.4856\n",
            "Epoch 195/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5134 - val_loss: 0.6973 - val_accuracy: 0.4804\n",
            "Epoch 196/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5026 - val_loss: 0.6952 - val_accuracy: 0.4883\n",
            "Epoch 197/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5093 - val_loss: 0.6884 - val_accuracy: 0.5300\n",
            "Epoch 198/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5160 - val_loss: 0.6945 - val_accuracy: 0.4883\n",
            "Epoch 199/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5096 - val_loss: 0.6899 - val_accuracy: 0.5222\n",
            "Epoch 200/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5105 - val_loss: 0.6996 - val_accuracy: 0.4856\n",
            "Epoch 201/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5023 - val_loss: 0.6896 - val_accuracy: 0.5170\n",
            "Epoch 202/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5099 - val_loss: 0.6897 - val_accuracy: 0.5039\n",
            "Epoch 203/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5102 - val_loss: 0.7131 - val_accuracy: 0.4778\n",
            "Epoch 204/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6880 - val_accuracy: 0.5117\n",
            "Epoch 205/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5108 - val_loss: 0.6915 - val_accuracy: 0.5170\n",
            "Epoch 206/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5192 - val_loss: 0.7009 - val_accuracy: 0.4830\n",
            "Epoch 207/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5174 - val_loss: 0.6961 - val_accuracy: 0.4830\n",
            "Epoch 208/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6909 - val_accuracy: 0.5144\n",
            "Epoch 209/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5020 - val_loss: 0.6913 - val_accuracy: 0.5144\n",
            "Epoch 210/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5140 - val_loss: 0.6884 - val_accuracy: 0.5144\n",
            "Epoch 211/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.4994 - val_loss: 0.6975 - val_accuracy: 0.4830\n",
            "Epoch 212/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6880 - val_accuracy: 0.5300\n",
            "Epoch 213/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5154 - val_loss: 0.7023 - val_accuracy: 0.4804\n",
            "Epoch 214/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5157 - val_loss: 0.6942 - val_accuracy: 0.4883\n",
            "Epoch 215/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5041 - val_loss: 0.6901 - val_accuracy: 0.5117\n",
            "Epoch 216/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5140 - val_loss: 0.6884 - val_accuracy: 0.5117\n",
            "Epoch 217/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5131 - val_loss: 0.6899 - val_accuracy: 0.5065\n",
            "Epoch 218/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5026 - val_loss: 0.6919 - val_accuracy: 0.5039\n",
            "Epoch 219/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5003 - val_loss: 0.6929 - val_accuracy: 0.5065\n",
            "Epoch 220/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5073 - val_loss: 0.6916 - val_accuracy: 0.4909\n",
            "Epoch 221/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5137 - val_loss: 0.6956 - val_accuracy: 0.4883\n",
            "Epoch 222/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5110 - val_loss: 0.6938 - val_accuracy: 0.4935\n",
            "Epoch 223/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5058 - val_loss: 0.6981 - val_accuracy: 0.4830\n",
            "Epoch 224/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5052 - val_loss: 0.6907 - val_accuracy: 0.5144\n",
            "Epoch 225/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5093 - val_loss: 0.6905 - val_accuracy: 0.5352\n",
            "Epoch 226/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5131 - val_loss: 0.6944 - val_accuracy: 0.4856\n",
            "Epoch 227/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5087 - val_loss: 0.6928 - val_accuracy: 0.5013\n",
            "Epoch 228/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4971 - val_loss: 0.6896 - val_accuracy: 0.5013\n",
            "Epoch 229/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6980 - val_accuracy: 0.4804\n",
            "Epoch 230/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5221 - val_loss: 0.6959 - val_accuracy: 0.4883\n",
            "Epoch 231/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5134 - val_loss: 0.7005 - val_accuracy: 0.4909\n",
            "Epoch 232/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.5192 - val_loss: 0.6926 - val_accuracy: 0.5039\n",
            "Epoch 233/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5145 - val_loss: 0.7098 - val_accuracy: 0.4804\n",
            "Epoch 234/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5067 - val_loss: 0.6879 - val_accuracy: 0.5222\n",
            "Epoch 235/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5020 - val_loss: 0.6903 - val_accuracy: 0.5013\n",
            "Epoch 236/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5137 - val_loss: 0.6927 - val_accuracy: 0.4961\n",
            "Epoch 237/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6887 - val_accuracy: 0.5117\n",
            "Epoch 238/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6890 - val_accuracy: 0.5170\n",
            "Epoch 239/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5070 - val_loss: 0.6954 - val_accuracy: 0.4883\n",
            "Epoch 240/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5140 - val_loss: 0.6958 - val_accuracy: 0.4883\n",
            "Epoch 241/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5032 - val_loss: 0.6900 - val_accuracy: 0.5196\n",
            "Epoch 242/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6924 - val_accuracy: 0.5013\n",
            "Epoch 243/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5163 - val_loss: 0.6935 - val_accuracy: 0.4778\n",
            "Epoch 244/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.7032 - val_accuracy: 0.4883\n",
            "Epoch 245/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.7016 - val_accuracy: 0.4856\n",
            "Epoch 246/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5035 - val_loss: 0.6874 - val_accuracy: 0.5300\n",
            "Epoch 247/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5078 - val_loss: 0.6879 - val_accuracy: 0.5300\n",
            "Epoch 248/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5017 - val_loss: 0.6959 - val_accuracy: 0.4883\n",
            "Epoch 249/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.7068 - val_accuracy: 0.4830\n",
            "Epoch 250/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5140 - val_loss: 0.7081 - val_accuracy: 0.4856\n",
            "Epoch 251/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5055 - val_loss: 0.6933 - val_accuracy: 0.4909\n",
            "Epoch 252/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5160 - val_loss: 0.6892 - val_accuracy: 0.5065\n",
            "Epoch 253/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.4883\n",
            "Epoch 254/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6905 - val_accuracy: 0.5405\n",
            "Epoch 255/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5125 - val_loss: 0.6944 - val_accuracy: 0.4804\n",
            "Epoch 256/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5174 - val_loss: 0.7099 - val_accuracy: 0.4804\n",
            "Epoch 257/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5087 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
            "Epoch 258/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5102 - val_loss: 0.6887 - val_accuracy: 0.5248\n",
            "Epoch 259/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5131 - val_loss: 0.6877 - val_accuracy: 0.5196\n",
            "Epoch 260/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5090 - val_loss: 0.6885 - val_accuracy: 0.5248\n",
            "Epoch 261/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5119 - val_loss: 0.6926 - val_accuracy: 0.5065\n",
            "Epoch 262/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5177 - val_loss: 0.6900 - val_accuracy: 0.5144\n",
            "Epoch 263/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5154 - val_loss: 0.6891 - val_accuracy: 0.5065\n",
            "Epoch 264/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5119 - val_loss: 0.6930 - val_accuracy: 0.5013\n",
            "Epoch 265/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4974 - val_loss: 0.7005 - val_accuracy: 0.4830\n",
            "Epoch 266/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5049 - val_loss: 0.7128 - val_accuracy: 0.4804\n",
            "Epoch 267/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.4968 - val_loss: 0.6882 - val_accuracy: 0.5222\n",
            "Epoch 268/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5087 - val_loss: 0.6895 - val_accuracy: 0.5144\n",
            "Epoch 269/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5096 - val_loss: 0.6938 - val_accuracy: 0.4856\n",
            "Epoch 270/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5116 - val_loss: 0.7003 - val_accuracy: 0.4883\n",
            "Epoch 271/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5070 - val_loss: 0.6904 - val_accuracy: 0.5117\n",
            "Epoch 272/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.7026 - val_accuracy: 0.4804\n",
            "Epoch 273/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5148 - val_loss: 0.6949 - val_accuracy: 0.4856\n",
            "Epoch 274/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5297 - val_loss: 0.6950 - val_accuracy: 0.4883\n",
            "Epoch 275/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5087 - val_loss: 0.6956 - val_accuracy: 0.4883\n",
            "Epoch 276/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5091\n",
            "Epoch 277/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5174 - val_loss: 0.6915 - val_accuracy: 0.5091\n",
            "Epoch 278/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5145 - val_loss: 0.6917 - val_accuracy: 0.5091\n",
            "Epoch 279/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5073 - val_loss: 0.7017 - val_accuracy: 0.4909\n",
            "Epoch 280/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5093 - val_loss: 0.7008 - val_accuracy: 0.4909\n",
            "Epoch 281/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5038 - val_loss: 0.6891 - val_accuracy: 0.5196\n",
            "Epoch 282/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6960 - val_accuracy: 0.4883\n",
            "Epoch 283/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5128 - val_loss: 0.6965 - val_accuracy: 0.4883\n",
            "Epoch 284/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5128 - val_loss: 0.6946 - val_accuracy: 0.4909\n",
            "Epoch 285/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5013\n",
            "Epoch 286/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5102 - val_loss: 0.6907 - val_accuracy: 0.5352\n",
            "Epoch 287/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5209 - val_loss: 0.6968 - val_accuracy: 0.4987\n",
            "Epoch 288/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5110 - val_loss: 0.6914 - val_accuracy: 0.5065\n",
            "Epoch 289/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5119 - val_loss: 0.6933 - val_accuracy: 0.4830\n",
            "Epoch 290/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5113 - val_loss: 0.7074 - val_accuracy: 0.4830\n",
            "Epoch 291/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5142 - val_loss: 0.6895 - val_accuracy: 0.5091\n",
            "Epoch 292/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6885 - val_accuracy: 0.5274\n",
            "Epoch 293/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.4935\n",
            "Epoch 294/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
            "Epoch 295/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5247 - val_loss: 0.6877 - val_accuracy: 0.5248\n",
            "Epoch 296/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5090 - val_loss: 0.6888 - val_accuracy: 0.5117\n",
            "Epoch 297/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5070 - val_loss: 0.6922 - val_accuracy: 0.4961\n",
            "Epoch 298/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5110 - val_loss: 0.6954 - val_accuracy: 0.4883\n",
            "Epoch 299/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5122 - val_loss: 0.6935 - val_accuracy: 0.4830\n",
            "Epoch 300/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4956 - val_loss: 0.6909 - val_accuracy: 0.5039\n",
            "Epoch 301/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5122 - val_loss: 0.6897 - val_accuracy: 0.5091\n",
            "Epoch 302/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5151 - val_loss: 0.6918 - val_accuracy: 0.4987\n",
            "Epoch 303/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5113 - val_loss: 0.6938 - val_accuracy: 0.4804\n",
            "Epoch 304/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5049 - val_loss: 0.6918 - val_accuracy: 0.5013\n",
            "Epoch 305/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5105 - val_loss: 0.6880 - val_accuracy: 0.5248\n",
            "Epoch 306/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5201 - val_loss: 0.6959 - val_accuracy: 0.4961\n",
            "Epoch 307/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5039\n",
            "Epoch 308/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.7048 - val_accuracy: 0.4830\n",
            "Epoch 309/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6925 - val_accuracy: 0.4961\n",
            "Epoch 310/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5090 - val_loss: 0.6929 - val_accuracy: 0.4909\n",
            "Epoch 311/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5061 - val_loss: 0.6960 - val_accuracy: 0.4883\n",
            "Epoch 312/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6925 - val_accuracy: 0.4935\n",
            "Epoch 313/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5192 - val_loss: 0.6965 - val_accuracy: 0.4856\n",
            "Epoch 314/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6888 - val_accuracy: 0.5039\n",
            "Epoch 315/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5131 - val_loss: 0.6896 - val_accuracy: 0.5170\n",
            "Epoch 316/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5140 - val_loss: 0.7065 - val_accuracy: 0.4830\n",
            "Epoch 317/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5215 - val_loss: 0.6994 - val_accuracy: 0.4935\n",
            "Epoch 318/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5070 - val_loss: 0.6907 - val_accuracy: 0.5248\n",
            "Epoch 319/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5198 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
            "Epoch 320/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5013\n",
            "Epoch 321/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6887 - val_accuracy: 0.5274\n",
            "Epoch 322/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5215 - val_loss: 0.6941 - val_accuracy: 0.4883\n",
            "Epoch 323/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5102 - val_loss: 0.6924 - val_accuracy: 0.5013\n",
            "Epoch 324/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4974 - val_loss: 0.6920 - val_accuracy: 0.4961\n",
            "Epoch 325/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6904 - val_accuracy: 0.5274\n",
            "Epoch 326/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5273 - val_loss: 0.6923 - val_accuracy: 0.5065\n",
            "Epoch 327/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5189 - val_loss: 0.6959 - val_accuracy: 0.4935\n",
            "Epoch 328/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5212 - val_loss: 0.6882 - val_accuracy: 0.5300\n",
            "Epoch 329/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5125 - val_loss: 0.6955 - val_accuracy: 0.4935\n",
            "Epoch 330/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5052 - val_loss: 0.6953 - val_accuracy: 0.4961\n",
            "Epoch 331/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5131 - val_loss: 0.6911 - val_accuracy: 0.5091\n",
            "Epoch 332/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5108 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
            "Epoch 333/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5087 - val_loss: 0.6912 - val_accuracy: 0.5065\n",
            "Epoch 334/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5113 - val_loss: 0.6954 - val_accuracy: 0.4909\n",
            "Epoch 335/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5119 - val_loss: 0.6990 - val_accuracy: 0.4909\n",
            "Epoch 336/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5067 - val_loss: 0.6931 - val_accuracy: 0.4830\n",
            "Epoch 337/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5102 - val_loss: 0.6913 - val_accuracy: 0.5117\n",
            "Epoch 338/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5166 - val_loss: 0.6922 - val_accuracy: 0.4987\n",
            "Epoch 339/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5131 - val_loss: 0.6901 - val_accuracy: 0.5065\n",
            "Epoch 340/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5102 - val_loss: 0.6902 - val_accuracy: 0.5170\n",
            "Epoch 341/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6941 - val_accuracy: 0.4987\n",
            "Epoch 342/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5163 - val_loss: 0.6892 - val_accuracy: 0.5248\n",
            "Epoch 343/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5244 - val_loss: 0.6900 - val_accuracy: 0.5300\n",
            "Epoch 344/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5134 - val_loss: 0.6901 - val_accuracy: 0.5300\n",
            "Epoch 345/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6917 - val_accuracy: 0.5091\n",
            "Epoch 346/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6927 - val_accuracy: 0.4883\n",
            "Epoch 347/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5070 - val_loss: 0.6986 - val_accuracy: 0.4883\n",
            "Epoch 348/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5137 - val_loss: 0.6946 - val_accuracy: 0.4961\n",
            "Epoch 349/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5221 - val_loss: 0.6938 - val_accuracy: 0.4856\n",
            "Epoch 350/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.4830\n",
            "Epoch 351/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5061 - val_loss: 0.6958 - val_accuracy: 0.5065\n",
            "Epoch 352/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6888 - val_accuracy: 0.5144\n",
            "Epoch 353/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5317 - val_loss: 0.7054 - val_accuracy: 0.4804\n",
            "Epoch 354/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5230 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
            "Epoch 355/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6893 - val_accuracy: 0.5222\n",
            "Epoch 356/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5241 - val_loss: 0.7070 - val_accuracy: 0.4856\n",
            "Epoch 357/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5151 - val_loss: 0.6980 - val_accuracy: 0.4909\n",
            "Epoch 358/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5230 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
            "Epoch 359/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6905 - val_accuracy: 0.5091\n",
            "Epoch 360/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5093 - val_loss: 0.6930 - val_accuracy: 0.4961\n",
            "Epoch 361/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6897 - val_accuracy: 0.5144\n",
            "Epoch 362/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6908 - val_accuracy: 0.5039\n",
            "Epoch 363/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6975 - val_accuracy: 0.4935\n",
            "Epoch 364/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5273 - val_loss: 0.6873 - val_accuracy: 0.5248\n",
            "Epoch 365/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5134 - val_loss: 0.6980 - val_accuracy: 0.4935\n",
            "Epoch 366/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5102 - val_loss: 0.7053 - val_accuracy: 0.4856\n",
            "Epoch 367/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5291 - val_loss: 0.6882 - val_accuracy: 0.5196\n",
            "Epoch 368/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5201 - val_loss: 0.6977 - val_accuracy: 0.4961\n",
            "Epoch 369/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5299 - val_loss: 0.6879 - val_accuracy: 0.5274\n",
            "Epoch 370/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5163 - val_loss: 0.6972 - val_accuracy: 0.4935\n",
            "Epoch 371/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5110 - val_loss: 0.6931 - val_accuracy: 0.4909\n",
            "Epoch 372/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5142 - val_loss: 0.6928 - val_accuracy: 0.4935\n",
            "Epoch 373/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5195 - val_loss: 0.6960 - val_accuracy: 0.4987\n",
            "Epoch 374/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6899 - val_accuracy: 0.5144\n",
            "Epoch 375/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6884 - val_accuracy: 0.5170\n",
            "Epoch 376/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5238 - val_loss: 0.6891 - val_accuracy: 0.5117\n",
            "Epoch 377/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5305 - val_loss: 0.7011 - val_accuracy: 0.4883\n",
            "Epoch 378/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5196\n",
            "Epoch 379/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5119 - val_loss: 0.7034 - val_accuracy: 0.4856\n",
            "Epoch 380/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5119 - val_loss: 0.6977 - val_accuracy: 0.4935\n",
            "Epoch 381/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5215 - val_loss: 0.6946 - val_accuracy: 0.4987\n",
            "Epoch 382/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5081 - val_loss: 0.6996 - val_accuracy: 0.4909\n",
            "Epoch 383/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5131 - val_loss: 0.6946 - val_accuracy: 0.4961\n",
            "Epoch 384/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5227 - val_loss: 0.6974 - val_accuracy: 0.4961\n",
            "Epoch 385/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5091\n",
            "Epoch 386/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5134 - val_loss: 0.6908 - val_accuracy: 0.5144\n",
            "Epoch 387/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5090 - val_loss: 0.6945 - val_accuracy: 0.4935\n",
            "Epoch 388/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5180 - val_loss: 0.6870 - val_accuracy: 0.5300\n",
            "Epoch 389/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5142 - val_loss: 0.6903 - val_accuracy: 0.5144\n",
            "Epoch 390/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5253 - val_loss: 0.6998 - val_accuracy: 0.4883\n",
            "Epoch 391/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6887 - val_accuracy: 0.5170\n",
            "Epoch 392/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5174 - val_loss: 0.7116 - val_accuracy: 0.4856\n",
            "Epoch 393/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5102 - val_loss: 0.6929 - val_accuracy: 0.4883\n",
            "Epoch 394/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5212 - val_loss: 0.6872 - val_accuracy: 0.5170\n",
            "Epoch 395/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5108 - val_loss: 0.6881 - val_accuracy: 0.5248\n",
            "Epoch 396/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5180 - val_loss: 0.6897 - val_accuracy: 0.5222\n",
            "Epoch 397/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5250 - val_loss: 0.6919 - val_accuracy: 0.4961\n",
            "Epoch 398/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6926 - val_accuracy: 0.4961\n",
            "Epoch 399/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5134 - val_loss: 0.6952 - val_accuracy: 0.4909\n",
            "Epoch 400/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5039\n",
            "Epoch 401/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6984 - val_accuracy: 0.4961\n",
            "Epoch 402/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5227 - val_loss: 0.6873 - val_accuracy: 0.5248\n",
            "Epoch 403/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5055 - val_loss: 0.6901 - val_accuracy: 0.5170\n",
            "Epoch 404/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6983 - val_accuracy: 0.4935\n",
            "Epoch 405/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6869 - val_accuracy: 0.5248\n",
            "Epoch 406/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5203 - val_loss: 0.6908 - val_accuracy: 0.5091\n",
            "Epoch 407/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5157 - val_loss: 0.6905 - val_accuracy: 0.5170\n",
            "Epoch 408/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5096 - val_loss: 0.6933 - val_accuracy: 0.5091\n",
            "Epoch 409/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5276 - val_loss: 0.6947 - val_accuracy: 0.4987\n",
            "Epoch 410/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5113 - val_loss: 0.6945 - val_accuracy: 0.4856\n",
            "Epoch 411/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5230 - val_loss: 0.6878 - val_accuracy: 0.5300\n",
            "Epoch 412/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5099 - val_loss: 0.6922 - val_accuracy: 0.5013\n",
            "Epoch 413/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5308 - val_loss: 0.6884 - val_accuracy: 0.5196\n",
            "Epoch 414/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5049 - val_loss: 0.6944 - val_accuracy: 0.4883\n",
            "Epoch 415/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5215 - val_loss: 0.6890 - val_accuracy: 0.5248\n",
            "Epoch 416/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5267 - val_loss: 0.6886 - val_accuracy: 0.5196\n",
            "Epoch 417/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5238 - val_loss: 0.6969 - val_accuracy: 0.4961\n",
            "Epoch 418/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5166 - val_loss: 0.6910 - val_accuracy: 0.5170\n",
            "Epoch 419/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5157 - val_loss: 0.6909 - val_accuracy: 0.4987\n",
            "Epoch 420/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5148 - val_loss: 0.6931 - val_accuracy: 0.4987\n",
            "Epoch 421/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.4987\n",
            "Epoch 422/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6881 - val_accuracy: 0.5196\n",
            "Epoch 423/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5224 - val_loss: 0.6896 - val_accuracy: 0.5326\n",
            "Epoch 424/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5192 - val_loss: 0.6913 - val_accuracy: 0.5222\n",
            "Epoch 425/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.7049 - val_accuracy: 0.4752\n",
            "Epoch 426/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5039\n",
            "Epoch 427/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5285 - val_loss: 0.7031 - val_accuracy: 0.4856\n",
            "Epoch 428/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6955 - val_accuracy: 0.4752\n",
            "Epoch 429/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5145 - val_loss: 0.6959 - val_accuracy: 0.4987\n",
            "Epoch 430/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5091\n",
            "Epoch 431/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5174 - val_loss: 0.6912 - val_accuracy: 0.5196\n",
            "Epoch 432/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5192 - val_loss: 0.6927 - val_accuracy: 0.4987\n",
            "Epoch 433/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5142 - val_loss: 0.6969 - val_accuracy: 0.4909\n",
            "Epoch 434/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5148 - val_loss: 0.6921 - val_accuracy: 0.5065\n",
            "Epoch 435/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6891 - val_accuracy: 0.5144\n",
            "Epoch 436/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5116 - val_loss: 0.6890 - val_accuracy: 0.5144\n",
            "Epoch 437/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5154 - val_loss: 0.6903 - val_accuracy: 0.5170\n",
            "Epoch 438/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5163 - val_loss: 0.6959 - val_accuracy: 0.4961\n",
            "Epoch 439/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5282 - val_loss: 0.6994 - val_accuracy: 0.4752\n",
            "Epoch 440/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5186 - val_loss: 0.7037 - val_accuracy: 0.4961\n",
            "Epoch 441/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6959 - val_accuracy: 0.4935\n",
            "Epoch 442/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5090 - val_loss: 0.6916 - val_accuracy: 0.5065\n",
            "Epoch 443/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5137 - val_loss: 0.6945 - val_accuracy: 0.4830\n",
            "Epoch 444/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5212 - val_loss: 0.6883 - val_accuracy: 0.5196\n",
            "Epoch 445/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6960 - val_accuracy: 0.4856\n",
            "Epoch 446/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5238 - val_loss: 0.6929 - val_accuracy: 0.5170\n",
            "Epoch 447/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5134 - val_loss: 0.6923 - val_accuracy: 0.5065\n",
            "Epoch 448/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5299 - val_loss: 0.6953 - val_accuracy: 0.4987\n",
            "Epoch 449/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5183 - val_loss: 0.6941 - val_accuracy: 0.4883\n",
            "Epoch 450/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5122 - val_loss: 0.6918 - val_accuracy: 0.5013\n",
            "Epoch 451/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5224 - val_loss: 0.7028 - val_accuracy: 0.4935\n",
            "Epoch 452/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5169 - val_loss: 0.6964 - val_accuracy: 0.4987\n",
            "Epoch 453/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5273 - val_loss: 0.6937 - val_accuracy: 0.5013\n",
            "Epoch 454/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5221 - val_loss: 0.6895 - val_accuracy: 0.5170\n",
            "Epoch 455/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5131 - val_loss: 0.6928 - val_accuracy: 0.5013\n",
            "Epoch 456/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.7012 - val_accuracy: 0.4804\n",
            "Epoch 457/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5140 - val_loss: 0.6911 - val_accuracy: 0.5144\n",
            "Epoch 458/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6880 - val_accuracy: 0.5170\n",
            "Epoch 459/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
            "Epoch 460/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6907 - val_accuracy: 0.5013\n",
            "Epoch 461/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.7022 - val_accuracy: 0.4804\n",
            "Epoch 462/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5091\n",
            "Epoch 463/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5256 - val_loss: 0.6952 - val_accuracy: 0.4935\n",
            "Epoch 464/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6900 - val_accuracy: 0.5144\n",
            "Epoch 465/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6985 - val_accuracy: 0.4961\n",
            "Epoch 466/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5215 - val_loss: 0.7063 - val_accuracy: 0.4856\n",
            "Epoch 467/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5180 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
            "Epoch 468/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6993 - val_accuracy: 0.4987\n",
            "Epoch 469/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5137 - val_loss: 0.6959 - val_accuracy: 0.4909\n",
            "Epoch 470/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5265 - val_loss: 0.6945 - val_accuracy: 0.4987\n",
            "Epoch 471/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5192 - val_loss: 0.6947 - val_accuracy: 0.4830\n",
            "Epoch 472/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5256 - val_loss: 0.6967 - val_accuracy: 0.4856\n",
            "Epoch 473/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5174 - val_loss: 0.7021 - val_accuracy: 0.4935\n",
            "Epoch 474/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5259 - val_loss: 0.6910 - val_accuracy: 0.5144\n",
            "Epoch 475/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5189 - val_loss: 0.6908 - val_accuracy: 0.5170\n",
            "Epoch 476/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5174 - val_loss: 0.6904 - val_accuracy: 0.5196\n",
            "Epoch 477/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5267 - val_loss: 0.6893 - val_accuracy: 0.5170\n",
            "Epoch 478/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6895 - val_accuracy: 0.5144\n",
            "Epoch 479/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6931 - val_accuracy: 0.5117\n",
            "Epoch 480/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.7044 - val_accuracy: 0.4856\n",
            "Epoch 481/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5154 - val_loss: 0.6915 - val_accuracy: 0.5248\n",
            "Epoch 482/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5378 - val_loss: 0.6962 - val_accuracy: 0.4935\n",
            "Epoch 483/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6871 - val_accuracy: 0.5300\n",
            "Epoch 484/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5317 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
            "Epoch 485/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5160 - val_loss: 0.6945 - val_accuracy: 0.4987\n",
            "Epoch 486/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5227 - val_loss: 0.7003 - val_accuracy: 0.4961\n",
            "Epoch 487/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5125 - val_loss: 0.6902 - val_accuracy: 0.5196\n",
            "Epoch 488/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5314 - val_loss: 0.6892 - val_accuracy: 0.5196\n",
            "Epoch 489/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6895 - val_accuracy: 0.5117\n",
            "Epoch 490/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5224 - val_loss: 0.6950 - val_accuracy: 0.4987\n",
            "Epoch 491/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5297 - val_loss: 0.6954 - val_accuracy: 0.4883\n",
            "Epoch 492/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5177 - val_loss: 0.6955 - val_accuracy: 0.4856\n",
            "Epoch 493/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5203 - val_loss: 0.6969 - val_accuracy: 0.4935\n",
            "Epoch 494/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5183 - val_loss: 0.6980 - val_accuracy: 0.5013\n",
            "Epoch 495/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5206 - val_loss: 0.6966 - val_accuracy: 0.4909\n",
            "Epoch 496/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5172 - val_loss: 0.6937 - val_accuracy: 0.4883\n",
            "Epoch 497/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5201 - val_loss: 0.6980 - val_accuracy: 0.4909\n",
            "Epoch 498/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5273 - val_loss: 0.6905 - val_accuracy: 0.5222\n",
            "Epoch 499/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.4883\n",
            "Epoch 500/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5172 - val_loss: 0.6982 - val_accuracy: 0.4961\n",
            "Epoch 501/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5253 - val_loss: 0.6979 - val_accuracy: 0.4935\n",
            "Epoch 502/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5259 - val_loss: 0.6919 - val_accuracy: 0.5039\n",
            "Epoch 503/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5198 - val_loss: 0.7080 - val_accuracy: 0.4909\n",
            "Epoch 504/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5259 - val_loss: 0.6968 - val_accuracy: 0.4909\n",
            "Epoch 505/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5230 - val_loss: 0.6936 - val_accuracy: 0.5144\n",
            "Epoch 506/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5157 - val_loss: 0.6911 - val_accuracy: 0.5117\n",
            "Epoch 507/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5241 - val_loss: 0.6963 - val_accuracy: 0.4856\n",
            "Epoch 508/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5235 - val_loss: 0.6900 - val_accuracy: 0.5248\n",
            "Epoch 509/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6988 - val_accuracy: 0.4987\n",
            "Epoch 510/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5174 - val_loss: 0.7005 - val_accuracy: 0.4726\n",
            "Epoch 511/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5105 - val_loss: 0.6899 - val_accuracy: 0.5144\n",
            "Epoch 512/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5203 - val_loss: 0.6979 - val_accuracy: 0.5013\n",
            "Epoch 513/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5224 - val_loss: 0.6986 - val_accuracy: 0.4935\n",
            "Epoch 514/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5262 - val_loss: 0.6940 - val_accuracy: 0.5091\n",
            "Epoch 515/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5224 - val_loss: 0.6936 - val_accuracy: 0.4961\n",
            "Epoch 516/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5227 - val_loss: 0.6971 - val_accuracy: 0.4961\n",
            "Epoch 517/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5294 - val_loss: 0.6911 - val_accuracy: 0.5170\n",
            "Epoch 518/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5218 - val_loss: 0.6908 - val_accuracy: 0.5117\n",
            "Epoch 519/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5262 - val_loss: 0.6995 - val_accuracy: 0.5039\n",
            "Epoch 520/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5262 - val_loss: 0.6945 - val_accuracy: 0.4935\n",
            "Epoch 521/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5169 - val_loss: 0.6959 - val_accuracy: 0.4935\n",
            "Epoch 522/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5196\n",
            "Epoch 523/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6901 - val_accuracy: 0.5170\n",
            "Epoch 524/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5203 - val_loss: 0.6907 - val_accuracy: 0.5300\n",
            "Epoch 525/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5198 - val_loss: 0.6943 - val_accuracy: 0.5039\n",
            "Epoch 526/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5169 - val_loss: 0.6905 - val_accuracy: 0.5144\n",
            "Epoch 527/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5195 - val_loss: 0.6960 - val_accuracy: 0.4883\n",
            "Epoch 528/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5209 - val_loss: 0.7011 - val_accuracy: 0.5039\n",
            "Epoch 529/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6983 - val_accuracy: 0.4883\n",
            "Epoch 530/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5267 - val_loss: 0.7028 - val_accuracy: 0.5013\n",
            "Epoch 531/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5282 - val_loss: 0.6905 - val_accuracy: 0.5274\n",
            "Epoch 532/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6936 - val_accuracy: 0.5170\n",
            "Epoch 533/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5256 - val_loss: 0.6954 - val_accuracy: 0.4804\n",
            "Epoch 534/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5294 - val_loss: 0.6950 - val_accuracy: 0.5065\n",
            "Epoch 535/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6964 - val_accuracy: 0.4883\n",
            "Epoch 536/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5137 - val_loss: 0.6972 - val_accuracy: 0.4935\n",
            "Epoch 537/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5183 - val_loss: 0.6938 - val_accuracy: 0.5013\n",
            "Epoch 538/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5352 - val_loss: 0.6973 - val_accuracy: 0.4909\n",
            "Epoch 539/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5267 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
            "Epoch 540/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5203 - val_loss: 0.6968 - val_accuracy: 0.4987\n",
            "Epoch 541/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5360 - val_loss: 0.6893 - val_accuracy: 0.5274\n",
            "Epoch 542/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5154 - val_loss: 0.6965 - val_accuracy: 0.4935\n",
            "Epoch 543/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5183 - val_loss: 0.6953 - val_accuracy: 0.5117\n",
            "Epoch 544/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5305 - val_loss: 0.6947 - val_accuracy: 0.5065\n",
            "Epoch 545/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5328 - val_loss: 0.6916 - val_accuracy: 0.5065\n",
            "Epoch 546/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5299 - val_loss: 0.6927 - val_accuracy: 0.5196\n",
            "Epoch 547/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.7017 - val_accuracy: 0.4961\n",
            "Epoch 548/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
            "Epoch 549/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5308 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
            "Epoch 550/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5144\n",
            "Epoch 551/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5174 - val_loss: 0.6948 - val_accuracy: 0.4961\n",
            "Epoch 552/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5235 - val_loss: 0.6943 - val_accuracy: 0.4987\n",
            "Epoch 553/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5142 - val_loss: 0.7011 - val_accuracy: 0.4935\n",
            "Epoch 554/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5323 - val_loss: 0.6966 - val_accuracy: 0.4883\n",
            "Epoch 555/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5209 - val_loss: 0.6934 - val_accuracy: 0.5091\n",
            "Epoch 556/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5250 - val_loss: 0.6932 - val_accuracy: 0.5379\n",
            "Epoch 557/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5291 - val_loss: 0.6906 - val_accuracy: 0.5170\n",
            "Epoch 558/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5192 - val_loss: 0.6970 - val_accuracy: 0.4909\n",
            "Epoch 559/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5262 - val_loss: 0.7031 - val_accuracy: 0.4987\n",
            "Epoch 560/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5262 - val_loss: 0.6923 - val_accuracy: 0.5091\n",
            "Epoch 561/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5259 - val_loss: 0.6916 - val_accuracy: 0.5091\n",
            "Epoch 562/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5145 - val_loss: 0.7003 - val_accuracy: 0.4909\n",
            "Epoch 563/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5267 - val_loss: 0.6934 - val_accuracy: 0.4961\n",
            "Epoch 564/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5227 - val_loss: 0.6994 - val_accuracy: 0.4909\n",
            "Epoch 565/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5369 - val_loss: 0.6907 - val_accuracy: 0.5170\n",
            "Epoch 566/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5288 - val_loss: 0.6948 - val_accuracy: 0.5117\n",
            "Epoch 567/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5276 - val_loss: 0.6949 - val_accuracy: 0.5117\n",
            "Epoch 568/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5212 - val_loss: 0.6952 - val_accuracy: 0.5144\n",
            "Epoch 569/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5140 - val_loss: 0.6924 - val_accuracy: 0.5091\n",
            "Epoch 570/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5244 - val_loss: 0.6946 - val_accuracy: 0.5144\n",
            "Epoch 571/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5299 - val_loss: 0.7016 - val_accuracy: 0.4961\n",
            "Epoch 572/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5065\n",
            "Epoch 573/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5256 - val_loss: 0.6999 - val_accuracy: 0.4935\n",
            "Epoch 574/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5256 - val_loss: 0.6984 - val_accuracy: 0.4856\n",
            "Epoch 575/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
            "Epoch 576/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5224 - val_loss: 0.7029 - val_accuracy: 0.4987\n",
            "Epoch 577/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5206 - val_loss: 0.6980 - val_accuracy: 0.4935\n",
            "Epoch 578/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5212 - val_loss: 0.6978 - val_accuracy: 0.4909\n",
            "Epoch 579/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5212 - val_loss: 0.6955 - val_accuracy: 0.5065\n",
            "Epoch 580/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5186 - val_loss: 0.6949 - val_accuracy: 0.5013\n",
            "Epoch 581/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5183 - val_loss: 0.7026 - val_accuracy: 0.4987\n",
            "Epoch 582/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5267 - val_loss: 0.6924 - val_accuracy: 0.5326\n",
            "Epoch 583/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5221 - val_loss: 0.6970 - val_accuracy: 0.4909\n",
            "Epoch 584/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5267 - val_loss: 0.6947 - val_accuracy: 0.5144\n",
            "Epoch 585/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5238 - val_loss: 0.6951 - val_accuracy: 0.5144\n",
            "Epoch 586/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5265 - val_loss: 0.6953 - val_accuracy: 0.5039\n",
            "Epoch 587/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5256 - val_loss: 0.7001 - val_accuracy: 0.4883\n",
            "Epoch 588/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5169 - val_loss: 0.7019 - val_accuracy: 0.4856\n",
            "Epoch 589/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5125 - val_loss: 0.6933 - val_accuracy: 0.5196\n",
            "Epoch 590/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5166 - val_loss: 0.6985 - val_accuracy: 0.5039\n",
            "Epoch 591/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5154 - val_loss: 0.6939 - val_accuracy: 0.5065\n",
            "Epoch 592/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5297 - val_loss: 0.7023 - val_accuracy: 0.4909\n",
            "Epoch 593/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5116 - val_loss: 0.7018 - val_accuracy: 0.5013\n",
            "Epoch 594/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5116 - val_loss: 0.6973 - val_accuracy: 0.4883\n",
            "Epoch 595/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5282 - val_loss: 0.6938 - val_accuracy: 0.4987\n",
            "Epoch 596/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5212 - val_loss: 0.7031 - val_accuracy: 0.4778\n",
            "Epoch 597/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5288 - val_loss: 0.6959 - val_accuracy: 0.4987\n",
            "Epoch 598/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5189 - val_loss: 0.7022 - val_accuracy: 0.4778\n",
            "Epoch 599/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5265 - val_loss: 0.6953 - val_accuracy: 0.5117\n",
            "Epoch 600/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5279 - val_loss: 0.6966 - val_accuracy: 0.4935\n",
            "Epoch 601/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5314 - val_loss: 0.7000 - val_accuracy: 0.4883\n",
            "Epoch 602/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5288 - val_loss: 0.6937 - val_accuracy: 0.5196\n",
            "Epoch 603/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5212 - val_loss: 0.7012 - val_accuracy: 0.4909\n",
            "Epoch 604/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5212 - val_loss: 0.7000 - val_accuracy: 0.4883\n",
            "Epoch 605/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5233 - val_loss: 0.7009 - val_accuracy: 0.4935\n",
            "Epoch 606/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5247 - val_loss: 0.6958 - val_accuracy: 0.5170\n",
            "Epoch 607/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5212 - val_loss: 0.6986 - val_accuracy: 0.4935\n",
            "Epoch 608/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5253 - val_loss: 0.7002 - val_accuracy: 0.4856\n",
            "Epoch 609/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5270 - val_loss: 0.6967 - val_accuracy: 0.4961\n",
            "Epoch 610/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5247 - val_loss: 0.7007 - val_accuracy: 0.4961\n",
            "Epoch 611/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5163 - val_loss: 0.6954 - val_accuracy: 0.5248\n",
            "Epoch 612/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5288 - val_loss: 0.7032 - val_accuracy: 0.4909\n",
            "Epoch 613/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5247 - val_loss: 0.6975 - val_accuracy: 0.4987\n",
            "Epoch 614/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5297 - val_loss: 0.6907 - val_accuracy: 0.5274\n",
            "Epoch 615/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5244 - val_loss: 0.6993 - val_accuracy: 0.5091\n",
            "Epoch 616/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5276 - val_loss: 0.7052 - val_accuracy: 0.5117\n",
            "Epoch 617/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5151 - val_loss: 0.6991 - val_accuracy: 0.4987\n",
            "Epoch 618/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5206 - val_loss: 0.6957 - val_accuracy: 0.5274\n",
            "Epoch 619/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5262 - val_loss: 0.6944 - val_accuracy: 0.5300\n",
            "Epoch 620/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5267 - val_loss: 0.6946 - val_accuracy: 0.5405\n",
            "Epoch 621/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5241 - val_loss: 0.7038 - val_accuracy: 0.4935\n",
            "Epoch 622/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5308 - val_loss: 0.6984 - val_accuracy: 0.4961\n",
            "Epoch 623/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6978 - val_accuracy: 0.4935\n",
            "Epoch 624/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5285 - val_loss: 0.6996 - val_accuracy: 0.4856\n",
            "Epoch 625/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5235 - val_loss: 0.6963 - val_accuracy: 0.4883\n",
            "Epoch 626/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5201 - val_loss: 0.7057 - val_accuracy: 0.4909\n",
            "Epoch 627/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5221 - val_loss: 0.6963 - val_accuracy: 0.4961\n",
            "Epoch 628/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5279 - val_loss: 0.6970 - val_accuracy: 0.4961\n",
            "Epoch 629/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5323 - val_loss: 0.7015 - val_accuracy: 0.4987\n",
            "Epoch 630/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5320 - val_loss: 0.6973 - val_accuracy: 0.4987\n",
            "Epoch 631/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5206 - val_loss: 0.7004 - val_accuracy: 0.4987\n",
            "Epoch 632/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5113 - val_loss: 0.7047 - val_accuracy: 0.4961\n",
            "Epoch 633/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5288 - val_loss: 0.7052 - val_accuracy: 0.4778\n",
            "Epoch 634/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5265 - val_loss: 0.7025 - val_accuracy: 0.4961\n",
            "Epoch 635/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5172 - val_loss: 0.6946 - val_accuracy: 0.5300\n",
            "Epoch 636/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5186 - val_loss: 0.6947 - val_accuracy: 0.5091\n",
            "Epoch 637/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5244 - val_loss: 0.6995 - val_accuracy: 0.5117\n",
            "Epoch 638/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5291 - val_loss: 0.6959 - val_accuracy: 0.5300\n",
            "Epoch 639/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5265 - val_loss: 0.6971 - val_accuracy: 0.5117\n",
            "Epoch 640/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5189 - val_loss: 0.6993 - val_accuracy: 0.5039\n",
            "Epoch 641/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5235 - val_loss: 0.7005 - val_accuracy: 0.4856\n",
            "Epoch 642/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5174 - val_loss: 0.6969 - val_accuracy: 0.5222\n",
            "Epoch 643/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5183 - val_loss: 0.6949 - val_accuracy: 0.5196\n",
            "Epoch 644/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5311 - val_loss: 0.6991 - val_accuracy: 0.4856\n",
            "Epoch 645/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5169 - val_loss: 0.6975 - val_accuracy: 0.5248\n",
            "Epoch 646/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5276 - val_loss: 0.6993 - val_accuracy: 0.4856\n",
            "Epoch 647/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5323 - val_loss: 0.6980 - val_accuracy: 0.4883\n",
            "Epoch 648/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5145 - val_loss: 0.6943 - val_accuracy: 0.5222\n",
            "Epoch 649/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5247 - val_loss: 0.7009 - val_accuracy: 0.4909\n",
            "Epoch 650/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5203 - val_loss: 0.6958 - val_accuracy: 0.5352\n",
            "Epoch 651/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5305 - val_loss: 0.6951 - val_accuracy: 0.5457\n",
            "Epoch 652/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5265 - val_loss: 0.6973 - val_accuracy: 0.4935\n",
            "Epoch 653/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5276 - val_loss: 0.6951 - val_accuracy: 0.5405\n",
            "Epoch 654/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5241 - val_loss: 0.6930 - val_accuracy: 0.5509\n",
            "Epoch 655/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5203 - val_loss: 0.6997 - val_accuracy: 0.4987\n",
            "Epoch 656/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5241 - val_loss: 0.6996 - val_accuracy: 0.4961\n",
            "Epoch 657/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5235 - val_loss: 0.7003 - val_accuracy: 0.4856\n",
            "Epoch 658/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5166 - val_loss: 0.6992 - val_accuracy: 0.4935\n",
            "Epoch 659/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5294 - val_loss: 0.6968 - val_accuracy: 0.4987\n",
            "Epoch 660/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5195 - val_loss: 0.7035 - val_accuracy: 0.4935\n",
            "Epoch 661/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5305 - val_loss: 0.6972 - val_accuracy: 0.5013\n",
            "Epoch 662/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5212 - val_loss: 0.6991 - val_accuracy: 0.4961\n",
            "Epoch 663/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5233 - val_loss: 0.7029 - val_accuracy: 0.4856\n",
            "Epoch 664/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5302 - val_loss: 0.6962 - val_accuracy: 0.5170\n",
            "Epoch 665/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5262 - val_loss: 0.7033 - val_accuracy: 0.4856\n",
            "Epoch 666/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5256 - val_loss: 0.6954 - val_accuracy: 0.5431\n",
            "Epoch 667/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5233 - val_loss: 0.6969 - val_accuracy: 0.5091\n",
            "Epoch 668/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5299 - val_loss: 0.7033 - val_accuracy: 0.4856\n",
            "Epoch 669/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5206 - val_loss: 0.7025 - val_accuracy: 0.4909\n",
            "Epoch 670/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5235 - val_loss: 0.6985 - val_accuracy: 0.5013\n",
            "Epoch 671/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5302 - val_loss: 0.6958 - val_accuracy: 0.5144\n",
            "Epoch 672/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5131 - val_loss: 0.6959 - val_accuracy: 0.5431\n",
            "Epoch 673/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5221 - val_loss: 0.7027 - val_accuracy: 0.4856\n",
            "Epoch 674/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5215 - val_loss: 0.7002 - val_accuracy: 0.4935\n",
            "Epoch 675/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5235 - val_loss: 0.6926 - val_accuracy: 0.5457\n",
            "Epoch 676/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5244 - val_loss: 0.6948 - val_accuracy: 0.5091\n",
            "Epoch 677/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5174 - val_loss: 0.7000 - val_accuracy: 0.4830\n",
            "Epoch 678/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5142 - val_loss: 0.6968 - val_accuracy: 0.5144\n",
            "Epoch 679/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5221 - val_loss: 0.7001 - val_accuracy: 0.4830\n",
            "Epoch 680/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5215 - val_loss: 0.7006 - val_accuracy: 0.4830\n",
            "Epoch 681/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5297 - val_loss: 0.7051 - val_accuracy: 0.4935\n",
            "Epoch 682/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5198 - val_loss: 0.7025 - val_accuracy: 0.4883\n",
            "Epoch 683/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5186 - val_loss: 0.6994 - val_accuracy: 0.4830\n",
            "Epoch 684/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5238 - val_loss: 0.7047 - val_accuracy: 0.4909\n",
            "Epoch 685/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5297 - val_loss: 0.7001 - val_accuracy: 0.5039\n",
            "Epoch 686/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5305 - val_loss: 0.7003 - val_accuracy: 0.4909\n",
            "Epoch 687/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5209 - val_loss: 0.7038 - val_accuracy: 0.4883\n",
            "Epoch 688/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5233 - val_loss: 0.7032 - val_accuracy: 0.4935\n",
            "Epoch 689/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5160 - val_loss: 0.7003 - val_accuracy: 0.4830\n",
            "Epoch 690/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5331 - val_loss: 0.7087 - val_accuracy: 0.4830\n",
            "Epoch 691/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5267 - val_loss: 0.6986 - val_accuracy: 0.5039\n",
            "Epoch 692/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5253 - val_loss: 0.6992 - val_accuracy: 0.4935\n",
            "Epoch 693/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5163 - val_loss: 0.6978 - val_accuracy: 0.5405\n",
            "Epoch 694/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5235 - val_loss: 0.6960 - val_accuracy: 0.5117\n",
            "Epoch 695/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5198 - val_loss: 0.6965 - val_accuracy: 0.4987\n",
            "Epoch 696/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5189 - val_loss: 0.6968 - val_accuracy: 0.5013\n",
            "Epoch 697/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5224 - val_loss: 0.6958 - val_accuracy: 0.5326\n",
            "Epoch 698/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5256 - val_loss: 0.6988 - val_accuracy: 0.5065\n",
            "Epoch 699/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5163 - val_loss: 0.7013 - val_accuracy: 0.4883\n",
            "Epoch 700/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5294 - val_loss: 0.6949 - val_accuracy: 0.5117\n",
            "Epoch 701/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5230 - val_loss: 0.7015 - val_accuracy: 0.5013\n",
            "Epoch 702/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5282 - val_loss: 0.7068 - val_accuracy: 0.4804\n",
            "Epoch 703/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5221 - val_loss: 0.7001 - val_accuracy: 0.4961\n",
            "Epoch 704/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5256 - val_loss: 0.7078 - val_accuracy: 0.4987\n",
            "Epoch 705/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5108 - val_loss: 0.7006 - val_accuracy: 0.4935\n",
            "Epoch 706/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5230 - val_loss: 0.7033 - val_accuracy: 0.4909\n",
            "Epoch 707/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5119 - val_loss: 0.7045 - val_accuracy: 0.4883\n",
            "Epoch 708/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5302 - val_loss: 0.6975 - val_accuracy: 0.5091\n",
            "Epoch 709/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5244 - val_loss: 0.6977 - val_accuracy: 0.5039\n",
            "Epoch 710/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5305 - val_loss: 0.6978 - val_accuracy: 0.5039\n",
            "Epoch 711/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5201 - val_loss: 0.6989 - val_accuracy: 0.5013\n",
            "Epoch 712/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5201 - val_loss: 0.6972 - val_accuracy: 0.5352\n",
            "Epoch 713/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5227 - val_loss: 0.6988 - val_accuracy: 0.4909\n",
            "Epoch 714/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5238 - val_loss: 0.6996 - val_accuracy: 0.4856\n",
            "Epoch 715/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5262 - val_loss: 0.6962 - val_accuracy: 0.5379\n",
            "Epoch 716/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5262 - val_loss: 0.6965 - val_accuracy: 0.4987\n",
            "Epoch 717/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5131 - val_loss: 0.7008 - val_accuracy: 0.4961\n",
            "Epoch 718/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5302 - val_loss: 0.6978 - val_accuracy: 0.4987\n",
            "Epoch 719/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5282 - val_loss: 0.6953 - val_accuracy: 0.4987\n",
            "Epoch 720/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5250 - val_loss: 0.7030 - val_accuracy: 0.4856\n",
            "Epoch 721/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5265 - val_loss: 0.6967 - val_accuracy: 0.5117\n",
            "Epoch 722/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5198 - val_loss: 0.7044 - val_accuracy: 0.4830\n",
            "Epoch 723/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5299 - val_loss: 0.6978 - val_accuracy: 0.4961\n",
            "Epoch 724/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5294 - val_loss: 0.6956 - val_accuracy: 0.5039\n",
            "Epoch 725/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5241 - val_loss: 0.7039 - val_accuracy: 0.4883\n",
            "Epoch 726/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5291 - val_loss: 0.7002 - val_accuracy: 0.5013\n",
            "Epoch 727/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5224 - val_loss: 0.7030 - val_accuracy: 0.4987\n",
            "Epoch 728/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5142 - val_loss: 0.6988 - val_accuracy: 0.4961\n",
            "Epoch 729/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5218 - val_loss: 0.7008 - val_accuracy: 0.4909\n",
            "Epoch 730/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5209 - val_loss: 0.7000 - val_accuracy: 0.4856\n",
            "Epoch 731/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5131 - val_loss: 0.7015 - val_accuracy: 0.4830\n",
            "Epoch 732/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5297 - val_loss: 0.7043 - val_accuracy: 0.4856\n",
            "Epoch 733/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5288 - val_loss: 0.6967 - val_accuracy: 0.5352\n",
            "Epoch 734/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5334 - val_loss: 0.7051 - val_accuracy: 0.4856\n",
            "Epoch 735/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5238 - val_loss: 0.6986 - val_accuracy: 0.5013\n",
            "Epoch 736/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5224 - val_loss: 0.6990 - val_accuracy: 0.4961\n",
            "Epoch 737/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5160 - val_loss: 0.6982 - val_accuracy: 0.4883\n",
            "Epoch 738/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5273 - val_loss: 0.6953 - val_accuracy: 0.5013\n",
            "Epoch 739/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5352\n",
            "Epoch 740/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5166 - val_loss: 0.7019 - val_accuracy: 0.5091\n",
            "Epoch 741/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5308 - val_loss: 0.6998 - val_accuracy: 0.4883\n",
            "Epoch 742/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5294 - val_loss: 0.7009 - val_accuracy: 0.5065\n",
            "Epoch 743/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5273 - val_loss: 0.7018 - val_accuracy: 0.4935\n",
            "Epoch 744/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5212 - val_loss: 0.6991 - val_accuracy: 0.5013\n",
            "Epoch 745/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5233 - val_loss: 0.6979 - val_accuracy: 0.4961\n",
            "Epoch 746/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5198 - val_loss: 0.6985 - val_accuracy: 0.4909\n",
            "Epoch 747/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5334 - val_loss: 0.6977 - val_accuracy: 0.5117\n",
            "Epoch 748/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5215 - val_loss: 0.7064 - val_accuracy: 0.4909\n",
            "Epoch 749/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5267 - val_loss: 0.6990 - val_accuracy: 0.4804\n",
            "Epoch 750/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5247 - val_loss: 0.7050 - val_accuracy: 0.4909\n",
            "Epoch 751/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5209 - val_loss: 0.7017 - val_accuracy: 0.4935\n",
            "Epoch 752/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5288 - val_loss: 0.6992 - val_accuracy: 0.4909\n",
            "Epoch 753/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5169 - val_loss: 0.7036 - val_accuracy: 0.4830\n",
            "Epoch 754/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5230 - val_loss: 0.7000 - val_accuracy: 0.4987\n",
            "Epoch 755/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5244 - val_loss: 0.6955 - val_accuracy: 0.5352\n",
            "Epoch 756/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5087 - val_loss: 0.7011 - val_accuracy: 0.4935\n",
            "Epoch 757/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5247 - val_loss: 0.6977 - val_accuracy: 0.5379\n",
            "Epoch 758/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5241 - val_loss: 0.6958 - val_accuracy: 0.5405\n",
            "Epoch 759/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5259 - val_loss: 0.7033 - val_accuracy: 0.4883\n",
            "Epoch 760/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5192 - val_loss: 0.7040 - val_accuracy: 0.4830\n",
            "Epoch 761/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5369 - val_loss: 0.6908 - val_accuracy: 0.5274\n",
            "Epoch 762/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5233 - val_loss: 0.6989 - val_accuracy: 0.4909\n",
            "Epoch 763/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5189 - val_loss: 0.7007 - val_accuracy: 0.4987\n",
            "Epoch 764/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5279 - val_loss: 0.7009 - val_accuracy: 0.4856\n",
            "Epoch 765/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5320 - val_loss: 0.6953 - val_accuracy: 0.5352\n",
            "Epoch 766/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5235 - val_loss: 0.7004 - val_accuracy: 0.5013\n",
            "Epoch 767/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5137 - val_loss: 0.7056 - val_accuracy: 0.4987\n",
            "Epoch 768/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5288 - val_loss: 0.7038 - val_accuracy: 0.4987\n",
            "Epoch 769/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5221 - val_loss: 0.6992 - val_accuracy: 0.5222\n",
            "Epoch 770/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5378 - val_loss: 0.7123 - val_accuracy: 0.4935\n",
            "Epoch 771/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5267 - val_loss: 0.6970 - val_accuracy: 0.5013\n",
            "Epoch 772/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5253 - val_loss: 0.6974 - val_accuracy: 0.5248\n",
            "Epoch 773/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5180 - val_loss: 0.6995 - val_accuracy: 0.5196\n",
            "Epoch 774/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5174 - val_loss: 0.7016 - val_accuracy: 0.4856\n",
            "Epoch 775/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5203 - val_loss: 0.7035 - val_accuracy: 0.4830\n",
            "Epoch 776/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5238 - val_loss: 0.7023 - val_accuracy: 0.4856\n",
            "Epoch 777/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5265 - val_loss: 0.6965 - val_accuracy: 0.4804\n",
            "Epoch 778/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5235 - val_loss: 0.6992 - val_accuracy: 0.5196\n",
            "Epoch 779/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5288 - val_loss: 0.7003 - val_accuracy: 0.5013\n",
            "Epoch 780/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5174 - val_loss: 0.6959 - val_accuracy: 0.5300\n",
            "Epoch 781/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5352 - val_loss: 0.6989 - val_accuracy: 0.5144\n",
            "Epoch 782/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5215 - val_loss: 0.6991 - val_accuracy: 0.5300\n",
            "Epoch 783/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5340 - val_loss: 0.6997 - val_accuracy: 0.4935\n",
            "Epoch 784/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5192 - val_loss: 0.7011 - val_accuracy: 0.4883\n",
            "Epoch 785/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5328 - val_loss: 0.7028 - val_accuracy: 0.4830\n",
            "Epoch 786/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5235 - val_loss: 0.7040 - val_accuracy: 0.4830\n",
            "Epoch 787/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5308 - val_loss: 0.7001 - val_accuracy: 0.4856\n",
            "Epoch 788/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5340 - val_loss: 0.7046 - val_accuracy: 0.4935\n",
            "Epoch 789/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5276 - val_loss: 0.7032 - val_accuracy: 0.4961\n",
            "Epoch 790/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5349 - val_loss: 0.7075 - val_accuracy: 0.4935\n",
            "Epoch 791/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5183 - val_loss: 0.7056 - val_accuracy: 0.4987\n",
            "Epoch 792/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5235 - val_loss: 0.7005 - val_accuracy: 0.4935\n",
            "Epoch 793/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5256 - val_loss: 0.7024 - val_accuracy: 0.4935\n",
            "Epoch 794/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5314 - val_loss: 0.7071 - val_accuracy: 0.5013\n",
            "Epoch 795/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5235 - val_loss: 0.6997 - val_accuracy: 0.5535\n",
            "Epoch 796/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5297 - val_loss: 0.7032 - val_accuracy: 0.4883\n",
            "Epoch 797/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5180 - val_loss: 0.7006 - val_accuracy: 0.5013\n",
            "Epoch 798/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5209 - val_loss: 0.7044 - val_accuracy: 0.4935\n",
            "Epoch 799/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5125 - val_loss: 0.7024 - val_accuracy: 0.4935\n",
            "Epoch 800/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5259 - val_loss: 0.6996 - val_accuracy: 0.4909\n",
            "Epoch 801/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5244 - val_loss: 0.6996 - val_accuracy: 0.5222\n",
            "Epoch 802/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5201 - val_loss: 0.6965 - val_accuracy: 0.4987\n",
            "Epoch 803/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5233 - val_loss: 0.6979 - val_accuracy: 0.4909\n",
            "Epoch 804/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5331 - val_loss: 0.7000 - val_accuracy: 0.5170\n",
            "Epoch 805/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5212 - val_loss: 0.6988 - val_accuracy: 0.5379\n",
            "Epoch 806/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5183 - val_loss: 0.6966 - val_accuracy: 0.4909\n",
            "Epoch 807/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5288 - val_loss: 0.6980 - val_accuracy: 0.4961\n",
            "Epoch 808/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5265 - val_loss: 0.6982 - val_accuracy: 0.4883\n",
            "Epoch 809/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5299 - val_loss: 0.7008 - val_accuracy: 0.5013\n",
            "Epoch 810/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5288 - val_loss: 0.7043 - val_accuracy: 0.4856\n",
            "Epoch 811/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5209 - val_loss: 0.7026 - val_accuracy: 0.4987\n",
            "Epoch 812/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5262 - val_loss: 0.7058 - val_accuracy: 0.4909\n",
            "Epoch 813/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5177 - val_loss: 0.6988 - val_accuracy: 0.4909\n",
            "Epoch 814/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5285 - val_loss: 0.7011 - val_accuracy: 0.5170\n",
            "Epoch 815/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5250 - val_loss: 0.7018 - val_accuracy: 0.4935\n",
            "Epoch 816/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5259 - val_loss: 0.7002 - val_accuracy: 0.5222\n",
            "Epoch 817/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5311 - val_loss: 0.7079 - val_accuracy: 0.4935\n",
            "Epoch 818/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5282 - val_loss: 0.6960 - val_accuracy: 0.5196\n",
            "Epoch 819/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5227 - val_loss: 0.7013 - val_accuracy: 0.4830\n",
            "Epoch 820/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5279 - val_loss: 0.7029 - val_accuracy: 0.4856\n",
            "Epoch 821/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5212 - val_loss: 0.6992 - val_accuracy: 0.5039\n",
            "Epoch 822/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5203 - val_loss: 0.6996 - val_accuracy: 0.5222\n",
            "Epoch 823/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5212 - val_loss: 0.7004 - val_accuracy: 0.4856\n",
            "Epoch 824/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5358 - val_loss: 0.6982 - val_accuracy: 0.5431\n",
            "Epoch 825/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5227 - val_loss: 0.7029 - val_accuracy: 0.4961\n",
            "Epoch 826/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5230 - val_loss: 0.6971 - val_accuracy: 0.5222\n",
            "Epoch 827/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5259 - val_loss: 0.7056 - val_accuracy: 0.4856\n",
            "Epoch 828/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5212 - val_loss: 0.7008 - val_accuracy: 0.5457\n",
            "Epoch 829/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5189 - val_loss: 0.7063 - val_accuracy: 0.4856\n",
            "Epoch 830/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5227 - val_loss: 0.7073 - val_accuracy: 0.4883\n",
            "Epoch 831/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5352 - val_loss: 0.6988 - val_accuracy: 0.5013\n",
            "Epoch 832/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5247 - val_loss: 0.7015 - val_accuracy: 0.5274\n",
            "Epoch 833/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5305 - val_loss: 0.7087 - val_accuracy: 0.4909\n",
            "Epoch 834/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5302 - val_loss: 0.7020 - val_accuracy: 0.5039\n",
            "Epoch 835/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5302 - val_loss: 0.7010 - val_accuracy: 0.5065\n",
            "Epoch 836/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5183 - val_loss: 0.7016 - val_accuracy: 0.4909\n",
            "Epoch 837/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5166 - val_loss: 0.7064 - val_accuracy: 0.4856\n",
            "Epoch 838/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5209 - val_loss: 0.7038 - val_accuracy: 0.4830\n",
            "Epoch 839/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5262 - val_loss: 0.6994 - val_accuracy: 0.4856\n",
            "Epoch 840/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5192 - val_loss: 0.7036 - val_accuracy: 0.4909\n",
            "Epoch 841/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5276 - val_loss: 0.7056 - val_accuracy: 0.4856\n",
            "Epoch 842/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5360 - val_loss: 0.6965 - val_accuracy: 0.5196\n",
            "Epoch 843/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5311 - val_loss: 0.6930 - val_accuracy: 0.5274\n",
            "Epoch 844/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5282 - val_loss: 0.6987 - val_accuracy: 0.4778\n",
            "Epoch 845/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5233 - val_loss: 0.6979 - val_accuracy: 0.5300\n",
            "Epoch 846/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5203 - val_loss: 0.7078 - val_accuracy: 0.4856\n",
            "Epoch 847/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5192 - val_loss: 0.7031 - val_accuracy: 0.4883\n",
            "Epoch 848/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5288 - val_loss: 0.7089 - val_accuracy: 0.5300\n",
            "Epoch 849/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5265 - val_loss: 0.7002 - val_accuracy: 0.5091\n",
            "Epoch 850/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5209 - val_loss: 0.7055 - val_accuracy: 0.4909\n",
            "Epoch 851/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5279 - val_loss: 0.7167 - val_accuracy: 0.4935\n",
            "Epoch 852/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5299 - val_loss: 0.6982 - val_accuracy: 0.5039\n",
            "Epoch 853/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5265 - val_loss: 0.6993 - val_accuracy: 0.4830\n",
            "Epoch 854/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5238 - val_loss: 0.7031 - val_accuracy: 0.4935\n",
            "Epoch 855/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5279 - val_loss: 0.7036 - val_accuracy: 0.4883\n",
            "Epoch 856/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5270 - val_loss: 0.7091 - val_accuracy: 0.4935\n",
            "Epoch 857/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5273 - val_loss: 0.7013 - val_accuracy: 0.5170\n",
            "Epoch 858/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5276 - val_loss: 0.7017 - val_accuracy: 0.5352\n",
            "Epoch 859/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5297 - val_loss: 0.7060 - val_accuracy: 0.4830\n",
            "Epoch 860/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5262 - val_loss: 0.6960 - val_accuracy: 0.5300\n",
            "Epoch 861/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5360 - val_loss: 0.7002 - val_accuracy: 0.5013\n",
            "Epoch 862/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5215 - val_loss: 0.6973 - val_accuracy: 0.4987\n",
            "Epoch 863/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5218 - val_loss: 0.7042 - val_accuracy: 0.4883\n",
            "Epoch 864/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5294 - val_loss: 0.7008 - val_accuracy: 0.4935\n",
            "Epoch 865/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5250 - val_loss: 0.7009 - val_accuracy: 0.4987\n",
            "Epoch 866/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5256 - val_loss: 0.7073 - val_accuracy: 0.4883\n",
            "Epoch 867/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5212 - val_loss: 0.7054 - val_accuracy: 0.4883\n",
            "Epoch 868/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5163 - val_loss: 0.7031 - val_accuracy: 0.4961\n",
            "Epoch 869/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5250 - val_loss: 0.7077 - val_accuracy: 0.4804\n",
            "Epoch 870/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5238 - val_loss: 0.7078 - val_accuracy: 0.4883\n",
            "Epoch 871/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5241 - val_loss: 0.7011 - val_accuracy: 0.4856\n",
            "Epoch 872/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5256 - val_loss: 0.7030 - val_accuracy: 0.5144\n",
            "Epoch 873/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5227 - val_loss: 0.7080 - val_accuracy: 0.4830\n",
            "Epoch 874/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5221 - val_loss: 0.6951 - val_accuracy: 0.4961\n",
            "Epoch 875/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5291 - val_loss: 0.7027 - val_accuracy: 0.4961\n",
            "Epoch 876/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5192 - val_loss: 0.7015 - val_accuracy: 0.4909\n",
            "Epoch 877/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5189 - val_loss: 0.7037 - val_accuracy: 0.5039\n",
            "Epoch 878/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5259 - val_loss: 0.7059 - val_accuracy: 0.4856\n",
            "Epoch 879/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5279 - val_loss: 0.7040 - val_accuracy: 0.4909\n",
            "Epoch 880/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5326 - val_loss: 0.6934 - val_accuracy: 0.5144\n",
            "Epoch 881/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5256 - val_loss: 0.7069 - val_accuracy: 0.4883\n",
            "Epoch 882/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5279 - val_loss: 0.7008 - val_accuracy: 0.5013\n",
            "Epoch 883/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5270 - val_loss: 0.7015 - val_accuracy: 0.4830\n",
            "Epoch 884/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5282 - val_loss: 0.6962 - val_accuracy: 0.5274\n",
            "Epoch 885/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5262 - val_loss: 0.7015 - val_accuracy: 0.5065\n",
            "Epoch 886/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5198 - val_loss: 0.7047 - val_accuracy: 0.5117\n",
            "Epoch 887/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5186 - val_loss: 0.6998 - val_accuracy: 0.4909\n",
            "Epoch 888/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5305 - val_loss: 0.6970 - val_accuracy: 0.5326\n",
            "Epoch 889/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5212 - val_loss: 0.6976 - val_accuracy: 0.5039\n",
            "Epoch 890/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5227 - val_loss: 0.7043 - val_accuracy: 0.4935\n",
            "Epoch 891/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5265 - val_loss: 0.7048 - val_accuracy: 0.4883\n",
            "Epoch 892/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5270 - val_loss: 0.7035 - val_accuracy: 0.5144\n",
            "Epoch 893/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5189 - val_loss: 0.7010 - val_accuracy: 0.4883\n",
            "Epoch 894/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5221 - val_loss: 0.7108 - val_accuracy: 0.4935\n",
            "Epoch 895/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5299 - val_loss: 0.7013 - val_accuracy: 0.5091\n",
            "Epoch 896/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5267 - val_loss: 0.7056 - val_accuracy: 0.4987\n",
            "Epoch 897/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5212 - val_loss: 0.6996 - val_accuracy: 0.4961\n",
            "Epoch 898/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5276 - val_loss: 0.7081 - val_accuracy: 0.4883\n",
            "Epoch 899/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5270 - val_loss: 0.7030 - val_accuracy: 0.5222\n",
            "Epoch 900/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5270 - val_loss: 0.6996 - val_accuracy: 0.5117\n",
            "Epoch 901/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5299 - val_loss: 0.7056 - val_accuracy: 0.5248\n",
            "Epoch 902/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5212 - val_loss: 0.7022 - val_accuracy: 0.4883\n",
            "Epoch 903/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5203 - val_loss: 0.7035 - val_accuracy: 0.4830\n",
            "Epoch 904/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5291 - val_loss: 0.6999 - val_accuracy: 0.4987\n",
            "Epoch 905/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5230 - val_loss: 0.7040 - val_accuracy: 0.5196\n",
            "Epoch 906/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5160 - val_loss: 0.6999 - val_accuracy: 0.4909\n",
            "Epoch 907/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5256 - val_loss: 0.7141 - val_accuracy: 0.5065\n",
            "Epoch 908/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5323 - val_loss: 0.7017 - val_accuracy: 0.4804\n",
            "Epoch 909/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5256 - val_loss: 0.7041 - val_accuracy: 0.5144\n",
            "Epoch 910/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5259 - val_loss: 0.7057 - val_accuracy: 0.5196\n",
            "Epoch 911/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5221 - val_loss: 0.7104 - val_accuracy: 0.4778\n",
            "Epoch 912/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5291 - val_loss: 0.7085 - val_accuracy: 0.4883\n",
            "Epoch 913/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5276 - val_loss: 0.7025 - val_accuracy: 0.4987\n",
            "Epoch 914/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5276 - val_loss: 0.7059 - val_accuracy: 0.5300\n",
            "Epoch 915/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5145 - val_loss: 0.6978 - val_accuracy: 0.4883\n",
            "Epoch 916/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5203 - val_loss: 0.7062 - val_accuracy: 0.4804\n",
            "Epoch 917/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5267 - val_loss: 0.6990 - val_accuracy: 0.5326\n",
            "Epoch 918/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5241 - val_loss: 0.7044 - val_accuracy: 0.5117\n",
            "Epoch 919/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5256 - val_loss: 0.7020 - val_accuracy: 0.5144\n",
            "Epoch 920/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5297 - val_loss: 0.6972 - val_accuracy: 0.5117\n",
            "Epoch 921/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5279 - val_loss: 0.6987 - val_accuracy: 0.5117\n",
            "Epoch 922/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5297 - val_loss: 0.7154 - val_accuracy: 0.4961\n",
            "Epoch 923/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5279 - val_loss: 0.7096 - val_accuracy: 0.4883\n",
            "Epoch 924/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5247 - val_loss: 0.7053 - val_accuracy: 0.4961\n",
            "Epoch 925/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5334 - val_loss: 0.7057 - val_accuracy: 0.5170\n",
            "Epoch 926/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5244 - val_loss: 0.6942 - val_accuracy: 0.5300\n",
            "Epoch 927/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5282 - val_loss: 0.6989 - val_accuracy: 0.5013\n",
            "Epoch 928/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5160 - val_loss: 0.7024 - val_accuracy: 0.4987\n",
            "Epoch 929/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5288 - val_loss: 0.7021 - val_accuracy: 0.5196\n",
            "Epoch 930/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5267 - val_loss: 0.7068 - val_accuracy: 0.5065\n",
            "Epoch 931/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5267 - val_loss: 0.7032 - val_accuracy: 0.4987\n",
            "Epoch 932/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5282 - val_loss: 0.7074 - val_accuracy: 0.4987\n",
            "Epoch 933/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5244 - val_loss: 0.7067 - val_accuracy: 0.5248\n",
            "Epoch 934/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5233 - val_loss: 0.7034 - val_accuracy: 0.5039\n",
            "Epoch 935/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5244 - val_loss: 0.7054 - val_accuracy: 0.4961\n",
            "Epoch 936/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5203 - val_loss: 0.7033 - val_accuracy: 0.4961\n",
            "Epoch 937/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5253 - val_loss: 0.7116 - val_accuracy: 0.4935\n",
            "Epoch 938/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5180 - val_loss: 0.7100 - val_accuracy: 0.5065\n",
            "Epoch 939/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5308 - val_loss: 0.7015 - val_accuracy: 0.5274\n",
            "Epoch 940/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5218 - val_loss: 0.7051 - val_accuracy: 0.5117\n",
            "Epoch 941/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5215 - val_loss: 0.7093 - val_accuracy: 0.4909\n",
            "Epoch 942/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5265 - val_loss: 0.7062 - val_accuracy: 0.4883\n",
            "Epoch 943/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5288 - val_loss: 0.7080 - val_accuracy: 0.4935\n",
            "Epoch 944/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5273 - val_loss: 0.6991 - val_accuracy: 0.5352\n",
            "Epoch 945/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5140 - val_loss: 0.7089 - val_accuracy: 0.4935\n",
            "Epoch 946/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5206 - val_loss: 0.7041 - val_accuracy: 0.4935\n",
            "Epoch 947/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5177 - val_loss: 0.7051 - val_accuracy: 0.5091\n",
            "Epoch 948/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5250 - val_loss: 0.7075 - val_accuracy: 0.4935\n",
            "Epoch 949/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5221 - val_loss: 0.7036 - val_accuracy: 0.5170\n",
            "Epoch 950/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5279 - val_loss: 0.7128 - val_accuracy: 0.4830\n",
            "Epoch 951/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5305 - val_loss: 0.7048 - val_accuracy: 0.5013\n",
            "Epoch 952/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5262 - val_loss: 0.7073 - val_accuracy: 0.4883\n",
            "Epoch 953/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5224 - val_loss: 0.7101 - val_accuracy: 0.4883\n",
            "Epoch 954/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5247 - val_loss: 0.7227 - val_accuracy: 0.4909\n",
            "Epoch 955/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5256 - val_loss: 0.7038 - val_accuracy: 0.4935\n",
            "Epoch 956/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5235 - val_loss: 0.7073 - val_accuracy: 0.4909\n",
            "Epoch 957/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5238 - val_loss: 0.7103 - val_accuracy: 0.4856\n",
            "Epoch 958/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5279 - val_loss: 0.7045 - val_accuracy: 0.4961\n",
            "Epoch 959/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5259 - val_loss: 0.7062 - val_accuracy: 0.4856\n",
            "Epoch 960/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5267 - val_loss: 0.7058 - val_accuracy: 0.5248\n",
            "Epoch 961/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5265 - val_loss: 0.7109 - val_accuracy: 0.5144\n",
            "Epoch 962/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5267 - val_loss: 0.7010 - val_accuracy: 0.5248\n",
            "Epoch 963/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5227 - val_loss: 0.7057 - val_accuracy: 0.5144\n",
            "Epoch 964/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5282 - val_loss: 0.7062 - val_accuracy: 0.4883\n",
            "Epoch 965/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5259 - val_loss: 0.7041 - val_accuracy: 0.5248\n",
            "Epoch 966/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5323 - val_loss: 0.7059 - val_accuracy: 0.4856\n",
            "Epoch 967/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5288 - val_loss: 0.7099 - val_accuracy: 0.5091\n",
            "Epoch 968/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5215 - val_loss: 0.7133 - val_accuracy: 0.4935\n",
            "Epoch 969/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5253 - val_loss: 0.7067 - val_accuracy: 0.5170\n",
            "Epoch 970/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5331 - val_loss: 0.7095 - val_accuracy: 0.5065\n",
            "Epoch 971/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5212 - val_loss: 0.7082 - val_accuracy: 0.4856\n",
            "Epoch 972/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5247 - val_loss: 0.7088 - val_accuracy: 0.4909\n",
            "Epoch 973/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5337 - val_loss: 0.6946 - val_accuracy: 0.5170\n",
            "Epoch 974/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5221 - val_loss: 0.7036 - val_accuracy: 0.4830\n",
            "Epoch 975/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5244 - val_loss: 0.6981 - val_accuracy: 0.5170\n",
            "Epoch 976/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5233 - val_loss: 0.7050 - val_accuracy: 0.4987\n",
            "Epoch 977/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5305 - val_loss: 0.7037 - val_accuracy: 0.5274\n",
            "Epoch 978/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5241 - val_loss: 0.7066 - val_accuracy: 0.5196\n",
            "Epoch 979/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5360 - val_loss: 0.7066 - val_accuracy: 0.4987\n",
            "Epoch 980/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5174 - val_loss: 0.7073 - val_accuracy: 0.4883\n",
            "Epoch 981/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5323 - val_loss: 0.7061 - val_accuracy: 0.5352\n",
            "Epoch 982/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5151 - val_loss: 0.7064 - val_accuracy: 0.4961\n",
            "Epoch 983/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5299 - val_loss: 0.7130 - val_accuracy: 0.4830\n",
            "Epoch 984/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5270 - val_loss: 0.7097 - val_accuracy: 0.4883\n",
            "Epoch 985/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5267 - val_loss: 0.7021 - val_accuracy: 0.5222\n",
            "Epoch 986/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5209 - val_loss: 0.7051 - val_accuracy: 0.4987\n",
            "Epoch 987/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5267 - val_loss: 0.7106 - val_accuracy: 0.5144\n",
            "Epoch 988/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5279 - val_loss: 0.7124 - val_accuracy: 0.4935\n",
            "Epoch 989/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5241 - val_loss: 0.7056 - val_accuracy: 0.5248\n",
            "Epoch 990/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5328 - val_loss: 0.7140 - val_accuracy: 0.4961\n",
            "Epoch 991/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5279 - val_loss: 0.7039 - val_accuracy: 0.5170\n",
            "Epoch 992/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5206 - val_loss: 0.7102 - val_accuracy: 0.5065\n",
            "Epoch 993/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5267 - val_loss: 0.7141 - val_accuracy: 0.4856\n",
            "Epoch 994/1000\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5270 - val_loss: 0.7010 - val_accuracy: 0.5222\n",
            "Epoch 995/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5221 - val_loss: 0.7077 - val_accuracy: 0.5222\n",
            "Epoch 996/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5206 - val_loss: 0.7050 - val_accuracy: 0.5013\n",
            "Epoch 997/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5174 - val_loss: 0.7047 - val_accuracy: 0.5065\n",
            "Epoch 998/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5340 - val_loss: 0.7067 - val_accuracy: 0.5170\n",
            "Epoch 999/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5288 - val_loss: 0.7027 - val_accuracy: 0.5013\n",
            "Epoch 1000/1000\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5276 - val_loss: 0.7058 - val_accuracy: 0.4987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2470cbde90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Nationwide_AAnalytics/Under.h5')"
      ],
      "metadata": {
        "id": "1GQDd9sxkLtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Accuracy = \", (acc * 100.0), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csSTyHJg0VJh",
        "outputId": "e7a2d4ca-ba67-4171-ead3-73d37aad61c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.5059\n",
            "Accuracy =  50.58823823928833 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4syJ9zEe0VGo",
        "outputId": "a51d6aad-1e27-4219-f886-fc207f07c15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06151679, 0.14076224, 0.30042922, 0.3389842 , 0.36500055,\n",
              "       0.36933243, 0.39089185, 0.39811987, 0.41987443, 0.44032353,\n",
              "       0.44060597, 0.45311838, 0.45761436, 0.4606013 , 0.46204728,\n",
              "       0.46472985, 0.4655377 , 0.46648622, 0.46993056, 0.47320673,\n",
              "       0.47537935, 0.47738203, 0.47996655, 0.4805699 , 0.48176578,\n",
              "       0.48298898, 0.48356083, 0.4838958 , 0.48532525, 0.4880254 ,\n",
              "       0.4886452 , 0.48995584, 0.4904191 , 0.49047962, 0.4916703 ,\n",
              "       0.49222732, 0.49248543, 0.49343398, 0.49343404, 0.4940086 ,\n",
              "       0.49406323, 0.49424893, 0.4948799 , 0.4954939 , 0.49567395,\n",
              "       0.49630314, 0.49681297, 0.49697834, 0.49704584, 0.4970726 ,\n",
              "       0.4981867 , 0.5003129 , 0.50066537, 0.50112677, 0.5012796 ,\n",
              "       0.5024659 , 0.50320864, 0.50331265, 0.50358   , 0.5039781 ,\n",
              "       0.5050728 , 0.5050921 , 0.5055471 , 0.5055883 , 0.50558835,\n",
              "       0.50620264, 0.50647956, 0.50666106, 0.50704277, 0.5071664 ,\n",
              "       0.508173  , 0.508573  , 0.50870264, 0.50898194, 0.5091357 ,\n",
              "       0.5099273 , 0.5101129 , 0.5101657 , 0.5103603 , 0.5106156 ,\n",
              "       0.5106964 , 0.5108821 , 0.51116616, 0.5114388 , 0.51184005,\n",
              "       0.5120953 , 0.5122285 , 0.51242375, 0.5127952 , 0.5133782 ,\n",
              "       0.5135747 , 0.5136894 , 0.51433265, 0.5145165 , 0.51451653,\n",
              "       0.5147037 , 0.5149101 , 0.515069  , 0.51558846, 0.5161413 ,\n",
              "       0.51627135, 0.5163634 , 0.51666903, 0.51685447, 0.5172255 ,\n",
              "       0.5175491 , 0.5177292 , 0.51778185, 0.5187519 , 0.51936656,\n",
              "       0.5193666 , 0.51946414, 0.52011716, 0.52032346, 0.5204172 ,\n",
              "       0.5208114 , 0.52081895, 0.52085865, 0.52091646, 0.5211013 ,\n",
              "       0.52114904, 0.5212294 , 0.5212649 , 0.5218693 , 0.5219139 ,\n",
              "       0.5226009 , 0.52300745, 0.52337813, 0.52382   , 0.5239175 ,\n",
              "       0.52411914, 0.5241192 , 0.5250742 , 0.52527124, 0.52536863,\n",
              "       0.52766377, 0.52823234, 0.5283694 , 0.5285992 , 0.5289161 ,\n",
              "       0.5301183 , 0.53136337, 0.53138834, 0.53205156, 0.53304404,\n",
              "       0.53363794, 0.5342823 , 0.5344921 , 0.535466  , 0.53588617,\n",
              "       0.53593946, 0.53664994, 0.5373864 , 0.542645  , 0.54308337,\n",
              "       0.5430834 , 0.5437442 , 0.5440638 , 0.5446934 , 0.5453249 ,\n",
              "       0.5464639 , 0.5475646 , 0.5479057 , 0.5491056 , 0.5491159 ,\n",
              "       0.55088335, 0.5515998 , 0.55353063, 0.55373406, 0.55473113,\n",
              "       0.5565012 , 0.5569622 , 0.56113094, 0.5652922 , 0.56542516,\n",
              "       0.56612855, 0.56853724, 0.57356423, 0.58268374, 0.5842925 ,\n",
              "       0.59893167, 0.69905174, 0.98946345, 1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2_PWUBNMdNQ",
        "outputId": "51c6ee15-6b02-4171-8e61-65e79d3999f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_DPPaLWOXWL",
        "outputId": "a727d37a-4d1d-4364-de7f-c7355ce8f08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 65, 146],\n",
              "       [ 64, 150]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "J--Mush-OW9k",
        "outputId": "42cf9929-beb4-4846-b2ba-8de1e1142805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kj6R2yUgQyRv",
        "outputId": "b72d6ca7-4d51-411d-b92d-91498f06a2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.50      0.31      0.38       211\\n           1       0.51      0.70      0.59       214\\n\\n    accuracy                           0.51       425\\n   macro avg       0.51      0.50      0.49       425\\nweighted avg       0.51      0.51      0.49       425\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test with unbalanced data\n",
        "y_pred = model.predict(X_ts)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "cm = confusion_matrix(Y_ts, y_pred)\n",
        "f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "DeW0XTwVo737",
        "outputId": "7a314af9-caef-4256-d7a1-ce7afc67d4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **OVER**"
      ],
      "metadata": {
        "id": "E1D8L4VRHCP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM"
      ],
      "metadata": {
        "id": "Wp_Dr2GLNL96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Increase the minority\n",
        "over = RandomOverSampler(sampling_strategy = 1)\n",
        "x_or, y_or = over.fit_resample(base,asw)\n",
        "y_or.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjVJOa29ZGZ",
        "outputId": "f54a7aee-4c63-4f66-f3a3-747471c25b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEXT_INSPECTION_GRADE_C_OR_BELOW    22160\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_or.value_counts().plot.pie(autopct = '%.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "twXxO_CXHT8_",
        "outputId": "662793bf-1efc-4fcf-8b89-fd0a13deecd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2470d6ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_or, y_or, test_size = 0.1)"
      ],
      "metadata": {
        "id": "tyas_xASHT4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,\n",
        "                    epochs=1000,\n",
        "                    validation_split = 0.1,\n",
        "                    #callbacks=[es_monitor]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxeUxntc9ZDM",
        "outputId": "ee5a0824-e8c5-463c-fa29-abda497c2b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
            "Epoch 2/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6916 - accuracy: 0.5163 - val_loss: 0.6919 - val_accuracy: 0.4947\n",
            "Epoch 3/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6912 - accuracy: 0.5144 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
            "Epoch 4/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5088\n",
            "Epoch 5/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6905 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5018\n",
            "Epoch 6/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5122 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
            "Epoch 7/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6908 - accuracy: 0.5124 - val_loss: 0.6924 - val_accuracy: 0.5028\n",
            "Epoch 8/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6905 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5008\n",
            "Epoch 9/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5088 - val_loss: 0.6914 - val_accuracy: 0.5088\n",
            "Epoch 10/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5109 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
            "Epoch 11/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5112 - val_loss: 0.6909 - val_accuracy: 0.5148\n",
            "Epoch 12/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5116 - val_loss: 0.6917 - val_accuracy: 0.5108\n",
            "Epoch 13/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5181 - val_loss: 0.6915 - val_accuracy: 0.5123\n",
            "Epoch 14/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6909 - accuracy: 0.5116 - val_loss: 0.6905 - val_accuracy: 0.5043\n",
            "Epoch 15/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5153 - val_loss: 0.6908 - val_accuracy: 0.5148\n",
            "Epoch 16/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5166 - val_loss: 0.6912 - val_accuracy: 0.5093\n",
            "Epoch 17/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5137 - val_loss: 0.6909 - val_accuracy: 0.5083\n",
            "Epoch 18/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6907 - accuracy: 0.5113 - val_loss: 0.6919 - val_accuracy: 0.5098\n",
            "Epoch 19/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6911 - accuracy: 0.5118 - val_loss: 0.6913 - val_accuracy: 0.5118\n",
            "Epoch 20/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5159 - val_loss: 0.6910 - val_accuracy: 0.5028\n",
            "Epoch 21/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6909 - accuracy: 0.5138 - val_loss: 0.6908 - val_accuracy: 0.5138\n",
            "Epoch 22/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5114 - val_loss: 0.6908 - val_accuracy: 0.5128\n",
            "Epoch 23/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5134 - val_loss: 0.6908 - val_accuracy: 0.5103\n",
            "Epoch 24/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5173 - val_loss: 0.6903 - val_accuracy: 0.5108\n",
            "Epoch 25/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5110 - val_loss: 0.6919 - val_accuracy: 0.5053\n",
            "Epoch 26/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5125 - val_loss: 0.6913 - val_accuracy: 0.5153\n",
            "Epoch 27/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6908 - accuracy: 0.5145 - val_loss: 0.6911 - val_accuracy: 0.5043\n",
            "Epoch 28/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5152 - val_loss: 0.6902 - val_accuracy: 0.5163\n",
            "Epoch 29/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6906 - accuracy: 0.5175 - val_loss: 0.6916 - val_accuracy: 0.5108\n",
            "Epoch 30/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6908 - accuracy: 0.5138 - val_loss: 0.6908 - val_accuracy: 0.5073\n",
            "Epoch 31/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6905 - accuracy: 0.5118 - val_loss: 0.6906 - val_accuracy: 0.5118\n",
            "Epoch 32/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6899 - accuracy: 0.5125 - val_loss: 0.6922 - val_accuracy: 0.5043\n",
            "Epoch 33/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6904 - accuracy: 0.5135 - val_loss: 0.6916 - val_accuracy: 0.5138\n",
            "Epoch 34/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5124 - val_loss: 0.6902 - val_accuracy: 0.5113\n",
            "Epoch 35/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5132 - val_loss: 0.6920 - val_accuracy: 0.4992\n",
            "Epoch 36/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6910 - accuracy: 0.5146 - val_loss: 0.6908 - val_accuracy: 0.5003\n",
            "Epoch 37/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6903 - accuracy: 0.5111 - val_loss: 0.6908 - val_accuracy: 0.5128\n",
            "Epoch 38/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5099 - val_loss: 0.6906 - val_accuracy: 0.5173\n",
            "Epoch 39/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5135 - val_loss: 0.6904 - val_accuracy: 0.5048\n",
            "Epoch 40/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5130 - val_loss: 0.6918 - val_accuracy: 0.5073\n",
            "Epoch 41/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5146 - val_loss: 0.6921 - val_accuracy: 0.5063\n",
            "Epoch 42/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5176 - val_loss: 0.6914 - val_accuracy: 0.5118\n",
            "Epoch 43/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5165 - val_loss: 0.6902 - val_accuracy: 0.5083\n",
            "Epoch 44/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5153 - val_loss: 0.6914 - val_accuracy: 0.5108\n",
            "Epoch 45/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6899 - accuracy: 0.5124 - val_loss: 0.6904 - val_accuracy: 0.5018\n",
            "Epoch 46/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.5117 - val_loss: 0.6914 - val_accuracy: 0.5053\n",
            "Epoch 47/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5162 - val_loss: 0.6911 - val_accuracy: 0.5168\n",
            "Epoch 48/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5098\n",
            "Epoch 49/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5145 - val_loss: 0.6904 - val_accuracy: 0.5128\n",
            "Epoch 50/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5148 - val_loss: 0.6899 - val_accuracy: 0.5203\n",
            "Epoch 51/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5122 - val_loss: 0.6894 - val_accuracy: 0.5038\n",
            "Epoch 52/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5120 - val_loss: 0.6917 - val_accuracy: 0.5173\n",
            "Epoch 53/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5130 - val_loss: 0.6911 - val_accuracy: 0.5113\n",
            "Epoch 54/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5120 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
            "Epoch 55/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5151 - val_loss: 0.6902 - val_accuracy: 0.5133\n",
            "Epoch 56/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5137 - val_loss: 0.6911 - val_accuracy: 0.4987\n",
            "Epoch 57/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5150 - val_loss: 0.6908 - val_accuracy: 0.5133\n",
            "Epoch 58/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5139 - val_loss: 0.6916 - val_accuracy: 0.5053\n",
            "Epoch 59/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5102 - val_loss: 0.6908 - val_accuracy: 0.5013\n",
            "Epoch 60/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5137 - val_loss: 0.6909 - val_accuracy: 0.5083\n",
            "Epoch 61/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5209 - val_loss: 0.6911 - val_accuracy: 0.5138\n",
            "Epoch 62/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5171 - val_loss: 0.6933 - val_accuracy: 0.5083\n",
            "Epoch 63/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5144 - val_loss: 0.6901 - val_accuracy: 0.5168\n",
            "Epoch 64/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5184 - val_loss: 0.6898 - val_accuracy: 0.5013\n",
            "Epoch 65/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5133 - val_loss: 0.6915 - val_accuracy: 0.5098\n",
            "Epoch 66/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5156 - val_loss: 0.6900 - val_accuracy: 0.5243\n",
            "Epoch 67/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5169 - val_loss: 0.6903 - val_accuracy: 0.5068\n",
            "Epoch 68/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5183 - val_loss: 0.6914 - val_accuracy: 0.5123\n",
            "Epoch 69/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5132 - val_loss: 0.6905 - val_accuracy: 0.5068\n",
            "Epoch 70/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5166 - val_loss: 0.6914 - val_accuracy: 0.5083\n",
            "Epoch 71/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5101 - val_loss: 0.6909 - val_accuracy: 0.5243\n",
            "Epoch 72/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5114 - val_loss: 0.6900 - val_accuracy: 0.5103\n",
            "Epoch 73/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5161 - val_loss: 0.6889 - val_accuracy: 0.5278\n",
            "Epoch 74/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5157 - val_loss: 0.6889 - val_accuracy: 0.5108\n",
            "Epoch 75/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5165 - val_loss: 0.6902 - val_accuracy: 0.5103\n",
            "Epoch 76/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5128 - val_loss: 0.6918 - val_accuracy: 0.5098\n",
            "Epoch 77/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5156 - val_loss: 0.6899 - val_accuracy: 0.5238\n",
            "Epoch 78/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5126 - val_loss: 0.6904 - val_accuracy: 0.5153\n",
            "Epoch 79/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5127 - val_loss: 0.6903 - val_accuracy: 0.5178\n",
            "Epoch 80/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5165 - val_loss: 0.6894 - val_accuracy: 0.5173\n",
            "Epoch 81/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5160 - val_loss: 0.6903 - val_accuracy: 0.5173\n",
            "Epoch 82/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5203 - val_loss: 0.6933 - val_accuracy: 0.5123\n",
            "Epoch 83/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5134 - val_loss: 0.6910 - val_accuracy: 0.5033\n",
            "Epoch 84/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5150 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
            "Epoch 85/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5144 - val_loss: 0.6900 - val_accuracy: 0.5118\n",
            "Epoch 86/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5121 - val_loss: 0.6904 - val_accuracy: 0.5098\n",
            "Epoch 87/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5124 - val_loss: 0.6893 - val_accuracy: 0.5133\n",
            "Epoch 88/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5181 - val_loss: 0.6907 - val_accuracy: 0.5218\n",
            "Epoch 89/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5159 - val_loss: 0.6913 - val_accuracy: 0.5008\n",
            "Epoch 90/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5191 - val_loss: 0.6907 - val_accuracy: 0.5123\n",
            "Epoch 91/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5178 - val_loss: 0.6903 - val_accuracy: 0.5128\n",
            "Epoch 92/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5182 - val_loss: 0.6905 - val_accuracy: 0.5113\n",
            "Epoch 93/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5179 - val_loss: 0.6894 - val_accuracy: 0.5158\n",
            "Epoch 94/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5199 - val_loss: 0.6903 - val_accuracy: 0.5253\n",
            "Epoch 95/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5156 - val_loss: 0.6908 - val_accuracy: 0.5253\n",
            "Epoch 96/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5213 - val_loss: 0.6907 - val_accuracy: 0.5083\n",
            "Epoch 97/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5180 - val_loss: 0.6896 - val_accuracy: 0.5073\n",
            "Epoch 98/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5155 - val_loss: 0.6908 - val_accuracy: 0.5193\n",
            "Epoch 99/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5176 - val_loss: 0.6914 - val_accuracy: 0.5128\n",
            "Epoch 100/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5148 - val_loss: 0.6914 - val_accuracy: 0.5098\n",
            "Epoch 101/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5185 - val_loss: 0.6904 - val_accuracy: 0.5128\n",
            "Epoch 102/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5170 - val_loss: 0.6899 - val_accuracy: 0.5193\n",
            "Epoch 103/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5178 - val_loss: 0.6901 - val_accuracy: 0.5168\n",
            "Epoch 104/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5208 - val_loss: 0.6890 - val_accuracy: 0.5193\n",
            "Epoch 105/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5174 - val_loss: 0.6893 - val_accuracy: 0.5088\n",
            "Epoch 106/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5184 - val_loss: 0.6882 - val_accuracy: 0.5248\n",
            "Epoch 107/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5216 - val_loss: 0.6905 - val_accuracy: 0.5163\n",
            "Epoch 108/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5198 - val_loss: 0.6908 - val_accuracy: 0.5068\n",
            "Epoch 109/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5171 - val_loss: 0.6896 - val_accuracy: 0.5093\n",
            "Epoch 110/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.5174 - val_loss: 0.6911 - val_accuracy: 0.5183\n",
            "Epoch 111/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5126 - val_loss: 0.6900 - val_accuracy: 0.5173\n",
            "Epoch 112/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.5191 - val_loss: 0.6893 - val_accuracy: 0.5078\n",
            "Epoch 113/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5203 - val_loss: 0.6898 - val_accuracy: 0.5218\n",
            "Epoch 114/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5203 - val_loss: 0.6906 - val_accuracy: 0.5228\n",
            "Epoch 115/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5229 - val_loss: 0.6878 - val_accuracy: 0.5158\n",
            "Epoch 116/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5238\n",
            "Epoch 117/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.5221 - val_loss: 0.6897 - val_accuracy: 0.5228\n",
            "Epoch 118/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5177 - val_loss: 0.6891 - val_accuracy: 0.5108\n",
            "Epoch 119/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.5181 - val_loss: 0.6899 - val_accuracy: 0.5178\n",
            "Epoch 120/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5224 - val_loss: 0.6882 - val_accuracy: 0.5168\n",
            "Epoch 121/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5219 - val_loss: 0.6880 - val_accuracy: 0.5153\n",
            "Epoch 122/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5236 - val_loss: 0.6904 - val_accuracy: 0.5123\n",
            "Epoch 123/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5246 - val_loss: 0.6918 - val_accuracy: 0.5223\n",
            "Epoch 124/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5209 - val_loss: 0.6905 - val_accuracy: 0.5173\n",
            "Epoch 125/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
            "Epoch 126/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5228 - val_loss: 0.6895 - val_accuracy: 0.5163\n",
            "Epoch 127/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5221 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
            "Epoch 128/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5211 - val_loss: 0.6888 - val_accuracy: 0.5238\n",
            "Epoch 129/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5167 - val_loss: 0.6900 - val_accuracy: 0.5108\n",
            "Epoch 130/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5164 - val_loss: 0.6903 - val_accuracy: 0.5153\n",
            "Epoch 131/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5205 - val_loss: 0.6904 - val_accuracy: 0.5193\n",
            "Epoch 132/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.5200 - val_loss: 0.6884 - val_accuracy: 0.5158\n",
            "Epoch 133/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.5212 - val_loss: 0.6894 - val_accuracy: 0.5253\n",
            "Epoch 134/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5247 - val_loss: 0.6903 - val_accuracy: 0.5113\n",
            "Epoch 135/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.5198 - val_loss: 0.6902 - val_accuracy: 0.5163\n",
            "Epoch 136/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5180 - val_loss: 0.6913 - val_accuracy: 0.5123\n",
            "Epoch 137/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5223 - val_loss: 0.6910 - val_accuracy: 0.5103\n",
            "Epoch 138/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5181 - val_loss: 0.6881 - val_accuracy: 0.5128\n",
            "Epoch 139/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5219 - val_loss: 0.6884 - val_accuracy: 0.5198\n",
            "Epoch 140/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5280 - val_loss: 0.6939 - val_accuracy: 0.5223\n",
            "Epoch 141/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5254 - val_loss: 0.6905 - val_accuracy: 0.5088\n",
            "Epoch 142/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5185 - val_loss: 0.6907 - val_accuracy: 0.5168\n",
            "Epoch 143/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5226 - val_loss: 0.6883 - val_accuracy: 0.5168\n",
            "Epoch 144/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5279 - val_loss: 0.6904 - val_accuracy: 0.5153\n",
            "Epoch 145/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5239 - val_loss: 0.6897 - val_accuracy: 0.5118\n",
            "Epoch 146/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5194 - val_loss: 0.6885 - val_accuracy: 0.5148\n",
            "Epoch 147/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5227 - val_loss: 0.6885 - val_accuracy: 0.5203\n",
            "Epoch 148/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5164 - val_loss: 0.6899 - val_accuracy: 0.5193\n",
            "Epoch 149/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5252 - val_loss: 0.6892 - val_accuracy: 0.5248\n",
            "Epoch 150/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5221 - val_loss: 0.6900 - val_accuracy: 0.5153\n",
            "Epoch 151/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5208 - val_loss: 0.6892 - val_accuracy: 0.5183\n",
            "Epoch 152/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5219 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
            "Epoch 153/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5240 - val_loss: 0.6886 - val_accuracy: 0.5193\n",
            "Epoch 154/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5241 - val_loss: 0.6874 - val_accuracy: 0.5143\n",
            "Epoch 155/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5219 - val_loss: 0.6897 - val_accuracy: 0.5208\n",
            "Epoch 156/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5261 - val_loss: 0.6883 - val_accuracy: 0.5153\n",
            "Epoch 157/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5189 - val_loss: 0.6896 - val_accuracy: 0.5248\n",
            "Epoch 158/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5210 - val_loss: 0.6910 - val_accuracy: 0.5143\n",
            "Epoch 159/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5225 - val_loss: 0.6896 - val_accuracy: 0.5173\n",
            "Epoch 160/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5250 - val_loss: 0.6902 - val_accuracy: 0.5253\n",
            "Epoch 161/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5238 - val_loss: 0.6893 - val_accuracy: 0.5248\n",
            "Epoch 162/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5228 - val_loss: 0.6889 - val_accuracy: 0.5243\n",
            "Epoch 163/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5272 - val_loss: 0.6888 - val_accuracy: 0.5253\n",
            "Epoch 164/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5281 - val_loss: 0.6886 - val_accuracy: 0.5283\n",
            "Epoch 165/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5249 - val_loss: 0.6880 - val_accuracy: 0.5218\n",
            "Epoch 166/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5215 - val_loss: 0.6889 - val_accuracy: 0.5273\n",
            "Epoch 167/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.5237 - val_loss: 0.6895 - val_accuracy: 0.5273\n",
            "Epoch 168/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5214 - val_loss: 0.6891 - val_accuracy: 0.5248\n",
            "Epoch 169/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5241 - val_loss: 0.6902 - val_accuracy: 0.5218\n",
            "Epoch 170/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5275 - val_loss: 0.6917 - val_accuracy: 0.5123\n",
            "Epoch 171/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5242 - val_loss: 0.6892 - val_accuracy: 0.5213\n",
            "Epoch 172/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5254 - val_loss: 0.6896 - val_accuracy: 0.5178\n",
            "Epoch 173/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5264 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
            "Epoch 174/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5264 - val_loss: 0.6892 - val_accuracy: 0.5173\n",
            "Epoch 175/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5257 - val_loss: 0.6876 - val_accuracy: 0.5278\n",
            "Epoch 176/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5168\n",
            "Epoch 177/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5213 - val_loss: 0.6898 - val_accuracy: 0.5153\n",
            "Epoch 178/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5244 - val_loss: 0.6898 - val_accuracy: 0.5248\n",
            "Epoch 179/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5244 - val_loss: 0.6900 - val_accuracy: 0.5158\n",
            "Epoch 180/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5233 - val_loss: 0.6892 - val_accuracy: 0.5103\n",
            "Epoch 181/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5231 - val_loss: 0.6894 - val_accuracy: 0.5128\n",
            "Epoch 182/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5208 - val_loss: 0.6869 - val_accuracy: 0.5268\n",
            "Epoch 183/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5254 - val_loss: 0.6892 - val_accuracy: 0.5218\n",
            "Epoch 184/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5283 - val_loss: 0.6879 - val_accuracy: 0.5248\n",
            "Epoch 185/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5242 - val_loss: 0.6873 - val_accuracy: 0.5268\n",
            "Epoch 186/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5229 - val_loss: 0.6897 - val_accuracy: 0.5223\n",
            "Epoch 187/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5242 - val_loss: 0.6879 - val_accuracy: 0.5248\n",
            "Epoch 188/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5259 - val_loss: 0.6880 - val_accuracy: 0.5158\n",
            "Epoch 189/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5230 - val_loss: 0.6904 - val_accuracy: 0.5163\n",
            "Epoch 190/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5237 - val_loss: 0.6901 - val_accuracy: 0.5238\n",
            "Epoch 191/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5260 - val_loss: 0.6893 - val_accuracy: 0.5248\n",
            "Epoch 192/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5216 - val_loss: 0.6907 - val_accuracy: 0.5193\n",
            "Epoch 193/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5305 - val_loss: 0.6896 - val_accuracy: 0.5248\n",
            "Epoch 194/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5253 - val_loss: 0.6908 - val_accuracy: 0.5138\n",
            "Epoch 195/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5299 - val_loss: 0.6879 - val_accuracy: 0.5273\n",
            "Epoch 196/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5226 - val_loss: 0.6900 - val_accuracy: 0.5193\n",
            "Epoch 197/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5248 - val_loss: 0.6890 - val_accuracy: 0.5188\n",
            "Epoch 198/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5225 - val_loss: 0.6908 - val_accuracy: 0.5263\n",
            "Epoch 199/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5233 - val_loss: 0.6892 - val_accuracy: 0.5133\n",
            "Epoch 200/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5242 - val_loss: 0.6880 - val_accuracy: 0.5118\n",
            "Epoch 201/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5280 - val_loss: 0.6890 - val_accuracy: 0.5233\n",
            "Epoch 202/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5286 - val_loss: 0.6888 - val_accuracy: 0.5273\n",
            "Epoch 203/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5271 - val_loss: 0.6891 - val_accuracy: 0.5288\n",
            "Epoch 204/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5237 - val_loss: 0.6891 - val_accuracy: 0.5148\n",
            "Epoch 205/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5281 - val_loss: 0.6896 - val_accuracy: 0.5258\n",
            "Epoch 206/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5304 - val_loss: 0.6887 - val_accuracy: 0.5173\n",
            "Epoch 207/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5273 - val_loss: 0.6889 - val_accuracy: 0.5158\n",
            "Epoch 208/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5253 - val_loss: 0.6885 - val_accuracy: 0.5243\n",
            "Epoch 209/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5263 - val_loss: 0.6886 - val_accuracy: 0.5263\n",
            "Epoch 210/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5259 - val_loss: 0.6914 - val_accuracy: 0.5208\n",
            "Epoch 211/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5262 - val_loss: 0.6894 - val_accuracy: 0.5183\n",
            "Epoch 212/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5253 - val_loss: 0.6883 - val_accuracy: 0.5248\n",
            "Epoch 213/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5238 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
            "Epoch 214/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5268 - val_loss: 0.6901 - val_accuracy: 0.5148\n",
            "Epoch 215/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5276 - val_loss: 0.6899 - val_accuracy: 0.5168\n",
            "Epoch 216/1000\n",
            "561/561 [==============================] - 1s 3ms/step - loss: 0.6888 - accuracy: 0.5243 - val_loss: 0.6908 - val_accuracy: 0.5168\n",
            "Epoch 217/1000\n",
            "561/561 [==============================] - 1s 3ms/step - loss: 0.6878 - accuracy: 0.5269 - val_loss: 0.6892 - val_accuracy: 0.5203\n",
            "Epoch 218/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5322 - val_loss: 0.6896 - val_accuracy: 0.5138\n",
            "Epoch 219/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5193\n",
            "Epoch 220/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5258 - val_loss: 0.6872 - val_accuracy: 0.5163\n",
            "Epoch 221/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5254 - val_loss: 0.6896 - val_accuracy: 0.5258\n",
            "Epoch 222/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5282 - val_loss: 0.6891 - val_accuracy: 0.5228\n",
            "Epoch 223/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5238 - val_loss: 0.6886 - val_accuracy: 0.5308\n",
            "Epoch 224/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5263 - val_loss: 0.6898 - val_accuracy: 0.5228\n",
            "Epoch 225/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5268 - val_loss: 0.6894 - val_accuracy: 0.5238\n",
            "Epoch 226/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5253 - val_loss: 0.6905 - val_accuracy: 0.5238\n",
            "Epoch 227/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5269 - val_loss: 0.6889 - val_accuracy: 0.5183\n",
            "Epoch 228/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5242 - val_loss: 0.6896 - val_accuracy: 0.5293\n",
            "Epoch 229/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5291 - val_loss: 0.6893 - val_accuracy: 0.5323\n",
            "Epoch 230/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5252 - val_loss: 0.6899 - val_accuracy: 0.5208\n",
            "Epoch 231/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5292 - val_loss: 0.6893 - val_accuracy: 0.5208\n",
            "Epoch 232/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5258 - val_loss: 0.6882 - val_accuracy: 0.5283\n",
            "Epoch 233/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5277 - val_loss: 0.6892 - val_accuracy: 0.5233\n",
            "Epoch 234/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5274 - val_loss: 0.6908 - val_accuracy: 0.5243\n",
            "Epoch 235/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5247 - val_loss: 0.6900 - val_accuracy: 0.5223\n",
            "Epoch 236/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5297 - val_loss: 0.6892 - val_accuracy: 0.5223\n",
            "Epoch 237/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5298 - val_loss: 0.6882 - val_accuracy: 0.5243\n",
            "Epoch 238/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5272 - val_loss: 0.6903 - val_accuracy: 0.5233\n",
            "Epoch 239/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5273 - val_loss: 0.6911 - val_accuracy: 0.5228\n",
            "Epoch 240/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5229 - val_loss: 0.6896 - val_accuracy: 0.5253\n",
            "Epoch 241/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5291 - val_loss: 0.6898 - val_accuracy: 0.5273\n",
            "Epoch 242/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5224 - val_loss: 0.6882 - val_accuracy: 0.5243\n",
            "Epoch 243/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5288 - val_loss: 0.6886 - val_accuracy: 0.5258\n",
            "Epoch 244/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5303 - val_loss: 0.6870 - val_accuracy: 0.5223\n",
            "Epoch 245/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5289 - val_loss: 0.6903 - val_accuracy: 0.5383\n",
            "Epoch 246/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5292 - val_loss: 0.6897 - val_accuracy: 0.5243\n",
            "Epoch 247/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5277 - val_loss: 0.6898 - val_accuracy: 0.5178\n",
            "Epoch 248/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5266 - val_loss: 0.6888 - val_accuracy: 0.5258\n",
            "Epoch 249/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5274 - val_loss: 0.6895 - val_accuracy: 0.5233\n",
            "Epoch 250/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5240 - val_loss: 0.6894 - val_accuracy: 0.5173\n",
            "Epoch 251/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5310 - val_loss: 0.6879 - val_accuracy: 0.5208\n",
            "Epoch 252/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5296 - val_loss: 0.6890 - val_accuracy: 0.5243\n",
            "Epoch 253/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5267 - val_loss: 0.6898 - val_accuracy: 0.5153\n",
            "Epoch 254/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5271 - val_loss: 0.6880 - val_accuracy: 0.5228\n",
            "Epoch 255/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5297 - val_loss: 0.6902 - val_accuracy: 0.5213\n",
            "Epoch 256/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5300 - val_loss: 0.6895 - val_accuracy: 0.5223\n",
            "Epoch 257/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5284 - val_loss: 0.6908 - val_accuracy: 0.5183\n",
            "Epoch 258/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5276 - val_loss: 0.6872 - val_accuracy: 0.5308\n",
            "Epoch 259/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5278 - val_loss: 0.6894 - val_accuracy: 0.5268\n",
            "Epoch 260/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5282 - val_loss: 0.6878 - val_accuracy: 0.5278\n",
            "Epoch 261/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5292 - val_loss: 0.6892 - val_accuracy: 0.5253\n",
            "Epoch 262/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5322 - val_loss: 0.6882 - val_accuracy: 0.5273\n",
            "Epoch 263/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5276 - val_loss: 0.6892 - val_accuracy: 0.5213\n",
            "Epoch 264/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5279 - val_loss: 0.6910 - val_accuracy: 0.5273\n",
            "Epoch 265/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5219 - val_loss: 0.6870 - val_accuracy: 0.5363\n",
            "Epoch 266/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5263 - val_loss: 0.6904 - val_accuracy: 0.5308\n",
            "Epoch 267/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5240 - val_loss: 0.6903 - val_accuracy: 0.5258\n",
            "Epoch 268/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5252 - val_loss: 0.6895 - val_accuracy: 0.5303\n",
            "Epoch 269/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5283 - val_loss: 0.6896 - val_accuracy: 0.5203\n",
            "Epoch 270/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5290 - val_loss: 0.6877 - val_accuracy: 0.5238\n",
            "Epoch 271/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5286 - val_loss: 0.6880 - val_accuracy: 0.5233\n",
            "Epoch 272/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5255 - val_loss: 0.6880 - val_accuracy: 0.5253\n",
            "Epoch 273/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5236 - val_loss: 0.6900 - val_accuracy: 0.5213\n",
            "Epoch 274/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5269 - val_loss: 0.6904 - val_accuracy: 0.5233\n",
            "Epoch 275/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5237 - val_loss: 0.6882 - val_accuracy: 0.5283\n",
            "Epoch 276/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5281 - val_loss: 0.6890 - val_accuracy: 0.5278\n",
            "Epoch 277/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5274 - val_loss: 0.6902 - val_accuracy: 0.5353\n",
            "Epoch 278/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5256 - val_loss: 0.6927 - val_accuracy: 0.5173\n",
            "Epoch 279/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5284 - val_loss: 0.6896 - val_accuracy: 0.5228\n",
            "Epoch 280/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5306 - val_loss: 0.6903 - val_accuracy: 0.5208\n",
            "Epoch 281/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5227 - val_loss: 0.6897 - val_accuracy: 0.5273\n",
            "Epoch 282/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5270 - val_loss: 0.6888 - val_accuracy: 0.5293\n",
            "Epoch 283/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5275 - val_loss: 0.6906 - val_accuracy: 0.5178\n",
            "Epoch 284/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5273 - val_loss: 0.6896 - val_accuracy: 0.5218\n",
            "Epoch 285/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5263 - val_loss: 0.6907 - val_accuracy: 0.5253\n",
            "Epoch 286/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5254 - val_loss: 0.6899 - val_accuracy: 0.5238\n",
            "Epoch 287/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5265 - val_loss: 0.6881 - val_accuracy: 0.5278\n",
            "Epoch 288/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5263 - val_loss: 0.6874 - val_accuracy: 0.5303\n",
            "Epoch 289/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5262 - val_loss: 0.6887 - val_accuracy: 0.5308\n",
            "Epoch 290/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5291 - val_loss: 0.6878 - val_accuracy: 0.5258\n",
            "Epoch 291/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5297 - val_loss: 0.6892 - val_accuracy: 0.5253\n",
            "Epoch 292/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5278 - val_loss: 0.6870 - val_accuracy: 0.5283\n",
            "Epoch 293/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5247 - val_loss: 0.6894 - val_accuracy: 0.5158\n",
            "Epoch 294/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5283\n",
            "Epoch 295/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5293 - val_loss: 0.6892 - val_accuracy: 0.5248\n",
            "Epoch 296/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5260 - val_loss: 0.6888 - val_accuracy: 0.5223\n",
            "Epoch 297/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5272 - val_loss: 0.6906 - val_accuracy: 0.5203\n",
            "Epoch 298/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5268 - val_loss: 0.6894 - val_accuracy: 0.5253\n",
            "Epoch 299/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5250 - val_loss: 0.6895 - val_accuracy: 0.5193\n",
            "Epoch 300/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5273 - val_loss: 0.6882 - val_accuracy: 0.5293\n",
            "Epoch 301/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5293\n",
            "Epoch 302/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5303 - val_loss: 0.6906 - val_accuracy: 0.5158\n",
            "Epoch 303/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5302 - val_loss: 0.6885 - val_accuracy: 0.5283\n",
            "Epoch 304/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5250 - val_loss: 0.6880 - val_accuracy: 0.5278\n",
            "Epoch 305/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5318 - val_loss: 0.6898 - val_accuracy: 0.5198\n",
            "Epoch 306/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5309 - val_loss: 0.6902 - val_accuracy: 0.5253\n",
            "Epoch 307/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5305 - val_loss: 0.6893 - val_accuracy: 0.5198\n",
            "Epoch 308/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5276 - val_loss: 0.6884 - val_accuracy: 0.5308\n",
            "Epoch 309/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5272 - val_loss: 0.6863 - val_accuracy: 0.5273\n",
            "Epoch 310/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5303 - val_loss: 0.6898 - val_accuracy: 0.5253\n",
            "Epoch 311/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5305 - val_loss: 0.6868 - val_accuracy: 0.5218\n",
            "Epoch 312/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5292 - val_loss: 0.6900 - val_accuracy: 0.5253\n",
            "Epoch 313/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5263 - val_loss: 0.6908 - val_accuracy: 0.5098\n",
            "Epoch 314/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5272 - val_loss: 0.6894 - val_accuracy: 0.5113\n",
            "Epoch 315/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5320 - val_loss: 0.6890 - val_accuracy: 0.5328\n",
            "Epoch 316/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5231 - val_loss: 0.6895 - val_accuracy: 0.5263\n",
            "Epoch 317/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5294 - val_loss: 0.6883 - val_accuracy: 0.5333\n",
            "Epoch 318/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5287 - val_loss: 0.6904 - val_accuracy: 0.5313\n",
            "Epoch 319/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5297 - val_loss: 0.6887 - val_accuracy: 0.5218\n",
            "Epoch 320/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5286 - val_loss: 0.6891 - val_accuracy: 0.5248\n",
            "Epoch 321/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5279 - val_loss: 0.6894 - val_accuracy: 0.5178\n",
            "Epoch 322/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5265 - val_loss: 0.6887 - val_accuracy: 0.5298\n",
            "Epoch 323/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5274 - val_loss: 0.6892 - val_accuracy: 0.5273\n",
            "Epoch 324/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5273 - val_loss: 0.6893 - val_accuracy: 0.5283\n",
            "Epoch 325/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5282 - val_loss: 0.6897 - val_accuracy: 0.5173\n",
            "Epoch 326/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5276 - val_loss: 0.6894 - val_accuracy: 0.5283\n",
            "Epoch 327/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5267 - val_loss: 0.6902 - val_accuracy: 0.5208\n",
            "Epoch 328/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5281 - val_loss: 0.6912 - val_accuracy: 0.5338\n",
            "Epoch 329/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5276 - val_loss: 0.6903 - val_accuracy: 0.5203\n",
            "Epoch 330/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5279 - val_loss: 0.6891 - val_accuracy: 0.5208\n",
            "Epoch 331/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5288 - val_loss: 0.6876 - val_accuracy: 0.5248\n",
            "Epoch 332/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5264 - val_loss: 0.6889 - val_accuracy: 0.5178\n",
            "Epoch 333/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5253 - val_loss: 0.6898 - val_accuracy: 0.5218\n",
            "Epoch 334/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5276 - val_loss: 0.6894 - val_accuracy: 0.5213\n",
            "Epoch 335/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5310 - val_loss: 0.6891 - val_accuracy: 0.5208\n",
            "Epoch 336/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5262 - val_loss: 0.6891 - val_accuracy: 0.5333\n",
            "Epoch 337/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5303 - val_loss: 0.6898 - val_accuracy: 0.5298\n",
            "Epoch 338/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5269 - val_loss: 0.6902 - val_accuracy: 0.5198\n",
            "Epoch 339/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5302 - val_loss: 0.6900 - val_accuracy: 0.5233\n",
            "Epoch 340/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5281 - val_loss: 0.6881 - val_accuracy: 0.5173\n",
            "Epoch 341/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5270 - val_loss: 0.6895 - val_accuracy: 0.5203\n",
            "Epoch 342/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5258 - val_loss: 0.6891 - val_accuracy: 0.5248\n",
            "Epoch 343/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5301 - val_loss: 0.6886 - val_accuracy: 0.5248\n",
            "Epoch 344/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5270 - val_loss: 0.6888 - val_accuracy: 0.5233\n",
            "Epoch 345/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5260 - val_loss: 0.6901 - val_accuracy: 0.5278\n",
            "Epoch 346/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5259 - val_loss: 0.6905 - val_accuracy: 0.5183\n",
            "Epoch 347/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5254 - val_loss: 0.6906 - val_accuracy: 0.5203\n",
            "Epoch 348/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5278 - val_loss: 0.6893 - val_accuracy: 0.5233\n",
            "Epoch 349/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5284 - val_loss: 0.6881 - val_accuracy: 0.5238\n",
            "Epoch 350/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5299 - val_loss: 0.6898 - val_accuracy: 0.5273\n",
            "Epoch 351/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5278 - val_loss: 0.6897 - val_accuracy: 0.5158\n",
            "Epoch 352/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5320 - val_loss: 0.6897 - val_accuracy: 0.5253\n",
            "Epoch 353/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5294 - val_loss: 0.6896 - val_accuracy: 0.5263\n",
            "Epoch 354/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5295 - val_loss: 0.6882 - val_accuracy: 0.5303\n",
            "Epoch 355/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5255 - val_loss: 0.6894 - val_accuracy: 0.5213\n",
            "Epoch 356/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5313 - val_loss: 0.6881 - val_accuracy: 0.5373\n",
            "Epoch 357/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5276 - val_loss: 0.6888 - val_accuracy: 0.5243\n",
            "Epoch 358/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5270 - val_loss: 0.6887 - val_accuracy: 0.5233\n",
            "Epoch 359/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5312 - val_loss: 0.6897 - val_accuracy: 0.5198\n",
            "Epoch 360/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5284 - val_loss: 0.6891 - val_accuracy: 0.5258\n",
            "Epoch 361/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5299 - val_loss: 0.6889 - val_accuracy: 0.5208\n",
            "Epoch 362/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5265 - val_loss: 0.6893 - val_accuracy: 0.5363\n",
            "Epoch 363/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5296 - val_loss: 0.6876 - val_accuracy: 0.5203\n",
            "Epoch 364/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5282 - val_loss: 0.6884 - val_accuracy: 0.5208\n",
            "Epoch 365/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5312 - val_loss: 0.6892 - val_accuracy: 0.5253\n",
            "Epoch 366/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5288 - val_loss: 0.6905 - val_accuracy: 0.5198\n",
            "Epoch 367/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5289 - val_loss: 0.6873 - val_accuracy: 0.5338\n",
            "Epoch 368/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5303 - val_loss: 0.6879 - val_accuracy: 0.5278\n",
            "Epoch 369/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5281 - val_loss: 0.6879 - val_accuracy: 0.5278\n",
            "Epoch 370/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5311 - val_loss: 0.6879 - val_accuracy: 0.5308\n",
            "Epoch 371/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5286 - val_loss: 0.6880 - val_accuracy: 0.5213\n",
            "Epoch 372/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5307 - val_loss: 0.6876 - val_accuracy: 0.5263\n",
            "Epoch 373/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5265 - val_loss: 0.6898 - val_accuracy: 0.5238\n",
            "Epoch 374/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5307 - val_loss: 0.6888 - val_accuracy: 0.5188\n",
            "Epoch 375/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5294 - val_loss: 0.6877 - val_accuracy: 0.5228\n",
            "Epoch 376/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5293 - val_loss: 0.6887 - val_accuracy: 0.5338\n",
            "Epoch 377/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5310 - val_loss: 0.6896 - val_accuracy: 0.5263\n",
            "Epoch 378/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5305 - val_loss: 0.6906 - val_accuracy: 0.5258\n",
            "Epoch 379/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5278 - val_loss: 0.6891 - val_accuracy: 0.5208\n",
            "Epoch 380/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5303 - val_loss: 0.6898 - val_accuracy: 0.5178\n",
            "Epoch 381/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5288 - val_loss: 0.6882 - val_accuracy: 0.5263\n",
            "Epoch 382/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5297 - val_loss: 0.6897 - val_accuracy: 0.5248\n",
            "Epoch 383/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5272 - val_loss: 0.6925 - val_accuracy: 0.5268\n",
            "Epoch 384/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5343 - val_loss: 0.6893 - val_accuracy: 0.5323\n",
            "Epoch 385/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5287 - val_loss: 0.6895 - val_accuracy: 0.5258\n",
            "Epoch 386/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5297 - val_loss: 0.6892 - val_accuracy: 0.5183\n",
            "Epoch 387/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5309 - val_loss: 0.6880 - val_accuracy: 0.5278\n",
            "Epoch 388/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5292 - val_loss: 0.6893 - val_accuracy: 0.5323\n",
            "Epoch 389/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5255 - val_loss: 0.6869 - val_accuracy: 0.5263\n",
            "Epoch 390/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5264 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
            "Epoch 391/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5289 - val_loss: 0.6887 - val_accuracy: 0.5308\n",
            "Epoch 392/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5285 - val_loss: 0.6897 - val_accuracy: 0.5268\n",
            "Epoch 393/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5307 - val_loss: 0.6891 - val_accuracy: 0.5228\n",
            "Epoch 394/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5346 - val_loss: 0.6873 - val_accuracy: 0.5323\n",
            "Epoch 395/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5282 - val_loss: 0.6909 - val_accuracy: 0.5178\n",
            "Epoch 396/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5304 - val_loss: 0.6898 - val_accuracy: 0.5213\n",
            "Epoch 397/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5365 - val_loss: 0.6889 - val_accuracy: 0.5268\n",
            "Epoch 398/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5339 - val_loss: 0.6887 - val_accuracy: 0.5248\n",
            "Epoch 399/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5320 - val_loss: 0.6885 - val_accuracy: 0.5298\n",
            "Epoch 400/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5293 - val_loss: 0.6895 - val_accuracy: 0.5323\n",
            "Epoch 401/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5291 - val_loss: 0.6891 - val_accuracy: 0.5328\n",
            "Epoch 402/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5323 - val_loss: 0.6893 - val_accuracy: 0.5163\n",
            "Epoch 403/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5293 - val_loss: 0.6912 - val_accuracy: 0.5243\n",
            "Epoch 404/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5320 - val_loss: 0.6874 - val_accuracy: 0.5263\n",
            "Epoch 405/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5292 - val_loss: 0.6909 - val_accuracy: 0.5188\n",
            "Epoch 406/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5313 - val_loss: 0.6903 - val_accuracy: 0.5283\n",
            "Epoch 407/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5290 - val_loss: 0.6874 - val_accuracy: 0.5233\n",
            "Epoch 408/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5283 - val_loss: 0.6897 - val_accuracy: 0.5193\n",
            "Epoch 409/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5272 - val_loss: 0.6900 - val_accuracy: 0.5193\n",
            "Epoch 410/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5339 - val_loss: 0.6910 - val_accuracy: 0.5048\n",
            "Epoch 411/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5299 - val_loss: 0.6879 - val_accuracy: 0.5283\n",
            "Epoch 412/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5291 - val_loss: 0.6905 - val_accuracy: 0.5258\n",
            "Epoch 413/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5329 - val_loss: 0.6894 - val_accuracy: 0.5208\n",
            "Epoch 414/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5313 - val_loss: 0.6889 - val_accuracy: 0.5303\n",
            "Epoch 415/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5293 - val_loss: 0.6884 - val_accuracy: 0.5303\n",
            "Epoch 416/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5318 - val_loss: 0.6868 - val_accuracy: 0.5278\n",
            "Epoch 417/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5331 - val_loss: 0.6892 - val_accuracy: 0.5298\n",
            "Epoch 418/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5263 - val_loss: 0.6876 - val_accuracy: 0.5238\n",
            "Epoch 419/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5293 - val_loss: 0.6879 - val_accuracy: 0.5298\n",
            "Epoch 420/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5316 - val_loss: 0.6895 - val_accuracy: 0.5158\n",
            "Epoch 421/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5307 - val_loss: 0.6894 - val_accuracy: 0.5323\n",
            "Epoch 422/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5283 - val_loss: 0.6891 - val_accuracy: 0.5288\n",
            "Epoch 423/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5294 - val_loss: 0.6898 - val_accuracy: 0.5173\n",
            "Epoch 424/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5322 - val_loss: 0.6891 - val_accuracy: 0.5363\n",
            "Epoch 425/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5309 - val_loss: 0.6906 - val_accuracy: 0.5243\n",
            "Epoch 426/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5293 - val_loss: 0.6898 - val_accuracy: 0.5248\n",
            "Epoch 427/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5318 - val_loss: 0.6899 - val_accuracy: 0.5248\n",
            "Epoch 428/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5273 - val_loss: 0.6894 - val_accuracy: 0.5293\n",
            "Epoch 429/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5283 - val_loss: 0.6889 - val_accuracy: 0.5248\n",
            "Epoch 430/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5283 - val_loss: 0.6872 - val_accuracy: 0.5373\n",
            "Epoch 431/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5272 - val_loss: 0.6896 - val_accuracy: 0.5143\n",
            "Epoch 432/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5330 - val_loss: 0.6891 - val_accuracy: 0.5208\n",
            "Epoch 433/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5312 - val_loss: 0.6894 - val_accuracy: 0.5193\n",
            "Epoch 434/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5286 - val_loss: 0.6892 - val_accuracy: 0.5293\n",
            "Epoch 435/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5315 - val_loss: 0.6884 - val_accuracy: 0.5313\n",
            "Epoch 436/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5293 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
            "Epoch 437/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5328 - val_loss: 0.6890 - val_accuracy: 0.5168\n",
            "Epoch 438/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5288 - val_loss: 0.6892 - val_accuracy: 0.5243\n",
            "Epoch 439/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5306 - val_loss: 0.6894 - val_accuracy: 0.5323\n",
            "Epoch 440/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5293 - val_loss: 0.6896 - val_accuracy: 0.5353\n",
            "Epoch 441/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5308 - val_loss: 0.6883 - val_accuracy: 0.5288\n",
            "Epoch 442/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5306 - val_loss: 0.6890 - val_accuracy: 0.5238\n",
            "Epoch 443/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5307 - val_loss: 0.6880 - val_accuracy: 0.5253\n",
            "Epoch 444/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5308 - val_loss: 0.6906 - val_accuracy: 0.5153\n",
            "Epoch 445/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5291 - val_loss: 0.6910 - val_accuracy: 0.5258\n",
            "Epoch 446/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5306 - val_loss: 0.6897 - val_accuracy: 0.5218\n",
            "Epoch 447/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5275 - val_loss: 0.6873 - val_accuracy: 0.5328\n",
            "Epoch 448/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5323 - val_loss: 0.6880 - val_accuracy: 0.5163\n",
            "Epoch 449/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5256 - val_loss: 0.6885 - val_accuracy: 0.5188\n",
            "Epoch 450/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5310 - val_loss: 0.6898 - val_accuracy: 0.5228\n",
            "Epoch 451/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5286 - val_loss: 0.6900 - val_accuracy: 0.5203\n",
            "Epoch 452/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5264 - val_loss: 0.6905 - val_accuracy: 0.5263\n",
            "Epoch 453/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5286 - val_loss: 0.6890 - val_accuracy: 0.5303\n",
            "Epoch 454/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5332 - val_loss: 0.6870 - val_accuracy: 0.5268\n",
            "Epoch 455/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5302 - val_loss: 0.6871 - val_accuracy: 0.5313\n",
            "Epoch 456/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5304 - val_loss: 0.6871 - val_accuracy: 0.5243\n",
            "Epoch 457/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5308 - val_loss: 0.6886 - val_accuracy: 0.5278\n",
            "Epoch 458/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5248 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
            "Epoch 459/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5253 - val_loss: 0.6880 - val_accuracy: 0.5233\n",
            "Epoch 460/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5318 - val_loss: 0.6870 - val_accuracy: 0.5293\n",
            "Epoch 461/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5322 - val_loss: 0.6896 - val_accuracy: 0.5198\n",
            "Epoch 462/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5284 - val_loss: 0.6904 - val_accuracy: 0.5308\n",
            "Epoch 463/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5265 - val_loss: 0.6882 - val_accuracy: 0.5348\n",
            "Epoch 464/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5315 - val_loss: 0.6893 - val_accuracy: 0.5208\n",
            "Epoch 465/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5270 - val_loss: 0.6881 - val_accuracy: 0.5303\n",
            "Epoch 466/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5341 - val_loss: 0.6871 - val_accuracy: 0.5213\n",
            "Epoch 467/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5318 - val_loss: 0.6900 - val_accuracy: 0.5248\n",
            "Epoch 468/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5325 - val_loss: 0.6879 - val_accuracy: 0.5358\n",
            "Epoch 469/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5311 - val_loss: 0.6879 - val_accuracy: 0.5208\n",
            "Epoch 470/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5359 - val_loss: 0.6904 - val_accuracy: 0.5268\n",
            "Epoch 471/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5294 - val_loss: 0.6905 - val_accuracy: 0.5178\n",
            "Epoch 472/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5342 - val_loss: 0.6871 - val_accuracy: 0.5248\n",
            "Epoch 473/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5310 - val_loss: 0.6903 - val_accuracy: 0.5278\n",
            "Epoch 474/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5315 - val_loss: 0.6880 - val_accuracy: 0.5233\n",
            "Epoch 475/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5283 - val_loss: 0.6865 - val_accuracy: 0.5383\n",
            "Epoch 476/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5286 - val_loss: 0.6898 - val_accuracy: 0.5188\n",
            "Epoch 477/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5299 - val_loss: 0.6888 - val_accuracy: 0.5253\n",
            "Epoch 478/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5325 - val_loss: 0.6883 - val_accuracy: 0.5348\n",
            "Epoch 479/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5284 - val_loss: 0.6895 - val_accuracy: 0.5218\n",
            "Epoch 480/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5311 - val_loss: 0.6878 - val_accuracy: 0.5203\n",
            "Epoch 481/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5333 - val_loss: 0.6881 - val_accuracy: 0.5348\n",
            "Epoch 482/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5304 - val_loss: 0.6900 - val_accuracy: 0.5243\n",
            "Epoch 483/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5296 - val_loss: 0.6892 - val_accuracy: 0.5303\n",
            "Epoch 484/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5289 - val_loss: 0.6915 - val_accuracy: 0.5153\n",
            "Epoch 485/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5286 - val_loss: 0.6902 - val_accuracy: 0.5183\n",
            "Epoch 486/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5315 - val_loss: 0.6882 - val_accuracy: 0.5243\n",
            "Epoch 487/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5275 - val_loss: 0.6907 - val_accuracy: 0.5238\n",
            "Epoch 488/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5276 - val_loss: 0.6889 - val_accuracy: 0.5343\n",
            "Epoch 489/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5359 - val_loss: 0.6886 - val_accuracy: 0.5288\n",
            "Epoch 490/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5358 - val_loss: 0.6897 - val_accuracy: 0.5253\n",
            "Epoch 491/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5331 - val_loss: 0.6890 - val_accuracy: 0.5263\n",
            "Epoch 492/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5303 - val_loss: 0.6912 - val_accuracy: 0.5238\n",
            "Epoch 493/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5282 - val_loss: 0.6900 - val_accuracy: 0.5313\n",
            "Epoch 494/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5285 - val_loss: 0.6909 - val_accuracy: 0.5138\n",
            "Epoch 495/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5279 - val_loss: 0.6891 - val_accuracy: 0.5318\n",
            "Epoch 496/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5296 - val_loss: 0.6900 - val_accuracy: 0.5318\n",
            "Epoch 497/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5327 - val_loss: 0.6894 - val_accuracy: 0.5323\n",
            "Epoch 498/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5294 - val_loss: 0.6898 - val_accuracy: 0.5213\n",
            "Epoch 499/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5320 - val_loss: 0.6889 - val_accuracy: 0.5218\n",
            "Epoch 500/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5325 - val_loss: 0.6905 - val_accuracy: 0.5183\n",
            "Epoch 501/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5286 - val_loss: 0.6894 - val_accuracy: 0.5313\n",
            "Epoch 502/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5331 - val_loss: 0.6902 - val_accuracy: 0.5268\n",
            "Epoch 503/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5288 - val_loss: 0.6874 - val_accuracy: 0.5444\n",
            "Epoch 504/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5297 - val_loss: 0.6877 - val_accuracy: 0.5333\n",
            "Epoch 505/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5289 - val_loss: 0.6900 - val_accuracy: 0.5358\n",
            "Epoch 506/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5312 - val_loss: 0.6885 - val_accuracy: 0.5323\n",
            "Epoch 507/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5294 - val_loss: 0.6886 - val_accuracy: 0.5233\n",
            "Epoch 508/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5323 - val_loss: 0.6899 - val_accuracy: 0.5228\n",
            "Epoch 509/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5303 - val_loss: 0.6897 - val_accuracy: 0.5193\n",
            "Epoch 510/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5310 - val_loss: 0.6867 - val_accuracy: 0.5298\n",
            "Epoch 511/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5278 - val_loss: 0.6898 - val_accuracy: 0.5233\n",
            "Epoch 512/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5293 - val_loss: 0.6884 - val_accuracy: 0.5243\n",
            "Epoch 513/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5309 - val_loss: 0.6884 - val_accuracy: 0.5313\n",
            "Epoch 514/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5320 - val_loss: 0.6892 - val_accuracy: 0.5353\n",
            "Epoch 515/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5315 - val_loss: 0.6891 - val_accuracy: 0.5233\n",
            "Epoch 516/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5311 - val_loss: 0.6891 - val_accuracy: 0.5153\n",
            "Epoch 517/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5321 - val_loss: 0.6892 - val_accuracy: 0.5278\n",
            "Epoch 518/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5291 - val_loss: 0.6909 - val_accuracy: 0.5213\n",
            "Epoch 519/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5286 - val_loss: 0.6893 - val_accuracy: 0.5343\n",
            "Epoch 520/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5325 - val_loss: 0.6896 - val_accuracy: 0.5183\n",
            "Epoch 521/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5365 - val_loss: 0.6900 - val_accuracy: 0.5183\n",
            "Epoch 522/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5347 - val_loss: 0.6888 - val_accuracy: 0.5273\n",
            "Epoch 523/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5336 - val_loss: 0.6889 - val_accuracy: 0.5238\n",
            "Epoch 524/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5285 - val_loss: 0.6896 - val_accuracy: 0.5208\n",
            "Epoch 525/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5331 - val_loss: 0.6905 - val_accuracy: 0.5148\n",
            "Epoch 526/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5309 - val_loss: 0.6874 - val_accuracy: 0.5213\n",
            "Epoch 527/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5332 - val_loss: 0.6904 - val_accuracy: 0.5318\n",
            "Epoch 528/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5336 - val_loss: 0.6900 - val_accuracy: 0.5263\n",
            "Epoch 529/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5320 - val_loss: 0.6891 - val_accuracy: 0.5253\n",
            "Epoch 530/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5286 - val_loss: 0.6925 - val_accuracy: 0.5248\n",
            "Epoch 531/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5272 - val_loss: 0.6888 - val_accuracy: 0.5298\n",
            "Epoch 532/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5319 - val_loss: 0.6878 - val_accuracy: 0.5273\n",
            "Epoch 533/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5361 - val_loss: 0.6892 - val_accuracy: 0.5258\n",
            "Epoch 534/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5291 - val_loss: 0.6891 - val_accuracy: 0.5378\n",
            "Epoch 535/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5318 - val_loss: 0.6879 - val_accuracy: 0.5303\n",
            "Epoch 536/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5318 - val_loss: 0.6900 - val_accuracy: 0.5273\n",
            "Epoch 537/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5309 - val_loss: 0.6871 - val_accuracy: 0.5188\n",
            "Epoch 538/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5306 - val_loss: 0.6889 - val_accuracy: 0.5208\n",
            "Epoch 539/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5284 - val_loss: 0.6892 - val_accuracy: 0.5308\n",
            "Epoch 540/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5296 - val_loss: 0.6887 - val_accuracy: 0.5278\n",
            "Epoch 541/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5278 - val_loss: 0.6882 - val_accuracy: 0.5308\n",
            "Epoch 542/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5349 - val_loss: 0.6868 - val_accuracy: 0.5318\n",
            "Epoch 543/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5342 - val_loss: 0.6892 - val_accuracy: 0.5258\n",
            "Epoch 544/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5361 - val_loss: 0.6887 - val_accuracy: 0.5243\n",
            "Epoch 545/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5360 - val_loss: 0.6897 - val_accuracy: 0.5248\n",
            "Epoch 546/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5302 - val_loss: 0.6876 - val_accuracy: 0.5373\n",
            "Epoch 547/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5367 - val_loss: 0.6893 - val_accuracy: 0.5218\n",
            "Epoch 548/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5288 - val_loss: 0.6887 - val_accuracy: 0.5338\n",
            "Epoch 549/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5286 - val_loss: 0.6883 - val_accuracy: 0.5318\n",
            "Epoch 550/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5301 - val_loss: 0.6941 - val_accuracy: 0.5178\n",
            "Epoch 551/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5335 - val_loss: 0.6904 - val_accuracy: 0.5223\n",
            "Epoch 552/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5291 - val_loss: 0.6895 - val_accuracy: 0.5303\n",
            "Epoch 553/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5310 - val_loss: 0.6904 - val_accuracy: 0.5273\n",
            "Epoch 554/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5298 - val_loss: 0.6891 - val_accuracy: 0.5313\n",
            "Epoch 555/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5314 - val_loss: 0.6891 - val_accuracy: 0.5308\n",
            "Epoch 556/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5352 - val_loss: 0.6969 - val_accuracy: 0.5368\n",
            "Epoch 557/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5299 - val_loss: 0.6909 - val_accuracy: 0.5218\n",
            "Epoch 558/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5327 - val_loss: 0.6911 - val_accuracy: 0.5108\n",
            "Epoch 559/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5303 - val_loss: 0.6889 - val_accuracy: 0.5268\n",
            "Epoch 560/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5300 - val_loss: 0.6883 - val_accuracy: 0.5288\n",
            "Epoch 561/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5313 - val_loss: 0.6898 - val_accuracy: 0.5208\n",
            "Epoch 562/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5271 - val_loss: 0.6896 - val_accuracy: 0.5288\n",
            "Epoch 563/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5328 - val_loss: 0.6890 - val_accuracy: 0.5178\n",
            "Epoch 564/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5332 - val_loss: 0.6879 - val_accuracy: 0.5373\n",
            "Epoch 565/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5337 - val_loss: 0.6875 - val_accuracy: 0.5223\n",
            "Epoch 566/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5317 - val_loss: 0.6877 - val_accuracy: 0.5313\n",
            "Epoch 567/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5322 - val_loss: 0.6888 - val_accuracy: 0.5333\n",
            "Epoch 568/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5307 - val_loss: 0.6971 - val_accuracy: 0.5273\n",
            "Epoch 569/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5286 - val_loss: 0.6894 - val_accuracy: 0.5208\n",
            "Epoch 570/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5294 - val_loss: 0.6858 - val_accuracy: 0.5378\n",
            "Epoch 571/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5322 - val_loss: 0.6874 - val_accuracy: 0.5308\n",
            "Epoch 572/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5349 - val_loss: 0.6880 - val_accuracy: 0.5178\n",
            "Epoch 573/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5323 - val_loss: 0.6900 - val_accuracy: 0.5173\n",
            "Epoch 574/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5338 - val_loss: 0.6896 - val_accuracy: 0.5343\n",
            "Epoch 575/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5284 - val_loss: 0.6889 - val_accuracy: 0.5148\n",
            "Epoch 576/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5333 - val_loss: 0.6886 - val_accuracy: 0.5248\n",
            "Epoch 577/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5300 - val_loss: 0.6907 - val_accuracy: 0.5188\n",
            "Epoch 578/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5306 - val_loss: 0.6901 - val_accuracy: 0.5253\n",
            "Epoch 579/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5337 - val_loss: 0.6893 - val_accuracy: 0.5343\n",
            "Epoch 580/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5340 - val_loss: 0.6891 - val_accuracy: 0.5228\n",
            "Epoch 581/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5278 - val_loss: 0.6902 - val_accuracy: 0.5353\n",
            "Epoch 582/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5283 - val_loss: 0.6885 - val_accuracy: 0.5293\n",
            "Epoch 583/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5312 - val_loss: 0.6909 - val_accuracy: 0.5223\n",
            "Epoch 584/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5357 - val_loss: 0.6893 - val_accuracy: 0.5298\n",
            "Epoch 585/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5326 - val_loss: 0.6896 - val_accuracy: 0.5223\n",
            "Epoch 586/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5326 - val_loss: 0.6892 - val_accuracy: 0.5343\n",
            "Epoch 587/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5277 - val_loss: 0.6890 - val_accuracy: 0.5288\n",
            "Epoch 588/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5317 - val_loss: 0.6876 - val_accuracy: 0.5308\n",
            "Epoch 589/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5274 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
            "Epoch 590/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5291 - val_loss: 0.6884 - val_accuracy: 0.5248\n",
            "Epoch 591/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5304 - val_loss: 0.6889 - val_accuracy: 0.5308\n",
            "Epoch 592/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5343 - val_loss: 0.6893 - val_accuracy: 0.5353\n",
            "Epoch 593/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5315 - val_loss: 0.6904 - val_accuracy: 0.5278\n",
            "Epoch 594/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5248 - val_loss: 0.6895 - val_accuracy: 0.5238\n",
            "Epoch 595/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5307 - val_loss: 0.6889 - val_accuracy: 0.5253\n",
            "Epoch 596/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5321 - val_loss: 0.6882 - val_accuracy: 0.5233\n",
            "Epoch 597/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5283 - val_loss: 0.6898 - val_accuracy: 0.5278\n",
            "Epoch 598/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5316 - val_loss: 0.6899 - val_accuracy: 0.5263\n",
            "Epoch 599/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5337 - val_loss: 0.6897 - val_accuracy: 0.5273\n",
            "Epoch 600/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5381 - val_loss: 0.6892 - val_accuracy: 0.5283\n",
            "Epoch 601/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5317 - val_loss: 0.6896 - val_accuracy: 0.5273\n",
            "Epoch 602/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5281 - val_loss: 0.6903 - val_accuracy: 0.5328\n",
            "Epoch 603/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5328 - val_loss: 0.6909 - val_accuracy: 0.5238\n",
            "Epoch 604/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5341 - val_loss: 0.6884 - val_accuracy: 0.5358\n",
            "Epoch 605/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5302 - val_loss: 0.6884 - val_accuracy: 0.5298\n",
            "Epoch 606/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5283 - val_loss: 0.6893 - val_accuracy: 0.5263\n",
            "Epoch 607/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5315 - val_loss: 0.6894 - val_accuracy: 0.5238\n",
            "Epoch 608/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5291 - val_loss: 0.6899 - val_accuracy: 0.5273\n",
            "Epoch 609/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5293 - val_loss: 0.6893 - val_accuracy: 0.5213\n",
            "Epoch 610/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5332 - val_loss: 0.6918 - val_accuracy: 0.5148\n",
            "Epoch 611/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5292 - val_loss: 0.6887 - val_accuracy: 0.5273\n",
            "Epoch 612/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5308 - val_loss: 0.6877 - val_accuracy: 0.5323\n",
            "Epoch 613/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5289 - val_loss: 0.6886 - val_accuracy: 0.5298\n",
            "Epoch 614/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5348 - val_loss: 0.6892 - val_accuracy: 0.5283\n",
            "Epoch 615/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5312 - val_loss: 0.6890 - val_accuracy: 0.5148\n",
            "Epoch 616/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5281 - val_loss: 0.6882 - val_accuracy: 0.5328\n",
            "Epoch 617/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5344 - val_loss: 0.6886 - val_accuracy: 0.5258\n",
            "Epoch 618/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5307 - val_loss: 0.6902 - val_accuracy: 0.5328\n",
            "Epoch 619/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5304 - val_loss: 0.6890 - val_accuracy: 0.5323\n",
            "Epoch 620/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5291 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
            "Epoch 621/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5296 - val_loss: 0.6896 - val_accuracy: 0.5238\n",
            "Epoch 622/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5273 - val_loss: 0.6895 - val_accuracy: 0.5353\n",
            "Epoch 623/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5337 - val_loss: 0.6895 - val_accuracy: 0.5258\n",
            "Epoch 624/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5293 - val_loss: 0.6881 - val_accuracy: 0.5333\n",
            "Epoch 625/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5318 - val_loss: 0.6893 - val_accuracy: 0.5233\n",
            "Epoch 626/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5317 - val_loss: 0.6900 - val_accuracy: 0.5293\n",
            "Epoch 627/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5317 - val_loss: 0.6895 - val_accuracy: 0.5228\n",
            "Epoch 628/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5303 - val_loss: 0.6897 - val_accuracy: 0.5409\n",
            "Epoch 629/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5320 - val_loss: 0.6900 - val_accuracy: 0.5278\n",
            "Epoch 630/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5332 - val_loss: 0.6895 - val_accuracy: 0.5303\n",
            "Epoch 631/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5351 - val_loss: 0.6885 - val_accuracy: 0.5268\n",
            "Epoch 632/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5336 - val_loss: 0.6890 - val_accuracy: 0.5253\n",
            "Epoch 633/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5318 - val_loss: 0.6865 - val_accuracy: 0.5348\n",
            "Epoch 634/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5347 - val_loss: 0.6900 - val_accuracy: 0.5188\n",
            "Epoch 635/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5291 - val_loss: 0.6882 - val_accuracy: 0.5278\n",
            "Epoch 636/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5338 - val_loss: 0.6878 - val_accuracy: 0.5348\n",
            "Epoch 637/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5340 - val_loss: 0.6900 - val_accuracy: 0.5253\n",
            "Epoch 638/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5311 - val_loss: 0.6896 - val_accuracy: 0.5298\n",
            "Epoch 639/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5321 - val_loss: 0.6876 - val_accuracy: 0.5223\n",
            "Epoch 640/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5348 - val_loss: 0.6882 - val_accuracy: 0.5293\n",
            "Epoch 641/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5317 - val_loss: 0.6901 - val_accuracy: 0.5318\n",
            "Epoch 642/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5293 - val_loss: 0.6886 - val_accuracy: 0.5358\n",
            "Epoch 643/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5360 - val_loss: 0.6887 - val_accuracy: 0.5328\n",
            "Epoch 644/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5365 - val_loss: 0.6908 - val_accuracy: 0.5203\n",
            "Epoch 645/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5353 - val_loss: 0.6887 - val_accuracy: 0.5278\n",
            "Epoch 646/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5317 - val_loss: 0.6913 - val_accuracy: 0.5218\n",
            "Epoch 647/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5301 - val_loss: 0.6887 - val_accuracy: 0.5318\n",
            "Epoch 648/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5294 - val_loss: 0.6907 - val_accuracy: 0.5363\n",
            "Epoch 649/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5340 - val_loss: 0.6901 - val_accuracy: 0.5173\n",
            "Epoch 650/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5308 - val_loss: 0.6888 - val_accuracy: 0.5228\n",
            "Epoch 651/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5318 - val_loss: 0.6888 - val_accuracy: 0.5188\n",
            "Epoch 652/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5339 - val_loss: 0.6890 - val_accuracy: 0.5253\n",
            "Epoch 653/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5315 - val_loss: 0.6886 - val_accuracy: 0.5318\n",
            "Epoch 654/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5321 - val_loss: 0.6878 - val_accuracy: 0.5298\n",
            "Epoch 655/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5287 - val_loss: 0.6933 - val_accuracy: 0.5258\n",
            "Epoch 656/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5304 - val_loss: 0.6898 - val_accuracy: 0.5283\n",
            "Epoch 657/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5371 - val_loss: 0.6873 - val_accuracy: 0.5278\n",
            "Epoch 658/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5397 - val_loss: 0.6880 - val_accuracy: 0.5193\n",
            "Epoch 659/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5332 - val_loss: 0.6877 - val_accuracy: 0.5393\n",
            "Epoch 660/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5316 - val_loss: 0.6886 - val_accuracy: 0.5223\n",
            "Epoch 661/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5348 - val_loss: 0.6874 - val_accuracy: 0.5368\n",
            "Epoch 662/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5367 - val_loss: 0.6866 - val_accuracy: 0.5273\n",
            "Epoch 663/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5318 - val_loss: 0.6880 - val_accuracy: 0.5333\n",
            "Epoch 664/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5341 - val_loss: 0.6904 - val_accuracy: 0.5233\n",
            "Epoch 665/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5317 - val_loss: 0.6890 - val_accuracy: 0.5228\n",
            "Epoch 666/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5307 - val_loss: 0.6902 - val_accuracy: 0.5233\n",
            "Epoch 667/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5345 - val_loss: 0.6879 - val_accuracy: 0.5253\n",
            "Epoch 668/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5335 - val_loss: 0.6898 - val_accuracy: 0.5288\n",
            "Epoch 669/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5322 - val_loss: 0.6912 - val_accuracy: 0.5258\n",
            "Epoch 670/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5353 - val_loss: 0.6895 - val_accuracy: 0.5353\n",
            "Epoch 671/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5395 - val_loss: 0.6902 - val_accuracy: 0.5243\n",
            "Epoch 672/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5340 - val_loss: 0.6893 - val_accuracy: 0.5233\n",
            "Epoch 673/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5346 - val_loss: 0.6895 - val_accuracy: 0.5333\n",
            "Epoch 674/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5295 - val_loss: 0.6895 - val_accuracy: 0.5283\n",
            "Epoch 675/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5355 - val_loss: 0.6921 - val_accuracy: 0.5353\n",
            "Epoch 676/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5385 - val_loss: 0.6892 - val_accuracy: 0.5158\n",
            "Epoch 677/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5353 - val_loss: 0.6966 - val_accuracy: 0.5363\n",
            "Epoch 678/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5350 - val_loss: 0.6911 - val_accuracy: 0.5318\n",
            "Epoch 679/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5299 - val_loss: 0.6902 - val_accuracy: 0.5078\n",
            "Epoch 680/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5335 - val_loss: 0.6902 - val_accuracy: 0.5178\n",
            "Epoch 681/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5337 - val_loss: 0.6882 - val_accuracy: 0.5298\n",
            "Epoch 682/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5327 - val_loss: 0.6886 - val_accuracy: 0.5323\n",
            "Epoch 683/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5347 - val_loss: 0.6894 - val_accuracy: 0.5303\n",
            "Epoch 684/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5311 - val_loss: 0.6887 - val_accuracy: 0.5308\n",
            "Epoch 685/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5311 - val_loss: 0.6901 - val_accuracy: 0.5188\n",
            "Epoch 686/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5336 - val_loss: 0.6889 - val_accuracy: 0.5233\n",
            "Epoch 687/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5301 - val_loss: 0.6893 - val_accuracy: 0.5298\n",
            "Epoch 688/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5316 - val_loss: 0.6885 - val_accuracy: 0.5208\n",
            "Epoch 689/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5316 - val_loss: 0.6931 - val_accuracy: 0.5358\n",
            "Epoch 690/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5312 - val_loss: 0.6883 - val_accuracy: 0.5223\n",
            "Epoch 691/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5334 - val_loss: 0.6876 - val_accuracy: 0.5228\n",
            "Epoch 692/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5337 - val_loss: 0.6901 - val_accuracy: 0.5273\n",
            "Epoch 693/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5320 - val_loss: 0.6903 - val_accuracy: 0.5253\n",
            "Epoch 694/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5307 - val_loss: 0.6877 - val_accuracy: 0.5298\n",
            "Epoch 695/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5327 - val_loss: 0.6878 - val_accuracy: 0.5298\n",
            "Epoch 696/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5293 - val_loss: 0.6890 - val_accuracy: 0.5323\n",
            "Epoch 697/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5310 - val_loss: 0.6890 - val_accuracy: 0.5328\n",
            "Epoch 698/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5332 - val_loss: 0.6905 - val_accuracy: 0.5263\n",
            "Epoch 699/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5342 - val_loss: 0.6914 - val_accuracy: 0.5348\n",
            "Epoch 700/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5311 - val_loss: 0.6879 - val_accuracy: 0.5268\n",
            "Epoch 701/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5330 - val_loss: 0.6891 - val_accuracy: 0.5353\n",
            "Epoch 702/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5345 - val_loss: 0.6886 - val_accuracy: 0.5323\n",
            "Epoch 703/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5321 - val_loss: 0.6877 - val_accuracy: 0.5283\n",
            "Epoch 704/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5317 - val_loss: 0.6887 - val_accuracy: 0.5248\n",
            "Epoch 705/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5335 - val_loss: 0.6883 - val_accuracy: 0.5323\n",
            "Epoch 706/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5311 - val_loss: 0.6927 - val_accuracy: 0.5203\n",
            "Epoch 707/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5340 - val_loss: 0.6889 - val_accuracy: 0.5253\n",
            "Epoch 708/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5326 - val_loss: 0.6906 - val_accuracy: 0.5193\n",
            "Epoch 709/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5316 - val_loss: 0.6896 - val_accuracy: 0.5183\n",
            "Epoch 710/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5351 - val_loss: 0.6894 - val_accuracy: 0.5238\n",
            "Epoch 711/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5318 - val_loss: 0.6887 - val_accuracy: 0.5298\n",
            "Epoch 712/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5307 - val_loss: 0.6902 - val_accuracy: 0.5208\n",
            "Epoch 713/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5357 - val_loss: 0.6879 - val_accuracy: 0.5328\n",
            "Epoch 714/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5323 - val_loss: 0.6879 - val_accuracy: 0.5333\n",
            "Epoch 715/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5345 - val_loss: 0.6887 - val_accuracy: 0.5228\n",
            "Epoch 716/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5353 - val_loss: 0.6898 - val_accuracy: 0.5253\n",
            "Epoch 717/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5331 - val_loss: 0.6887 - val_accuracy: 0.5343\n",
            "Epoch 718/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5324 - val_loss: 0.6902 - val_accuracy: 0.5328\n",
            "Epoch 719/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6879 - val_accuracy: 0.5208\n",
            "Epoch 720/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5322 - val_loss: 0.6893 - val_accuracy: 0.5283\n",
            "Epoch 721/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5357 - val_loss: 0.6901 - val_accuracy: 0.5278\n",
            "Epoch 722/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5293 - val_loss: 0.6890 - val_accuracy: 0.5363\n",
            "Epoch 723/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5322 - val_loss: 0.6915 - val_accuracy: 0.5223\n",
            "Epoch 724/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5350 - val_loss: 0.6899 - val_accuracy: 0.5308\n",
            "Epoch 725/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5322 - val_loss: 0.6892 - val_accuracy: 0.5323\n",
            "Epoch 726/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5348 - val_loss: 0.6896 - val_accuracy: 0.5248\n",
            "Epoch 727/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5315 - val_loss: 0.6880 - val_accuracy: 0.5293\n",
            "Epoch 728/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5351 - val_loss: 0.6885 - val_accuracy: 0.5258\n",
            "Epoch 729/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5325 - val_loss: 0.6922 - val_accuracy: 0.5218\n",
            "Epoch 730/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5365 - val_loss: 0.6884 - val_accuracy: 0.5283\n",
            "Epoch 731/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5352 - val_loss: 0.6882 - val_accuracy: 0.5313\n",
            "Epoch 732/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5338 - val_loss: 0.6874 - val_accuracy: 0.5323\n",
            "Epoch 733/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5331 - val_loss: 0.6896 - val_accuracy: 0.5258\n",
            "Epoch 734/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5351 - val_loss: 0.6882 - val_accuracy: 0.5368\n",
            "Epoch 735/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5307 - val_loss: 0.6894 - val_accuracy: 0.5278\n",
            "Epoch 736/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5353 - val_loss: 0.6884 - val_accuracy: 0.5383\n",
            "Epoch 737/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5335 - val_loss: 0.6890 - val_accuracy: 0.5193\n",
            "Epoch 738/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5321 - val_loss: 0.6885 - val_accuracy: 0.5318\n",
            "Epoch 739/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5334 - val_loss: 0.6898 - val_accuracy: 0.5273\n",
            "Epoch 740/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5335 - val_loss: 0.6881 - val_accuracy: 0.5333\n",
            "Epoch 741/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5361 - val_loss: 0.6889 - val_accuracy: 0.5313\n",
            "Epoch 742/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5337 - val_loss: 0.6890 - val_accuracy: 0.5328\n",
            "Epoch 743/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5330 - val_loss: 0.6887 - val_accuracy: 0.5293\n",
            "Epoch 744/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5309 - val_loss: 0.6983 - val_accuracy: 0.5178\n",
            "Epoch 745/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5349 - val_loss: 0.6887 - val_accuracy: 0.5283\n",
            "Epoch 746/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5342 - val_loss: 0.6896 - val_accuracy: 0.5228\n",
            "Epoch 747/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5317 - val_loss: 0.6876 - val_accuracy: 0.5148\n",
            "Epoch 748/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5385 - val_loss: 0.6890 - val_accuracy: 0.5313\n",
            "Epoch 749/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5326 - val_loss: 0.6905 - val_accuracy: 0.5343\n",
            "Epoch 750/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5372 - val_loss: 0.6904 - val_accuracy: 0.5333\n",
            "Epoch 751/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5327 - val_loss: 0.6892 - val_accuracy: 0.5303\n",
            "Epoch 752/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5371 - val_loss: 0.6893 - val_accuracy: 0.5263\n",
            "Epoch 753/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5328 - val_loss: 0.6891 - val_accuracy: 0.5288\n",
            "Epoch 754/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5322 - val_loss: 0.6895 - val_accuracy: 0.5188\n",
            "Epoch 755/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5344 - val_loss: 0.6896 - val_accuracy: 0.5353\n",
            "Epoch 756/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5322 - val_loss: 0.6898 - val_accuracy: 0.5203\n",
            "Epoch 757/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5313 - val_loss: 0.6901 - val_accuracy: 0.5298\n",
            "Epoch 758/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5330 - val_loss: 0.6892 - val_accuracy: 0.5198\n",
            "Epoch 759/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5336 - val_loss: 0.6892 - val_accuracy: 0.5248\n",
            "Epoch 760/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5308 - val_loss: 0.6897 - val_accuracy: 0.5198\n",
            "Epoch 761/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5340 - val_loss: 0.6885 - val_accuracy: 0.5298\n",
            "Epoch 762/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5367 - val_loss: 0.6880 - val_accuracy: 0.5253\n",
            "Epoch 763/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5331 - val_loss: 0.6893 - val_accuracy: 0.5178\n",
            "Epoch 764/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5303 - val_loss: 0.6895 - val_accuracy: 0.5273\n",
            "Epoch 765/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5346 - val_loss: 0.6899 - val_accuracy: 0.5343\n",
            "Epoch 766/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5343 - val_loss: 0.6899 - val_accuracy: 0.5223\n",
            "Epoch 767/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5324 - val_loss: 0.6885 - val_accuracy: 0.5338\n",
            "Epoch 768/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5352 - val_loss: 0.6895 - val_accuracy: 0.5263\n",
            "Epoch 769/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5331 - val_loss: 0.6892 - val_accuracy: 0.5348\n",
            "Epoch 770/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5374 - val_loss: 0.6890 - val_accuracy: 0.5293\n",
            "Epoch 771/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5359 - val_loss: 0.6898 - val_accuracy: 0.5153\n",
            "Epoch 772/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5350 - val_loss: 0.6883 - val_accuracy: 0.5188\n",
            "Epoch 773/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5358 - val_loss: 0.6911 - val_accuracy: 0.5253\n",
            "Epoch 774/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5361 - val_loss: 0.6891 - val_accuracy: 0.5333\n",
            "Epoch 775/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5330 - val_loss: 0.6907 - val_accuracy: 0.5238\n",
            "Epoch 776/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5364 - val_loss: 0.6899 - val_accuracy: 0.5293\n",
            "Epoch 777/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5367 - val_loss: 0.6916 - val_accuracy: 0.5283\n",
            "Epoch 778/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5384 - val_loss: 0.6878 - val_accuracy: 0.5303\n",
            "Epoch 779/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5347 - val_loss: 0.6894 - val_accuracy: 0.5268\n",
            "Epoch 780/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5354 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
            "Epoch 781/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5367 - val_loss: 0.6893 - val_accuracy: 0.5213\n",
            "Epoch 782/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5359 - val_loss: 0.6881 - val_accuracy: 0.5273\n",
            "Epoch 783/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5380 - val_loss: 0.6892 - val_accuracy: 0.5208\n",
            "Epoch 784/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5337 - val_loss: 0.6898 - val_accuracy: 0.5313\n",
            "Epoch 785/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5350 - val_loss: 0.6895 - val_accuracy: 0.5263\n",
            "Epoch 786/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5333 - val_loss: 0.6904 - val_accuracy: 0.5183\n",
            "Epoch 787/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5305 - val_loss: 0.6902 - val_accuracy: 0.5288\n",
            "Epoch 788/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5340 - val_loss: 0.6901 - val_accuracy: 0.5193\n",
            "Epoch 789/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5325 - val_loss: 0.6902 - val_accuracy: 0.5208\n",
            "Epoch 790/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5317 - val_loss: 0.6906 - val_accuracy: 0.5363\n",
            "Epoch 791/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5308 - val_loss: 0.6898 - val_accuracy: 0.5268\n",
            "Epoch 792/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5342 - val_loss: 0.6890 - val_accuracy: 0.5283\n",
            "Epoch 793/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5307 - val_loss: 0.6900 - val_accuracy: 0.5223\n",
            "Epoch 794/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5349 - val_loss: 0.6886 - val_accuracy: 0.5183\n",
            "Epoch 795/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5370 - val_loss: 0.6879 - val_accuracy: 0.5283\n",
            "Epoch 796/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5355 - val_loss: 0.6892 - val_accuracy: 0.5088\n",
            "Epoch 797/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6906 - val_accuracy: 0.5278\n",
            "Epoch 798/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5331 - val_loss: 0.6885 - val_accuracy: 0.5198\n",
            "Epoch 799/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5352 - val_loss: 0.6901 - val_accuracy: 0.5338\n",
            "Epoch 800/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5352 - val_loss: 0.6875 - val_accuracy: 0.5308\n",
            "Epoch 801/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5379 - val_loss: 0.6875 - val_accuracy: 0.5368\n",
            "Epoch 802/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5349 - val_loss: 0.6909 - val_accuracy: 0.5063\n",
            "Epoch 803/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5318 - val_loss: 0.6897 - val_accuracy: 0.5343\n",
            "Epoch 804/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5365 - val_loss: 0.6884 - val_accuracy: 0.5233\n",
            "Epoch 805/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5348 - val_loss: 0.6896 - val_accuracy: 0.5293\n",
            "Epoch 806/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5333 - val_loss: 0.7014 - val_accuracy: 0.5188\n",
            "Epoch 807/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5337 - val_loss: 0.6894 - val_accuracy: 0.5213\n",
            "Epoch 808/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5348 - val_loss: 0.6891 - val_accuracy: 0.5293\n",
            "Epoch 809/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5335 - val_loss: 0.6890 - val_accuracy: 0.5298\n",
            "Epoch 810/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5367 - val_loss: 0.6892 - val_accuracy: 0.5278\n",
            "Epoch 811/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5336 - val_loss: 0.6889 - val_accuracy: 0.5213\n",
            "Epoch 812/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5339 - val_loss: 0.6883 - val_accuracy: 0.5228\n",
            "Epoch 813/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5379 - val_loss: 0.6898 - val_accuracy: 0.5313\n",
            "Epoch 814/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5362 - val_loss: 0.6885 - val_accuracy: 0.5333\n",
            "Epoch 815/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5345 - val_loss: 0.6891 - val_accuracy: 0.5263\n",
            "Epoch 816/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5328 - val_loss: 0.6887 - val_accuracy: 0.5253\n",
            "Epoch 817/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5340 - val_loss: 0.6896 - val_accuracy: 0.5338\n",
            "Epoch 818/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5355 - val_loss: 0.6898 - val_accuracy: 0.5218\n",
            "Epoch 819/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5365 - val_loss: 0.6893 - val_accuracy: 0.5273\n",
            "Epoch 820/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5330 - val_loss: 0.6894 - val_accuracy: 0.5223\n",
            "Epoch 821/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5333 - val_loss: 0.6884 - val_accuracy: 0.5313\n",
            "Epoch 822/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5335 - val_loss: 0.6880 - val_accuracy: 0.5263\n",
            "Epoch 823/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5338 - val_loss: 0.6883 - val_accuracy: 0.5288\n",
            "Epoch 824/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5336 - val_loss: 0.6908 - val_accuracy: 0.5258\n",
            "Epoch 825/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5319 - val_loss: 0.6902 - val_accuracy: 0.5193\n",
            "Epoch 826/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5308 - val_loss: 0.6884 - val_accuracy: 0.5233\n",
            "Epoch 827/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5346 - val_loss: 0.6897 - val_accuracy: 0.5253\n",
            "Epoch 828/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5374 - val_loss: 0.6898 - val_accuracy: 0.5283\n",
            "Epoch 829/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5281 - val_loss: 0.6878 - val_accuracy: 0.5313\n",
            "Epoch 830/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5332 - val_loss: 0.6899 - val_accuracy: 0.5348\n",
            "Epoch 831/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5328 - val_loss: 0.6900 - val_accuracy: 0.5243\n",
            "Epoch 832/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5352 - val_loss: 0.6890 - val_accuracy: 0.5263\n",
            "Epoch 833/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5326 - val_loss: 0.6936 - val_accuracy: 0.5198\n",
            "Epoch 834/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5342 - val_loss: 0.6895 - val_accuracy: 0.5353\n",
            "Epoch 835/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5359 - val_loss: 0.6901 - val_accuracy: 0.5288\n",
            "Epoch 836/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5347 - val_loss: 0.6883 - val_accuracy: 0.5233\n",
            "Epoch 837/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5365 - val_loss: 0.6876 - val_accuracy: 0.5238\n",
            "Epoch 838/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5365 - val_loss: 0.6908 - val_accuracy: 0.5238\n",
            "Epoch 839/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5291 - val_loss: 0.6890 - val_accuracy: 0.5348\n",
            "Epoch 840/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5328 - val_loss: 0.6900 - val_accuracy: 0.5278\n",
            "Epoch 841/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5358 - val_loss: 0.6896 - val_accuracy: 0.5168\n",
            "Epoch 842/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5358 - val_loss: 0.6882 - val_accuracy: 0.5243\n",
            "Epoch 843/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5345 - val_loss: 0.6885 - val_accuracy: 0.5253\n",
            "Epoch 844/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5354 - val_loss: 0.6882 - val_accuracy: 0.5268\n",
            "Epoch 845/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5318 - val_loss: 0.6897 - val_accuracy: 0.5368\n",
            "Epoch 846/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5351 - val_loss: 0.6887 - val_accuracy: 0.5278\n",
            "Epoch 847/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5361 - val_loss: 0.6907 - val_accuracy: 0.5303\n",
            "Epoch 848/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5363 - val_loss: 0.6895 - val_accuracy: 0.5303\n",
            "Epoch 849/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5373 - val_loss: 0.6896 - val_accuracy: 0.5178\n",
            "Epoch 850/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5384 - val_loss: 0.6893 - val_accuracy: 0.5298\n",
            "Epoch 851/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5346 - val_loss: 0.6896 - val_accuracy: 0.5308\n",
            "Epoch 852/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5335 - val_loss: 0.6880 - val_accuracy: 0.5273\n",
            "Epoch 853/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5355 - val_loss: 0.6888 - val_accuracy: 0.5308\n",
            "Epoch 854/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5361 - val_loss: 0.6882 - val_accuracy: 0.5288\n",
            "Epoch 855/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5331 - val_loss: 0.6892 - val_accuracy: 0.5238\n",
            "Epoch 856/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5357 - val_loss: 0.6912 - val_accuracy: 0.5283\n",
            "Epoch 857/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5369 - val_loss: 0.6886 - val_accuracy: 0.5328\n",
            "Epoch 858/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5387 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
            "Epoch 859/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5325 - val_loss: 0.6899 - val_accuracy: 0.5178\n",
            "Epoch 860/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5345 - val_loss: 0.6888 - val_accuracy: 0.5243\n",
            "Epoch 861/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5343 - val_loss: 0.6883 - val_accuracy: 0.5158\n",
            "Epoch 862/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5353 - val_loss: 0.6882 - val_accuracy: 0.5183\n",
            "Epoch 863/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5333 - val_loss: 0.6878 - val_accuracy: 0.5318\n",
            "Epoch 864/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5365 - val_loss: 0.6883 - val_accuracy: 0.5293\n",
            "Epoch 865/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5393 - val_loss: 0.6884 - val_accuracy: 0.5378\n",
            "Epoch 866/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5352 - val_loss: 0.6896 - val_accuracy: 0.5388\n",
            "Epoch 867/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5311 - val_loss: 0.6896 - val_accuracy: 0.5223\n",
            "Epoch 868/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5322 - val_loss: 0.6899 - val_accuracy: 0.5118\n",
            "Epoch 869/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5360 - val_loss: 0.6894 - val_accuracy: 0.5348\n",
            "Epoch 870/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5350 - val_loss: 0.6897 - val_accuracy: 0.5263\n",
            "Epoch 871/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5364 - val_loss: 0.6882 - val_accuracy: 0.5288\n",
            "Epoch 872/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5383 - val_loss: 0.6900 - val_accuracy: 0.5323\n",
            "Epoch 873/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5316 - val_loss: 0.6917 - val_accuracy: 0.5298\n",
            "Epoch 874/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5367 - val_loss: 0.6886 - val_accuracy: 0.5313\n",
            "Epoch 875/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5351 - val_loss: 0.6907 - val_accuracy: 0.5293\n",
            "Epoch 876/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5376 - val_loss: 0.6930 - val_accuracy: 0.5258\n",
            "Epoch 877/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5353 - val_loss: 0.6893 - val_accuracy: 0.5293\n",
            "Epoch 878/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5349 - val_loss: 0.6883 - val_accuracy: 0.5283\n",
            "Epoch 879/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5350 - val_loss: 0.6883 - val_accuracy: 0.5328\n",
            "Epoch 880/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5325 - val_loss: 0.6892 - val_accuracy: 0.5263\n",
            "Epoch 881/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5366 - val_loss: 0.6891 - val_accuracy: 0.5198\n",
            "Epoch 882/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5346 - val_loss: 0.6878 - val_accuracy: 0.5343\n",
            "Epoch 883/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5349 - val_loss: 0.6879 - val_accuracy: 0.5293\n",
            "Epoch 884/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5313 - val_loss: 0.6878 - val_accuracy: 0.5318\n",
            "Epoch 885/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5364 - val_loss: 0.6886 - val_accuracy: 0.5228\n",
            "Epoch 886/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6836 - accuracy: 0.5355 - val_loss: 0.6882 - val_accuracy: 0.5268\n",
            "Epoch 887/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5358 - val_loss: 0.6873 - val_accuracy: 0.5313\n",
            "Epoch 888/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5337 - val_loss: 0.6905 - val_accuracy: 0.5218\n",
            "Epoch 889/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5320 - val_loss: 0.6897 - val_accuracy: 0.5228\n",
            "Epoch 890/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5354 - val_loss: 0.6871 - val_accuracy: 0.5404\n",
            "Epoch 891/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5338 - val_loss: 0.6887 - val_accuracy: 0.5263\n",
            "Epoch 892/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6836 - accuracy: 0.5355 - val_loss: 0.6882 - val_accuracy: 0.5213\n",
            "Epoch 893/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5314 - val_loss: 0.6865 - val_accuracy: 0.5338\n",
            "Epoch 894/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5349 - val_loss: 0.6868 - val_accuracy: 0.5283\n",
            "Epoch 895/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5361 - val_loss: 0.6926 - val_accuracy: 0.5313\n",
            "Epoch 896/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5340 - val_loss: 0.6898 - val_accuracy: 0.5278\n",
            "Epoch 897/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5365 - val_loss: 0.6891 - val_accuracy: 0.5333\n",
            "Epoch 898/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5345 - val_loss: 0.6894 - val_accuracy: 0.5268\n",
            "Epoch 899/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5350 - val_loss: 0.6891 - val_accuracy: 0.5263\n",
            "Epoch 900/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5392 - val_loss: 0.6883 - val_accuracy: 0.5288\n",
            "Epoch 901/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5354 - val_loss: 0.6884 - val_accuracy: 0.5253\n",
            "Epoch 902/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5354 - val_loss: 0.6882 - val_accuracy: 0.5338\n",
            "Epoch 903/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5343 - val_loss: 0.6905 - val_accuracy: 0.5193\n",
            "Epoch 904/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5276 - val_loss: 0.6890 - val_accuracy: 0.5313\n",
            "Epoch 905/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5348 - val_loss: 0.6895 - val_accuracy: 0.5228\n",
            "Epoch 906/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5370 - val_loss: 0.6879 - val_accuracy: 0.5323\n",
            "Epoch 907/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5340 - val_loss: 0.6917 - val_accuracy: 0.5228\n",
            "Epoch 908/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5366 - val_loss: 0.6880 - val_accuracy: 0.5368\n",
            "Epoch 909/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5351 - val_loss: 0.6889 - val_accuracy: 0.5248\n",
            "Epoch 910/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5384 - val_loss: 0.6893 - val_accuracy: 0.5253\n",
            "Epoch 911/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5368 - val_loss: 0.6876 - val_accuracy: 0.5168\n",
            "Epoch 912/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5331 - val_loss: 0.6918 - val_accuracy: 0.5193\n",
            "Epoch 913/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5338 - val_loss: 0.6879 - val_accuracy: 0.5178\n",
            "Epoch 914/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5323 - val_loss: 0.6892 - val_accuracy: 0.5268\n",
            "Epoch 915/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5347 - val_loss: 0.6883 - val_accuracy: 0.5283\n",
            "Epoch 916/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5352 - val_loss: 0.6881 - val_accuracy: 0.5323\n",
            "Epoch 917/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5377 - val_loss: 0.6898 - val_accuracy: 0.5253\n",
            "Epoch 918/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5334 - val_loss: 0.6885 - val_accuracy: 0.5208\n",
            "Epoch 919/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5351 - val_loss: 0.6959 - val_accuracy: 0.5298\n",
            "Epoch 920/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5359 - val_loss: 0.6879 - val_accuracy: 0.5228\n",
            "Epoch 921/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5345 - val_loss: 0.6889 - val_accuracy: 0.5348\n",
            "Epoch 922/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5347 - val_loss: 0.6884 - val_accuracy: 0.5248\n",
            "Epoch 923/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5321 - val_loss: 0.6869 - val_accuracy: 0.5368\n",
            "Epoch 924/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5355 - val_loss: 0.6892 - val_accuracy: 0.5193\n",
            "Epoch 925/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5386 - val_loss: 0.6879 - val_accuracy: 0.5353\n",
            "Epoch 926/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6832 - accuracy: 0.5389 - val_loss: 0.6883 - val_accuracy: 0.5278\n",
            "Epoch 927/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5331 - val_loss: 0.6885 - val_accuracy: 0.5273\n",
            "Epoch 928/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5344 - val_loss: 0.6884 - val_accuracy: 0.5283\n",
            "Epoch 929/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6835 - accuracy: 0.5374 - val_loss: 0.6882 - val_accuracy: 0.5233\n",
            "Epoch 930/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5361 - val_loss: 0.6896 - val_accuracy: 0.5178\n",
            "Epoch 931/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5322 - val_loss: 0.6880 - val_accuracy: 0.5283\n",
            "Epoch 932/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5347 - val_loss: 0.6887 - val_accuracy: 0.5233\n",
            "Epoch 933/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5323 - val_loss: 0.6880 - val_accuracy: 0.5283\n",
            "Epoch 934/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5336 - val_loss: 0.6877 - val_accuracy: 0.5238\n",
            "Epoch 935/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5306 - val_loss: 0.6878 - val_accuracy: 0.5253\n",
            "Epoch 936/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5380 - val_loss: 0.6900 - val_accuracy: 0.5213\n",
            "Epoch 937/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5302 - val_loss: 0.6886 - val_accuracy: 0.5303\n",
            "Epoch 938/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5389 - val_loss: 0.6888 - val_accuracy: 0.5178\n",
            "Epoch 939/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5361 - val_loss: 0.6893 - val_accuracy: 0.5328\n",
            "Epoch 940/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5376 - val_loss: 0.6908 - val_accuracy: 0.5263\n",
            "Epoch 941/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5327 - val_loss: 0.6885 - val_accuracy: 0.5268\n",
            "Epoch 942/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5338 - val_loss: 0.6888 - val_accuracy: 0.5303\n",
            "Epoch 943/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5375 - val_loss: 0.6895 - val_accuracy: 0.5183\n",
            "Epoch 944/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5355 - val_loss: 0.6904 - val_accuracy: 0.5208\n",
            "Epoch 945/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5341 - val_loss: 0.6890 - val_accuracy: 0.5248\n",
            "Epoch 946/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5331 - val_loss: 0.6900 - val_accuracy: 0.5178\n",
            "Epoch 947/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5291 - val_loss: 0.6883 - val_accuracy: 0.5203\n",
            "Epoch 948/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5367 - val_loss: 0.6884 - val_accuracy: 0.5388\n",
            "Epoch 949/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6836 - accuracy: 0.5356 - val_loss: 0.6871 - val_accuracy: 0.5323\n",
            "Epoch 950/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5350 - val_loss: 0.6871 - val_accuracy: 0.5293\n",
            "Epoch 951/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5375 - val_loss: 0.6889 - val_accuracy: 0.5318\n",
            "Epoch 952/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5360 - val_loss: 0.6938 - val_accuracy: 0.5218\n",
            "Epoch 953/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5352 - val_loss: 0.6890 - val_accuracy: 0.5288\n",
            "Epoch 954/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5371 - val_loss: 0.6886 - val_accuracy: 0.5263\n",
            "Epoch 955/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5352 - val_loss: 0.6886 - val_accuracy: 0.5343\n",
            "Epoch 956/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5349 - val_loss: 0.6880 - val_accuracy: 0.5223\n",
            "Epoch 957/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6834 - accuracy: 0.5345 - val_loss: 0.6882 - val_accuracy: 0.5313\n",
            "Epoch 958/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5337 - val_loss: 0.6894 - val_accuracy: 0.5178\n",
            "Epoch 959/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5351 - val_loss: 0.6891 - val_accuracy: 0.5343\n",
            "Epoch 960/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5343 - val_loss: 0.6889 - val_accuracy: 0.5268\n",
            "Epoch 961/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5366 - val_loss: 0.6894 - val_accuracy: 0.5253\n",
            "Epoch 962/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5352 - val_loss: 0.6890 - val_accuracy: 0.5318\n",
            "Epoch 963/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5292 - val_loss: 0.6884 - val_accuracy: 0.5273\n",
            "Epoch 964/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.5372 - val_loss: 0.6899 - val_accuracy: 0.5258\n",
            "Epoch 965/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5375 - val_loss: 0.6882 - val_accuracy: 0.5218\n",
            "Epoch 966/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5356 - val_loss: 0.6886 - val_accuracy: 0.5288\n",
            "Epoch 967/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6836 - accuracy: 0.5398 - val_loss: 0.6885 - val_accuracy: 0.5258\n",
            "Epoch 968/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6841 - accuracy: 0.5352 - val_loss: 0.6888 - val_accuracy: 0.5253\n",
            "Epoch 969/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5346 - val_loss: 0.6886 - val_accuracy: 0.5168\n",
            "Epoch 970/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5314 - val_loss: 0.6872 - val_accuracy: 0.5258\n",
            "Epoch 971/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5320 - val_loss: 0.6874 - val_accuracy: 0.5233\n",
            "Epoch 972/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5360 - val_loss: 0.6887 - val_accuracy: 0.5283\n",
            "Epoch 973/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5333 - val_loss: 0.6878 - val_accuracy: 0.5263\n",
            "Epoch 974/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5331 - val_loss: 0.6887 - val_accuracy: 0.5298\n",
            "Epoch 975/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5371 - val_loss: 0.6894 - val_accuracy: 0.5288\n",
            "Epoch 976/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5332 - val_loss: 0.6881 - val_accuracy: 0.5293\n",
            "Epoch 977/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5352 - val_loss: 0.6891 - val_accuracy: 0.5313\n",
            "Epoch 978/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6893 - val_accuracy: 0.5288\n",
            "Epoch 979/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5356 - val_loss: 0.6885 - val_accuracy: 0.5248\n",
            "Epoch 980/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5373 - val_loss: 0.6884 - val_accuracy: 0.5258\n",
            "Epoch 981/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5326 - val_loss: 0.6895 - val_accuracy: 0.5213\n",
            "Epoch 982/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5361 - val_loss: 0.6906 - val_accuracy: 0.5313\n",
            "Epoch 983/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5362 - val_loss: 0.6884 - val_accuracy: 0.5308\n",
            "Epoch 984/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5352 - val_loss: 0.6902 - val_accuracy: 0.5218\n",
            "Epoch 985/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5375 - val_loss: 0.6886 - val_accuracy: 0.5293\n",
            "Epoch 986/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5371 - val_loss: 0.6877 - val_accuracy: 0.5363\n",
            "Epoch 987/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5345 - val_loss: 0.6878 - val_accuracy: 0.5248\n",
            "Epoch 988/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5325 - val_loss: 0.6883 - val_accuracy: 0.5328\n",
            "Epoch 989/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5371 - val_loss: 0.6888 - val_accuracy: 0.5238\n",
            "Epoch 990/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5327 - val_loss: 0.6884 - val_accuracy: 0.5138\n",
            "Epoch 991/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5336 - val_loss: 0.6904 - val_accuracy: 0.5208\n",
            "Epoch 992/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5361 - val_loss: 0.6889 - val_accuracy: 0.5308\n",
            "Epoch 993/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5315 - val_loss: 0.6910 - val_accuracy: 0.5238\n",
            "Epoch 994/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5335 - val_loss: 0.6875 - val_accuracy: 0.5243\n",
            "Epoch 995/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5346 - val_loss: 0.6901 - val_accuracy: 0.5268\n",
            "Epoch 996/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5333 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
            "Epoch 997/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5362 - val_loss: 0.6883 - val_accuracy: 0.5238\n",
            "Epoch 998/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6838 - accuracy: 0.5362 - val_loss: 0.6864 - val_accuracy: 0.5313\n",
            "Epoch 999/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.5351 - val_loss: 0.6887 - val_accuracy: 0.5233\n",
            "Epoch 1000/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5374 - val_loss: 0.6889 - val_accuracy: 0.5233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2430fa0650>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Nationwide_AAnalytics/Over_Randon.h5')"
      ],
      "metadata": {
        "id": "JB7LeiZIkpPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Accuracy = \", (acc * 100.0), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoGjRBzC9ZAr",
        "outputId": "d7bc0fe5-e997-41d0-a9ba-5063bb00d8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5239\n",
            "Accuracy =  52.391695976257324 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu0f8EJx9Y94",
        "outputId": "8f26e057-cdde-4d45-d8f1-cd585381133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.8574958e-14, 2.6520552e-10, 1.2199691e-08, 2.0078751e-07,\n",
              "       1.7396949e-06, 7.8866024e-06, 1.1136751e-05, 2.3698185e-05,\n",
              "       2.9924512e-04, 1.0662645e-02, 3.5373718e-02, 1.1754826e-01,\n",
              "       2.0386985e-01, 2.0619947e-01, 2.0619974e-01, 2.4818897e-01,\n",
              "       2.7210739e-01, 2.8592545e-01, 2.9333386e-01, 3.2902017e-01,\n",
              "       3.3155400e-01, 3.4073341e-01, 3.4913766e-01, 3.6189336e-01,\n",
              "       3.6277086e-01, 3.7101483e-01, 3.7335551e-01, 3.7393785e-01,\n",
              "       3.7411612e-01, 3.7903535e-01, 3.8723302e-01, 3.9390153e-01,\n",
              "       3.9563024e-01, 3.9689738e-01, 4.0231252e-01, 4.0431502e-01,\n",
              "       4.0431505e-01, 4.0521389e-01, 4.0578601e-01, 4.0733635e-01,\n",
              "       4.1328639e-01, 4.1341114e-01, 4.1689417e-01, 4.1731715e-01,\n",
              "       4.2265686e-01, 4.2265695e-01, 4.2407700e-01, 4.2407703e-01,\n",
              "       4.2658132e-01, 4.2704254e-01, 4.2704257e-01, 4.2759824e-01,\n",
              "       4.3065831e-01, 4.3119779e-01, 4.3207061e-01, 4.3361068e-01,\n",
              "       4.3537527e-01, 4.3651167e-01, 4.3704432e-01, 4.3767315e-01,\n",
              "       4.3798190e-01, 4.3945327e-01, 4.4050255e-01, 4.4078568e-01,\n",
              "       4.4078571e-01, 4.4175822e-01, 4.4320315e-01, 4.4487649e-01,\n",
              "       4.4752544e-01, 4.4801489e-01, 4.4965717e-01, 4.5058197e-01,\n",
              "       4.5246831e-01, 4.5246840e-01, 4.5250499e-01, 4.5250502e-01,\n",
              "       4.5269373e-01, 4.5291245e-01, 4.5399600e-01, 4.5421576e-01,\n",
              "       4.5462018e-01, 4.5516834e-01, 4.5517460e-01, 4.5577145e-01,\n",
              "       4.5625076e-01, 4.5762336e-01, 4.5762339e-01, 4.5775405e-01,\n",
              "       4.5794329e-01, 4.6007249e-01, 4.6031582e-01, 4.6053055e-01,\n",
              "       4.6214700e-01, 4.6228942e-01, 4.6273449e-01, 4.6441802e-01,\n",
              "       4.6623653e-01, 4.6679863e-01, 4.6738568e-01, 4.6777111e-01,\n",
              "       4.6841124e-01, 4.6841127e-01, 4.6847308e-01, 4.6847311e-01,\n",
              "       4.6852508e-01, 4.6864954e-01, 4.6989933e-01, 4.7039562e-01,\n",
              "       4.7039565e-01, 4.7090313e-01, 4.7094131e-01, 4.7138795e-01,\n",
              "       4.7199339e-01, 4.7199351e-01, 4.7204974e-01, 4.7239211e-01,\n",
              "       4.7263643e-01, 4.7324717e-01, 4.7327730e-01, 4.7461456e-01,\n",
              "       4.7537154e-01, 4.7567177e-01, 4.7624162e-01, 4.7643945e-01,\n",
              "       4.7652227e-01, 4.7654352e-01, 4.7686183e-01, 4.7752973e-01,\n",
              "       4.7780669e-01, 4.7783351e-01, 4.7785133e-01, 4.7810867e-01,\n",
              "       4.7835976e-01, 4.7891286e-01, 4.7933239e-01, 4.8021549e-01,\n",
              "       4.8043633e-01, 4.8043635e-01, 4.8119920e-01, 4.8145020e-01,\n",
              "       4.8247749e-01, 4.8287266e-01, 4.8337105e-01, 4.8337108e-01,\n",
              "       4.8338544e-01, 4.8363611e-01, 4.8384196e-01, 4.8422223e-01,\n",
              "       4.8423043e-01, 4.8423049e-01, 4.8466167e-01, 4.8472700e-01,\n",
              "       4.8583928e-01, 4.8584005e-01, 4.8621860e-01, 4.8624778e-01,\n",
              "       4.8624781e-01, 4.8650035e-01, 4.8715097e-01, 4.8728511e-01,\n",
              "       4.8728514e-01, 4.8751536e-01, 4.8771426e-01, 4.8809817e-01,\n",
              "       4.8812863e-01, 4.8827484e-01, 4.8914692e-01, 4.8926410e-01,\n",
              "       4.8926419e-01, 4.8942250e-01, 4.8942253e-01, 4.8964563e-01,\n",
              "       4.8964566e-01, 4.9006376e-01, 4.9035704e-01, 4.9062464e-01,\n",
              "       4.9066094e-01, 4.9078843e-01, 4.9208444e-01, 4.9339920e-01,\n",
              "       4.9426502e-01, 4.9440348e-01, 4.9460596e-01, 4.9470612e-01,\n",
              "       4.9514288e-01, 4.9518645e-01, 4.9518654e-01, 4.9699751e-01,\n",
              "       4.9699754e-01, 4.9780294e-01, 4.9803180e-01, 4.9886569e-01,\n",
              "       4.9886572e-01, 4.9896544e-01, 4.9966079e-01, 4.9979109e-01,\n",
              "       5.0053382e-01, 5.0061345e-01, 5.0128418e-01, 5.0152165e-01,\n",
              "       5.0188452e-01, 5.0219756e-01, 5.0231475e-01, 5.0242984e-01,\n",
              "       5.0262862e-01, 5.0323963e-01, 5.0323969e-01, 5.0376910e-01,\n",
              "       5.0463051e-01, 5.0482786e-01, 5.0520688e-01, 5.0525963e-01,\n",
              "       5.0551975e-01, 5.0563097e-01, 5.0592655e-01, 5.0694942e-01,\n",
              "       5.0700963e-01, 5.0768054e-01, 5.0793409e-01, 5.0825006e-01,\n",
              "       5.0825012e-01, 5.0832283e-01, 5.0857854e-01, 5.0975507e-01,\n",
              "       5.1043135e-01, 5.1169026e-01, 5.1169032e-01, 5.1205796e-01,\n",
              "       5.1302212e-01, 5.1322347e-01, 5.1325768e-01, 5.1329678e-01,\n",
              "       5.1367939e-01, 5.1567149e-01, 5.1618028e-01, 5.1618034e-01,\n",
              "       5.1782292e-01, 5.1786828e-01, 5.1795989e-01, 5.1934749e-01,\n",
              "       5.2041799e-01, 5.2103847e-01, 5.2107179e-01, 5.2139157e-01,\n",
              "       5.2145135e-01, 5.2221769e-01, 5.2259833e-01, 5.2295691e-01,\n",
              "       5.2326638e-01, 5.2357620e-01, 5.2394718e-01, 5.2506995e-01,\n",
              "       5.2543736e-01, 5.2546567e-01, 5.2592677e-01, 5.2606571e-01,\n",
              "       5.2692711e-01, 5.2723932e-01, 5.2731025e-01, 5.2796638e-01,\n",
              "       5.2841622e-01, 5.2963030e-01, 5.2988809e-01, 5.3072792e-01,\n",
              "       5.3090417e-01, 5.3090423e-01, 5.3109890e-01, 5.3201503e-01,\n",
              "       5.3258187e-01, 5.3307468e-01, 5.3371316e-01, 5.3517592e-01,\n",
              "       5.3654689e-01, 5.3655303e-01, 5.3694981e-01, 5.3745019e-01,\n",
              "       5.3758633e-01, 5.3808278e-01, 5.3824079e-01, 5.3826976e-01,\n",
              "       5.3835326e-01, 5.3835332e-01, 5.3908300e-01, 5.3920102e-01,\n",
              "       5.3955376e-01, 5.3963321e-01, 5.3995192e-01, 5.4007983e-01,\n",
              "       5.4060584e-01, 5.4292780e-01, 5.4354292e-01, 5.4360437e-01,\n",
              "       5.4441208e-01, 5.4479074e-01, 5.4523087e-01, 5.4528767e-01,\n",
              "       5.4528773e-01, 5.4662991e-01, 5.4805881e-01, 5.4956114e-01,\n",
              "       5.4997778e-01, 5.4997784e-01, 5.5047458e-01, 5.5136091e-01,\n",
              "       5.5136096e-01, 5.5204725e-01, 5.5214292e-01, 5.5373091e-01,\n",
              "       5.5437559e-01, 5.5671924e-01, 5.5741888e-01, 5.5741894e-01,\n",
              "       5.5783957e-01, 5.5876410e-01, 5.5936265e-01, 5.5984735e-01,\n",
              "       5.6029671e-01, 5.6055748e-01, 5.6279665e-01, 5.6395894e-01,\n",
              "       5.6418544e-01, 5.6665456e-01, 5.6882966e-01, 5.6990516e-01,\n",
              "       5.7045037e-01, 5.7045043e-01, 5.7129371e-01, 5.7210493e-01,\n",
              "       5.7298052e-01, 5.7304960e-01, 5.7388270e-01, 5.7388276e-01,\n",
              "       5.7493520e-01, 5.7545274e-01, 5.7645655e-01, 5.7675606e-01,\n",
              "       5.7791477e-01, 5.7862818e-01, 5.7889366e-01, 5.7889372e-01,\n",
              "       5.7902586e-01, 5.9184289e-01, 5.9212065e-01, 5.9236497e-01,\n",
              "       5.9338731e-01, 5.9339523e-01, 5.9364086e-01, 5.9364104e-01,\n",
              "       5.9793824e-01, 6.0306388e-01, 6.0393792e-01, 6.0529697e-01,\n",
              "       6.0534537e-01, 6.0773581e-01, 6.0836464e-01, 6.1006916e-01,\n",
              "       6.1057287e-01, 6.1660010e-01, 6.1752254e-01, 6.2239850e-01,\n",
              "       6.2336153e-01, 6.2427998e-01, 6.2649959e-01, 6.3604110e-01,\n",
              "       6.3662142e-01, 6.3773537e-01, 6.3937986e-01, 6.4214265e-01,\n",
              "       6.4491981e-01, 6.4565545e-01, 6.4777708e-01, 6.5930080e-01,\n",
              "       6.6271263e-01, 6.6318750e-01, 6.6357970e-01, 6.7043304e-01,\n",
              "       7.0381671e-01, 7.0430863e-01, 7.2112072e-01, 8.1660569e-01,\n",
              "       8.6552691e-01, 8.9682728e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU-VEMmB9Y7R",
        "outputId": "50793d15-3106-40df-ec87-9df0721c0815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "VqOlO8DB9Y46",
        "outputId": "05092623-9b62-4020-e247-2655a274d5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "g-f_Y8AV9Y2l",
        "outputId": "982dadc8-debd-457a-e178-3ca5bad4acca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.50      0.57      0.53      1054\\n           1       0.55      0.48      0.51      1162\\n\\n    accuracy                           0.52      2216\\n   macro avg       0.53      0.53      0.52      2216\\nweighted avg       0.53      0.52      0.52      2216\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test with unbalanced data\n",
        "y_pred = model.predict(X_ts)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "cm = confusion_matrix(Y_ts, y_pred)\n",
        "f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Ud6XUQSJpX3a",
        "outputId": "c4956284-9d08-4b6a-ccbf-d968386ed951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SMOTE**"
      ],
      "metadata": {
        "id": "jPByQrrXoADP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE()\n",
        "x_os, y_os = sm.fit_resample(base,asw)\n",
        "y_os.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5tL2M4L9Y0B",
        "outputId": "a3d71653-53af-4e86-d7fa-7e3b1faa84aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NEXT_INSPECTION_GRADE_C_OR_BELOW    22160\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_os.value_counts().plot.pie(autopct = '%.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8KRANLAK9Yxa",
        "outputId": "14c33cac-53c0-4031-a3c6-faf00507c7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2430fa0790>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_os, y_os, test_size = 0.1)"
      ],
      "metadata": {
        "id": "HSNbJ2K4oI8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,\n",
        "                    epochs=1000,\n",
        "                    validation_split = 0.1,\n",
        "                    #callbacks=[es_monitor]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw3LXIbB9Yuw",
        "outputId": "69df7338-bbf1-43e2-bc46-66f6e576c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5253 - val_loss: 0.6881 - val_accuracy: 0.5218\n",
            "Epoch 2/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5249 - val_loss: 0.6894 - val_accuracy: 0.5123\n",
            "Epoch 3/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5250 - val_loss: 0.6911 - val_accuracy: 0.5183\n",
            "Epoch 4/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6875 - accuracy: 0.5304 - val_loss: 0.6888 - val_accuracy: 0.5153\n",
            "Epoch 5/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5259 - val_loss: 0.6903 - val_accuracy: 0.5028\n",
            "Epoch 6/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5268 - val_loss: 0.6904 - val_accuracy: 0.5328\n",
            "Epoch 7/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6875 - accuracy: 0.5250 - val_loss: 0.6870 - val_accuracy: 0.5243\n",
            "Epoch 8/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5251 - val_loss: 0.6919 - val_accuracy: 0.5088\n",
            "Epoch 9/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5283 - val_loss: 0.6884 - val_accuracy: 0.5223\n",
            "Epoch 10/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5205 - val_loss: 0.6939 - val_accuracy: 0.5183\n",
            "Epoch 11/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5309 - val_loss: 0.6894 - val_accuracy: 0.5158\n",
            "Epoch 12/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5283 - val_loss: 0.6862 - val_accuracy: 0.5263\n",
            "Epoch 13/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5274 - val_loss: 0.6882 - val_accuracy: 0.5253\n",
            "Epoch 14/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5277 - val_loss: 0.6879 - val_accuracy: 0.5103\n",
            "Epoch 15/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5272 - val_loss: 0.6912 - val_accuracy: 0.5248\n",
            "Epoch 16/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5313 - val_loss: 0.6902 - val_accuracy: 0.5208\n",
            "Epoch 17/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5296 - val_loss: 0.6898 - val_accuracy: 0.5143\n",
            "Epoch 18/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6880 - accuracy: 0.5305 - val_loss: 0.6877 - val_accuracy: 0.5238\n",
            "Epoch 19/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5253 - val_loss: 0.6894 - val_accuracy: 0.5183\n",
            "Epoch 20/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5252 - val_loss: 0.6866 - val_accuracy: 0.5233\n",
            "Epoch 21/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5291 - val_loss: 0.6892 - val_accuracy: 0.5223\n",
            "Epoch 22/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5313 - val_loss: 0.6907 - val_accuracy: 0.5083\n",
            "Epoch 23/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5293 - val_loss: 0.6933 - val_accuracy: 0.5333\n",
            "Epoch 24/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5259 - val_loss: 0.6889 - val_accuracy: 0.5323\n",
            "Epoch 25/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5259 - val_loss: 0.6889 - val_accuracy: 0.5118\n",
            "Epoch 26/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5289 - val_loss: 0.6897 - val_accuracy: 0.5168\n",
            "Epoch 27/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5299 - val_loss: 0.6858 - val_accuracy: 0.5298\n",
            "Epoch 28/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5247 - val_loss: 0.6894 - val_accuracy: 0.5343\n",
            "Epoch 29/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5269 - val_loss: 0.6874 - val_accuracy: 0.5348\n",
            "Epoch 30/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5271 - val_loss: 0.6868 - val_accuracy: 0.5288\n",
            "Epoch 31/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5285 - val_loss: 0.6890 - val_accuracy: 0.5163\n",
            "Epoch 32/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5311 - val_loss: 0.6874 - val_accuracy: 0.5263\n",
            "Epoch 33/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6877 - accuracy: 0.5281 - val_loss: 0.6865 - val_accuracy: 0.5313\n",
            "Epoch 34/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5308 - val_loss: 0.6939 - val_accuracy: 0.5213\n",
            "Epoch 35/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5257 - val_loss: 0.6881 - val_accuracy: 0.5208\n",
            "Epoch 36/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5242 - val_loss: 0.6936 - val_accuracy: 0.5178\n",
            "Epoch 37/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5267 - val_loss: 0.6871 - val_accuracy: 0.5258\n",
            "Epoch 38/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6871 - accuracy: 0.5225 - val_loss: 0.6894 - val_accuracy: 0.5103\n",
            "Epoch 39/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5273 - val_loss: 0.6937 - val_accuracy: 0.5273\n",
            "Epoch 40/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5333 - val_loss: 0.6902 - val_accuracy: 0.5273\n",
            "Epoch 41/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5302 - val_loss: 0.6882 - val_accuracy: 0.5228\n",
            "Epoch 42/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5281 - val_loss: 0.6932 - val_accuracy: 0.5133\n",
            "Epoch 43/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5278 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
            "Epoch 44/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5299 - val_loss: 0.6880 - val_accuracy: 0.5248\n",
            "Epoch 45/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5271 - val_loss: 0.6886 - val_accuracy: 0.5248\n",
            "Epoch 46/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5237 - val_loss: 0.6883 - val_accuracy: 0.5248\n",
            "Epoch 47/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5277 - val_loss: 0.6885 - val_accuracy: 0.5278\n",
            "Epoch 48/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5211 - val_loss: 0.6875 - val_accuracy: 0.5243\n",
            "Epoch 49/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5282 - val_loss: 0.6883 - val_accuracy: 0.5293\n",
            "Epoch 50/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5264 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
            "Epoch 51/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5288 - val_loss: 0.6881 - val_accuracy: 0.5243\n",
            "Epoch 52/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
            "Epoch 53/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5258 - val_loss: 0.6920 - val_accuracy: 0.5243\n",
            "Epoch 54/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5281 - val_loss: 0.6911 - val_accuracy: 0.5293\n",
            "Epoch 55/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5287 - val_loss: 0.6915 - val_accuracy: 0.5233\n",
            "Epoch 56/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5290 - val_loss: 0.6872 - val_accuracy: 0.5223\n",
            "Epoch 57/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5297 - val_loss: 0.6874 - val_accuracy: 0.5273\n",
            "Epoch 58/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5256 - val_loss: 0.6877 - val_accuracy: 0.5233\n",
            "Epoch 59/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5318 - val_loss: 0.6946 - val_accuracy: 0.5218\n",
            "Epoch 60/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5300 - val_loss: 0.6869 - val_accuracy: 0.5278\n",
            "Epoch 61/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5283 - val_loss: 0.6893 - val_accuracy: 0.5278\n",
            "Epoch 62/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5288 - val_loss: 0.6871 - val_accuracy: 0.5218\n",
            "Epoch 63/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5294 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
            "Epoch 64/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5317 - val_loss: 0.6923 - val_accuracy: 0.5068\n",
            "Epoch 65/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.5260 - val_loss: 0.6879 - val_accuracy: 0.5213\n",
            "Epoch 66/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.5284 - val_loss: 0.6934 - val_accuracy: 0.5308\n",
            "Epoch 67/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5241 - val_loss: 0.6880 - val_accuracy: 0.5308\n",
            "Epoch 68/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5245 - val_loss: 0.6943 - val_accuracy: 0.5338\n",
            "Epoch 69/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5302 - val_loss: 0.6867 - val_accuracy: 0.5253\n",
            "Epoch 70/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5282 - val_loss: 0.6872 - val_accuracy: 0.5283\n",
            "Epoch 71/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5272 - val_loss: 0.6893 - val_accuracy: 0.5173\n",
            "Epoch 72/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5278 - val_loss: 0.6890 - val_accuracy: 0.5063\n",
            "Epoch 73/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5243 - val_loss: 0.6891 - val_accuracy: 0.5323\n",
            "Epoch 74/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5327 - val_loss: 0.6877 - val_accuracy: 0.5228\n",
            "Epoch 75/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5287 - val_loss: 0.6946 - val_accuracy: 0.5223\n",
            "Epoch 76/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5289 - val_loss: 0.6892 - val_accuracy: 0.5213\n",
            "Epoch 77/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5271 - val_loss: 0.6902 - val_accuracy: 0.5263\n",
            "Epoch 78/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5271 - val_loss: 0.6880 - val_accuracy: 0.5168\n",
            "Epoch 79/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5238 - val_loss: 0.6886 - val_accuracy: 0.5093\n",
            "Epoch 80/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5258 - val_loss: 0.6882 - val_accuracy: 0.5208\n",
            "Epoch 81/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5251 - val_loss: 0.6879 - val_accuracy: 0.5148\n",
            "Epoch 82/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5264 - val_loss: 0.6896 - val_accuracy: 0.5188\n",
            "Epoch 83/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5278 - val_loss: 0.6886 - val_accuracy: 0.5253\n",
            "Epoch 84/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5298 - val_loss: 0.6889 - val_accuracy: 0.5203\n",
            "Epoch 85/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5247 - val_loss: 0.6889 - val_accuracy: 0.5183\n",
            "Epoch 86/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5311 - val_loss: 0.6889 - val_accuracy: 0.5098\n",
            "Epoch 87/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5242 - val_loss: 0.6874 - val_accuracy: 0.5268\n",
            "Epoch 88/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5287 - val_loss: 0.6928 - val_accuracy: 0.5273\n",
            "Epoch 89/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5243 - val_loss: 0.6885 - val_accuracy: 0.5198\n",
            "Epoch 90/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5265 - val_loss: 0.6890 - val_accuracy: 0.5278\n",
            "Epoch 91/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5269 - val_loss: 0.6887 - val_accuracy: 0.5268\n",
            "Epoch 92/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5262 - val_loss: 0.6877 - val_accuracy: 0.5238\n",
            "Epoch 93/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5253 - val_loss: 0.6869 - val_accuracy: 0.5278\n",
            "Epoch 94/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5264 - val_loss: 0.6889 - val_accuracy: 0.5198\n",
            "Epoch 95/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5294 - val_loss: 0.6877 - val_accuracy: 0.5158\n",
            "Epoch 96/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5282 - val_loss: 0.6909 - val_accuracy: 0.5148\n",
            "Epoch 97/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5269 - val_loss: 0.6881 - val_accuracy: 0.5183\n",
            "Epoch 98/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5246 - val_loss: 0.6891 - val_accuracy: 0.5128\n",
            "Epoch 99/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5270 - val_loss: 0.6898 - val_accuracy: 0.5188\n",
            "Epoch 100/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5283 - val_loss: 0.6865 - val_accuracy: 0.5273\n",
            "Epoch 101/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5281 - val_loss: 0.6875 - val_accuracy: 0.5248\n",
            "Epoch 102/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5274 - val_loss: 0.6863 - val_accuracy: 0.5228\n",
            "Epoch 103/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5287 - val_loss: 0.6982 - val_accuracy: 0.5358\n",
            "Epoch 104/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5256 - val_loss: 0.6880 - val_accuracy: 0.5243\n",
            "Epoch 105/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5266 - val_loss: 0.6876 - val_accuracy: 0.5228\n",
            "Epoch 106/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5279 - val_loss: 0.6874 - val_accuracy: 0.5098\n",
            "Epoch 107/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5276 - val_loss: 0.6888 - val_accuracy: 0.5248\n",
            "Epoch 108/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
            "Epoch 109/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5297 - val_loss: 0.6885 - val_accuracy: 0.5223\n",
            "Epoch 110/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6868 - accuracy: 0.5268 - val_loss: 0.6869 - val_accuracy: 0.5198\n",
            "Epoch 111/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5310 - val_loss: 0.6872 - val_accuracy: 0.5198\n",
            "Epoch 112/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5259 - val_loss: 0.6884 - val_accuracy: 0.5248\n",
            "Epoch 113/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5247 - val_loss: 0.6924 - val_accuracy: 0.5088\n",
            "Epoch 114/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5294 - val_loss: 0.6885 - val_accuracy: 0.5283\n",
            "Epoch 115/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5248 - val_loss: 0.6906 - val_accuracy: 0.5258\n",
            "Epoch 116/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5306 - val_loss: 0.6872 - val_accuracy: 0.5303\n",
            "Epoch 117/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5253 - val_loss: 0.6903 - val_accuracy: 0.5318\n",
            "Epoch 118/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5341 - val_loss: 0.6878 - val_accuracy: 0.5218\n",
            "Epoch 119/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5233 - val_loss: 0.6876 - val_accuracy: 0.5248\n",
            "Epoch 120/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5292 - val_loss: 0.6903 - val_accuracy: 0.5208\n",
            "Epoch 121/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5282 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
            "Epoch 122/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5254 - val_loss: 0.6957 - val_accuracy: 0.5243\n",
            "Epoch 123/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5290 - val_loss: 0.6879 - val_accuracy: 0.5163\n",
            "Epoch 124/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5266 - val_loss: 0.6893 - val_accuracy: 0.5128\n",
            "Epoch 125/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5307 - val_loss: 0.6874 - val_accuracy: 0.5173\n",
            "Epoch 126/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5254 - val_loss: 0.6894 - val_accuracy: 0.5183\n",
            "Epoch 127/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5253 - val_loss: 0.6879 - val_accuracy: 0.5128\n",
            "Epoch 128/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5282 - val_loss: 0.6890 - val_accuracy: 0.5228\n",
            "Epoch 129/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5267 - val_loss: 0.6871 - val_accuracy: 0.5343\n",
            "Epoch 130/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5284 - val_loss: 0.6856 - val_accuracy: 0.5213\n",
            "Epoch 131/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5250 - val_loss: 0.6907 - val_accuracy: 0.5258\n",
            "Epoch 132/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5267 - val_loss: 0.6876 - val_accuracy: 0.5193\n",
            "Epoch 133/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5293 - val_loss: 0.6915 - val_accuracy: 0.5143\n",
            "Epoch 134/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5321 - val_loss: 0.6887 - val_accuracy: 0.5363\n",
            "Epoch 135/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5312 - val_loss: 0.6903 - val_accuracy: 0.5218\n",
            "Epoch 136/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5286 - val_loss: 0.6887 - val_accuracy: 0.5143\n",
            "Epoch 137/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5302 - val_loss: 0.6900 - val_accuracy: 0.5213\n",
            "Epoch 138/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5281 - val_loss: 0.6896 - val_accuracy: 0.5198\n",
            "Epoch 139/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5269 - val_loss: 0.6882 - val_accuracy: 0.5308\n",
            "Epoch 140/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5258 - val_loss: 0.6883 - val_accuracy: 0.5258\n",
            "Epoch 141/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5268 - val_loss: 0.6874 - val_accuracy: 0.5263\n",
            "Epoch 142/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5228 - val_loss: 0.6894 - val_accuracy: 0.5163\n",
            "Epoch 143/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6875 - accuracy: 0.5209 - val_loss: 0.6892 - val_accuracy: 0.5258\n",
            "Epoch 144/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5287 - val_loss: 0.6934 - val_accuracy: 0.5283\n",
            "Epoch 145/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5309 - val_loss: 0.6888 - val_accuracy: 0.5238\n",
            "Epoch 146/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5297 - val_loss: 0.6882 - val_accuracy: 0.5173\n",
            "Epoch 147/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5264 - val_loss: 0.6912 - val_accuracy: 0.5333\n",
            "Epoch 148/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5291 - val_loss: 0.6891 - val_accuracy: 0.5378\n",
            "Epoch 149/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5252 - val_loss: 0.6876 - val_accuracy: 0.5343\n",
            "Epoch 150/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5279 - val_loss: 0.6863 - val_accuracy: 0.5258\n",
            "Epoch 151/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5265 - val_loss: 0.6880 - val_accuracy: 0.5273\n",
            "Epoch 152/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5259 - val_loss: 0.6868 - val_accuracy: 0.5233\n",
            "Epoch 153/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5298 - val_loss: 0.6962 - val_accuracy: 0.5348\n",
            "Epoch 154/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5276 - val_loss: 0.6869 - val_accuracy: 0.5248\n",
            "Epoch 155/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5284 - val_loss: 0.6921 - val_accuracy: 0.5233\n",
            "Epoch 156/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5271 - val_loss: 0.6882 - val_accuracy: 0.5198\n",
            "Epoch 157/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5316 - val_loss: 0.6912 - val_accuracy: 0.5263\n",
            "Epoch 158/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5252 - val_loss: 0.6895 - val_accuracy: 0.5198\n",
            "Epoch 159/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5274 - val_loss: 0.6875 - val_accuracy: 0.5158\n",
            "Epoch 160/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5270 - val_loss: 0.6856 - val_accuracy: 0.5278\n",
            "Epoch 161/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5301 - val_loss: 0.6910 - val_accuracy: 0.5103\n",
            "Epoch 162/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5261 - val_loss: 0.6860 - val_accuracy: 0.5283\n",
            "Epoch 163/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5224 - val_loss: 0.6874 - val_accuracy: 0.5308\n",
            "Epoch 164/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5248 - val_loss: 0.6882 - val_accuracy: 0.5278\n",
            "Epoch 165/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5257 - val_loss: 0.6886 - val_accuracy: 0.5263\n",
            "Epoch 166/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5291 - val_loss: 0.6894 - val_accuracy: 0.5233\n",
            "Epoch 167/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5256 - val_loss: 0.6877 - val_accuracy: 0.5283\n",
            "Epoch 168/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5292 - val_loss: 0.6860 - val_accuracy: 0.5208\n",
            "Epoch 169/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5322 - val_loss: 0.6901 - val_accuracy: 0.5203\n",
            "Epoch 170/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5272 - val_loss: 0.6893 - val_accuracy: 0.5393\n",
            "Epoch 171/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5317 - val_loss: 0.6875 - val_accuracy: 0.5333\n",
            "Epoch 172/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6908 - val_accuracy: 0.5383\n",
            "Epoch 173/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5261 - val_loss: 0.6890 - val_accuracy: 0.5108\n",
            "Epoch 174/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5282 - val_loss: 0.6871 - val_accuracy: 0.5308\n",
            "Epoch 175/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5287 - val_loss: 0.6866 - val_accuracy: 0.5093\n",
            "Epoch 176/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5293 - val_loss: 0.6883 - val_accuracy: 0.5138\n",
            "Epoch 177/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5308 - val_loss: 0.6855 - val_accuracy: 0.5348\n",
            "Epoch 178/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5246 - val_loss: 0.6872 - val_accuracy: 0.5193\n",
            "Epoch 179/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5273 - val_loss: 0.6880 - val_accuracy: 0.5198\n",
            "Epoch 180/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5283 - val_loss: 0.6904 - val_accuracy: 0.5088\n",
            "Epoch 181/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5272 - val_loss: 0.6890 - val_accuracy: 0.5198\n",
            "Epoch 182/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5304 - val_loss: 0.6862 - val_accuracy: 0.5298\n",
            "Epoch 183/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5245 - val_loss: 0.6874 - val_accuracy: 0.5153\n",
            "Epoch 184/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5270 - val_loss: 0.6892 - val_accuracy: 0.5223\n",
            "Epoch 185/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5301 - val_loss: 0.6918 - val_accuracy: 0.5233\n",
            "Epoch 186/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5235 - val_loss: 0.6868 - val_accuracy: 0.5263\n",
            "Epoch 187/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5303 - val_loss: 0.6878 - val_accuracy: 0.5263\n",
            "Epoch 188/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5284 - val_loss: 0.6873 - val_accuracy: 0.5298\n",
            "Epoch 189/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5304 - val_loss: 0.6861 - val_accuracy: 0.5153\n",
            "Epoch 190/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5323 - val_loss: 0.6863 - val_accuracy: 0.5193\n",
            "Epoch 191/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5322 - val_loss: 0.6863 - val_accuracy: 0.5368\n",
            "Epoch 192/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5286 - val_loss: 0.6872 - val_accuracy: 0.5263\n",
            "Epoch 193/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5263 - val_loss: 0.6907 - val_accuracy: 0.5123\n",
            "Epoch 194/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.5318 - val_loss: 0.6889 - val_accuracy: 0.5198\n",
            "Epoch 195/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5305 - val_loss: 0.6899 - val_accuracy: 0.5138\n",
            "Epoch 196/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5291 - val_loss: 0.6894 - val_accuracy: 0.5153\n",
            "Epoch 197/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5284 - val_loss: 0.6897 - val_accuracy: 0.4967\n",
            "Epoch 198/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5281 - val_loss: 0.6892 - val_accuracy: 0.5203\n",
            "Epoch 199/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5287 - val_loss: 0.6955 - val_accuracy: 0.5228\n",
            "Epoch 200/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5283 - val_loss: 0.6882 - val_accuracy: 0.5268\n",
            "Epoch 201/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5306 - val_loss: 0.6890 - val_accuracy: 0.5113\n",
            "Epoch 202/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6870 - accuracy: 0.5327 - val_loss: 0.6884 - val_accuracy: 0.5273\n",
            "Epoch 203/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5278 - val_loss: 0.6916 - val_accuracy: 0.5258\n",
            "Epoch 204/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5288 - val_loss: 0.6898 - val_accuracy: 0.5238\n",
            "Epoch 205/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5252 - val_loss: 0.6874 - val_accuracy: 0.5218\n",
            "Epoch 206/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5297 - val_loss: 0.6902 - val_accuracy: 0.5088\n",
            "Epoch 207/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5286 - val_loss: 0.6875 - val_accuracy: 0.5218\n",
            "Epoch 208/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5318 - val_loss: 0.6907 - val_accuracy: 0.5058\n",
            "Epoch 209/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5280 - val_loss: 0.6881 - val_accuracy: 0.5213\n",
            "Epoch 210/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5301 - val_loss: 0.6865 - val_accuracy: 0.5303\n",
            "Epoch 211/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5312 - val_loss: 0.6913 - val_accuracy: 0.5233\n",
            "Epoch 212/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5297 - val_loss: 0.6889 - val_accuracy: 0.5278\n",
            "Epoch 213/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5311 - val_loss: 0.6900 - val_accuracy: 0.5193\n",
            "Epoch 214/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5300 - val_loss: 0.6893 - val_accuracy: 0.5243\n",
            "Epoch 215/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5304 - val_loss: 0.6888 - val_accuracy: 0.5228\n",
            "Epoch 216/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5279 - val_loss: 0.6898 - val_accuracy: 0.5178\n",
            "Epoch 217/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5308 - val_loss: 0.6874 - val_accuracy: 0.5228\n",
            "Epoch 218/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5302 - val_loss: 0.6864 - val_accuracy: 0.5243\n",
            "Epoch 219/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5281 - val_loss: 0.6859 - val_accuracy: 0.5348\n",
            "Epoch 220/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5303 - val_loss: 0.6870 - val_accuracy: 0.5348\n",
            "Epoch 221/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5329 - val_loss: 0.6889 - val_accuracy: 0.5308\n",
            "Epoch 222/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5253 - val_loss: 0.6937 - val_accuracy: 0.5228\n",
            "Epoch 223/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5269 - val_loss: 0.6857 - val_accuracy: 0.5218\n",
            "Epoch 224/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5297 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
            "Epoch 225/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5321 - val_loss: 0.6918 - val_accuracy: 0.5268\n",
            "Epoch 226/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5306 - val_loss: 0.6897 - val_accuracy: 0.5313\n",
            "Epoch 227/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5304 - val_loss: 0.6867 - val_accuracy: 0.5268\n",
            "Epoch 228/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5304 - val_loss: 0.6892 - val_accuracy: 0.5183\n",
            "Epoch 229/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5304 - val_loss: 0.6879 - val_accuracy: 0.5188\n",
            "Epoch 230/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.5289 - val_loss: 0.6884 - val_accuracy: 0.5268\n",
            "Epoch 231/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5306 - val_loss: 0.6885 - val_accuracy: 0.5178\n",
            "Epoch 232/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5270 - val_loss: 0.6881 - val_accuracy: 0.5258\n",
            "Epoch 233/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5299 - val_loss: 0.6912 - val_accuracy: 0.5003\n",
            "Epoch 234/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5271 - val_loss: 0.6862 - val_accuracy: 0.5328\n",
            "Epoch 235/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5282 - val_loss: 0.6894 - val_accuracy: 0.5404\n",
            "Epoch 236/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5323 - val_loss: 0.6878 - val_accuracy: 0.5238\n",
            "Epoch 237/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5343 - val_loss: 0.6875 - val_accuracy: 0.5338\n",
            "Epoch 238/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5301 - val_loss: 0.6910 - val_accuracy: 0.5158\n",
            "Epoch 239/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5315 - val_loss: 0.6897 - val_accuracy: 0.5313\n",
            "Epoch 240/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5303 - val_loss: 0.6935 - val_accuracy: 0.5323\n",
            "Epoch 241/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5253 - val_loss: 0.6888 - val_accuracy: 0.5208\n",
            "Epoch 242/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5265 - val_loss: 0.6883 - val_accuracy: 0.5323\n",
            "Epoch 243/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5324 - val_loss: 0.6881 - val_accuracy: 0.5258\n",
            "Epoch 244/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5294 - val_loss: 0.6882 - val_accuracy: 0.5233\n",
            "Epoch 245/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5279 - val_loss: 0.6904 - val_accuracy: 0.5228\n",
            "Epoch 246/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5286 - val_loss: 0.6890 - val_accuracy: 0.5158\n",
            "Epoch 247/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5283 - val_loss: 0.6875 - val_accuracy: 0.5273\n",
            "Epoch 248/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5287 - val_loss: 0.6888 - val_accuracy: 0.5208\n",
            "Epoch 249/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5307 - val_loss: 0.6885 - val_accuracy: 0.5218\n",
            "Epoch 250/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5272 - val_loss: 0.6910 - val_accuracy: 0.5388\n",
            "Epoch 251/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5293 - val_loss: 0.6887 - val_accuracy: 0.5208\n",
            "Epoch 252/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5274 - val_loss: 0.6878 - val_accuracy: 0.5308\n",
            "Epoch 253/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5341 - val_loss: 0.6874 - val_accuracy: 0.5223\n",
            "Epoch 254/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5299 - val_loss: 0.6893 - val_accuracy: 0.5273\n",
            "Epoch 255/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5314 - val_loss: 0.6875 - val_accuracy: 0.5233\n",
            "Epoch 256/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5265 - val_loss: 0.6929 - val_accuracy: 0.5298\n",
            "Epoch 257/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5312 - val_loss: 0.6873 - val_accuracy: 0.5213\n",
            "Epoch 258/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5265 - val_loss: 0.6903 - val_accuracy: 0.5283\n",
            "Epoch 259/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5323 - val_loss: 0.6877 - val_accuracy: 0.5353\n",
            "Epoch 260/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5312 - val_loss: 0.6870 - val_accuracy: 0.5313\n",
            "Epoch 261/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5270 - val_loss: 0.6961 - val_accuracy: 0.5459\n",
            "Epoch 262/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6866 - accuracy: 0.5289 - val_loss: 0.6907 - val_accuracy: 0.5308\n",
            "Epoch 263/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5288 - val_loss: 0.6896 - val_accuracy: 0.5228\n",
            "Epoch 264/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.5283 - val_loss: 0.6894 - val_accuracy: 0.5248\n",
            "Epoch 265/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5286 - val_loss: 0.6890 - val_accuracy: 0.5138\n",
            "Epoch 266/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5259 - val_loss: 0.6869 - val_accuracy: 0.5393\n",
            "Epoch 267/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5283 - val_loss: 0.6869 - val_accuracy: 0.5218\n",
            "Epoch 268/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5321 - val_loss: 0.6890 - val_accuracy: 0.5253\n",
            "Epoch 269/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5284 - val_loss: 0.6888 - val_accuracy: 0.5288\n",
            "Epoch 270/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5290 - val_loss: 0.6877 - val_accuracy: 0.5168\n",
            "Epoch 271/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5273 - val_loss: 0.6872 - val_accuracy: 0.5278\n",
            "Epoch 272/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5312 - val_loss: 0.6867 - val_accuracy: 0.5308\n",
            "Epoch 273/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5253 - val_loss: 0.6906 - val_accuracy: 0.5268\n",
            "Epoch 274/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5304 - val_loss: 0.6903 - val_accuracy: 0.5213\n",
            "Epoch 275/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5325 - val_loss: 0.6883 - val_accuracy: 0.5323\n",
            "Epoch 276/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5322 - val_loss: 0.6892 - val_accuracy: 0.5233\n",
            "Epoch 277/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5316 - val_loss: 0.6974 - val_accuracy: 0.5424\n",
            "Epoch 278/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5273 - val_loss: 0.6883 - val_accuracy: 0.5173\n",
            "Epoch 279/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5308 - val_loss: 0.6885 - val_accuracy: 0.5333\n",
            "Epoch 280/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5279 - val_loss: 0.6860 - val_accuracy: 0.5308\n",
            "Epoch 281/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5297 - val_loss: 0.6876 - val_accuracy: 0.5253\n",
            "Epoch 282/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5293 - val_loss: 0.6935 - val_accuracy: 0.5283\n",
            "Epoch 283/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5304 - val_loss: 0.6898 - val_accuracy: 0.5198\n",
            "Epoch 284/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5296 - val_loss: 0.6897 - val_accuracy: 0.5353\n",
            "Epoch 285/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5294 - val_loss: 0.6952 - val_accuracy: 0.5383\n",
            "Epoch 286/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5299 - val_loss: 0.6907 - val_accuracy: 0.5248\n",
            "Epoch 287/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5278 - val_loss: 0.6881 - val_accuracy: 0.5348\n",
            "Epoch 288/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5283 - val_loss: 0.6867 - val_accuracy: 0.5278\n",
            "Epoch 289/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5278 - val_loss: 0.6877 - val_accuracy: 0.5253\n",
            "Epoch 290/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5270 - val_loss: 0.6888 - val_accuracy: 0.5253\n",
            "Epoch 291/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5298 - val_loss: 0.6881 - val_accuracy: 0.5168\n",
            "Epoch 292/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5302 - val_loss: 0.6882 - val_accuracy: 0.5273\n",
            "Epoch 293/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5297 - val_loss: 0.6916 - val_accuracy: 0.5098\n",
            "Epoch 294/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5287 - val_loss: 0.6881 - val_accuracy: 0.5338\n",
            "Epoch 295/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5240 - val_loss: 0.6875 - val_accuracy: 0.5233\n",
            "Epoch 296/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5257 - val_loss: 0.6886 - val_accuracy: 0.5218\n",
            "Epoch 297/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5318 - val_loss: 0.6903 - val_accuracy: 0.5253\n",
            "Epoch 298/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5284 - val_loss: 0.6895 - val_accuracy: 0.5253\n",
            "Epoch 299/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5336 - val_loss: 0.6911 - val_accuracy: 0.5313\n",
            "Epoch 300/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5272 - val_loss: 0.6894 - val_accuracy: 0.5218\n",
            "Epoch 301/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5333 - val_loss: 0.6856 - val_accuracy: 0.5243\n",
            "Epoch 302/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5303 - val_loss: 0.6874 - val_accuracy: 0.5368\n",
            "Epoch 303/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5333 - val_loss: 0.6878 - val_accuracy: 0.5238\n",
            "Epoch 304/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5237 - val_loss: 0.6899 - val_accuracy: 0.5183\n",
            "Epoch 305/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5254 - val_loss: 0.6896 - val_accuracy: 0.5198\n",
            "Epoch 306/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5294 - val_loss: 0.6876 - val_accuracy: 0.5348\n",
            "Epoch 307/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5266 - val_loss: 0.6890 - val_accuracy: 0.5263\n",
            "Epoch 308/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5227 - val_loss: 0.6877 - val_accuracy: 0.5163\n",
            "Epoch 309/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5284 - val_loss: 0.6906 - val_accuracy: 0.5213\n",
            "Epoch 310/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5294 - val_loss: 0.6909 - val_accuracy: 0.5273\n",
            "Epoch 311/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5294 - val_loss: 0.6880 - val_accuracy: 0.5188\n",
            "Epoch 312/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5312 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
            "Epoch 313/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5294 - val_loss: 0.6887 - val_accuracy: 0.5328\n",
            "Epoch 314/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5267 - val_loss: 0.6883 - val_accuracy: 0.5163\n",
            "Epoch 315/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5308 - val_loss: 0.6888 - val_accuracy: 0.5128\n",
            "Epoch 316/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5278 - val_loss: 0.6885 - val_accuracy: 0.5303\n",
            "Epoch 317/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5279 - val_loss: 0.6887 - val_accuracy: 0.5318\n",
            "Epoch 318/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5290 - val_loss: 0.6879 - val_accuracy: 0.5123\n",
            "Epoch 319/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5317 - val_loss: 0.6924 - val_accuracy: 0.5313\n",
            "Epoch 320/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5293 - val_loss: 0.6907 - val_accuracy: 0.5133\n",
            "Epoch 321/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5273 - val_loss: 0.6876 - val_accuracy: 0.5308\n",
            "Epoch 322/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5265 - val_loss: 0.6882 - val_accuracy: 0.5298\n",
            "Epoch 323/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5296 - val_loss: 0.6887 - val_accuracy: 0.5238\n",
            "Epoch 324/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5289 - val_loss: 0.6900 - val_accuracy: 0.5193\n",
            "Epoch 325/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5279 - val_loss: 0.6892 - val_accuracy: 0.5398\n",
            "Epoch 326/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5258 - val_loss: 0.6897 - val_accuracy: 0.5138\n",
            "Epoch 327/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5248 - val_loss: 0.6914 - val_accuracy: 0.5233\n",
            "Epoch 328/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5321 - val_loss: 0.6877 - val_accuracy: 0.5273\n",
            "Epoch 329/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5305 - val_loss: 0.6870 - val_accuracy: 0.5293\n",
            "Epoch 330/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5282 - val_loss: 0.6884 - val_accuracy: 0.5198\n",
            "Epoch 331/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5297 - val_loss: 0.6928 - val_accuracy: 0.5183\n",
            "Epoch 332/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5295 - val_loss: 0.6904 - val_accuracy: 0.5263\n",
            "Epoch 333/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5266 - val_loss: 0.6889 - val_accuracy: 0.5288\n",
            "Epoch 334/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5269 - val_loss: 0.6917 - val_accuracy: 0.5173\n",
            "Epoch 335/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5302 - val_loss: 0.6916 - val_accuracy: 0.5223\n",
            "Epoch 336/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5265 - val_loss: 0.6892 - val_accuracy: 0.5233\n",
            "Epoch 337/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5343 - val_loss: 0.6880 - val_accuracy: 0.5363\n",
            "Epoch 338/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5292 - val_loss: 0.6903 - val_accuracy: 0.5228\n",
            "Epoch 339/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5299 - val_loss: 0.6887 - val_accuracy: 0.5323\n",
            "Epoch 340/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5292 - val_loss: 0.6896 - val_accuracy: 0.5098\n",
            "Epoch 341/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5303 - val_loss: 0.6865 - val_accuracy: 0.5278\n",
            "Epoch 342/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5338 - val_loss: 0.6932 - val_accuracy: 0.5178\n",
            "Epoch 343/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5272 - val_loss: 0.6883 - val_accuracy: 0.5158\n",
            "Epoch 344/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5330 - val_loss: 0.6865 - val_accuracy: 0.5298\n",
            "Epoch 345/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5303 - val_loss: 0.6867 - val_accuracy: 0.5268\n",
            "Epoch 346/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5298 - val_loss: 0.6905 - val_accuracy: 0.5308\n",
            "Epoch 347/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5321 - val_loss: 0.6935 - val_accuracy: 0.5203\n",
            "Epoch 348/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5301 - val_loss: 0.6892 - val_accuracy: 0.5238\n",
            "Epoch 349/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5296 - val_loss: 0.6886 - val_accuracy: 0.5273\n",
            "Epoch 350/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5277 - val_loss: 0.6884 - val_accuracy: 0.5278\n",
            "Epoch 351/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5269 - val_loss: 0.6874 - val_accuracy: 0.5273\n",
            "Epoch 352/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5283 - val_loss: 0.6899 - val_accuracy: 0.5103\n",
            "Epoch 353/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5283 - val_loss: 0.6868 - val_accuracy: 0.5298\n",
            "Epoch 354/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5300 - val_loss: 0.6894 - val_accuracy: 0.5338\n",
            "Epoch 355/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5340 - val_loss: 0.6903 - val_accuracy: 0.5273\n",
            "Epoch 356/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5315 - val_loss: 0.6879 - val_accuracy: 0.5348\n",
            "Epoch 357/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5332 - val_loss: 0.6892 - val_accuracy: 0.5288\n",
            "Epoch 358/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5292 - val_loss: 0.6896 - val_accuracy: 0.5188\n",
            "Epoch 359/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5303 - val_loss: 0.6859 - val_accuracy: 0.5318\n",
            "Epoch 360/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5324 - val_loss: 0.6904 - val_accuracy: 0.5243\n",
            "Epoch 361/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5300 - val_loss: 0.6873 - val_accuracy: 0.5333\n",
            "Epoch 362/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5312 - val_loss: 0.6894 - val_accuracy: 0.5198\n",
            "Epoch 363/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5312 - val_loss: 0.6903 - val_accuracy: 0.5238\n",
            "Epoch 364/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5302 - val_loss: 0.6920 - val_accuracy: 0.5273\n",
            "Epoch 365/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5288 - val_loss: 0.6873 - val_accuracy: 0.5288\n",
            "Epoch 366/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5287 - val_loss: 0.6897 - val_accuracy: 0.5218\n",
            "Epoch 367/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5332 - val_loss: 0.6872 - val_accuracy: 0.5273\n",
            "Epoch 368/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5298 - val_loss: 0.6894 - val_accuracy: 0.5223\n",
            "Epoch 369/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5323 - val_loss: 0.6877 - val_accuracy: 0.5383\n",
            "Epoch 370/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5330 - val_loss: 0.6877 - val_accuracy: 0.5178\n",
            "Epoch 371/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5274 - val_loss: 0.6869 - val_accuracy: 0.5233\n",
            "Epoch 372/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6882 - val_accuracy: 0.5203\n",
            "Epoch 373/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5271 - val_loss: 0.6879 - val_accuracy: 0.5288\n",
            "Epoch 374/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5295 - val_loss: 0.6881 - val_accuracy: 0.5333\n",
            "Epoch 375/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5306 - val_loss: 0.6877 - val_accuracy: 0.5183\n",
            "Epoch 376/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5274 - val_loss: 0.6870 - val_accuracy: 0.5278\n",
            "Epoch 377/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5273 - val_loss: 0.6935 - val_accuracy: 0.5258\n",
            "Epoch 378/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5330 - val_loss: 0.6885 - val_accuracy: 0.5358\n",
            "Epoch 379/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5341 - val_loss: 0.6921 - val_accuracy: 0.5213\n",
            "Epoch 380/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5297 - val_loss: 0.6890 - val_accuracy: 0.5153\n",
            "Epoch 381/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5295 - val_loss: 0.6879 - val_accuracy: 0.5153\n",
            "Epoch 382/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5325 - val_loss: 0.6902 - val_accuracy: 0.5188\n",
            "Epoch 383/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5298 - val_loss: 0.6931 - val_accuracy: 0.5283\n",
            "Epoch 384/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5346 - val_loss: 0.6904 - val_accuracy: 0.5243\n",
            "Epoch 385/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5308 - val_loss: 0.6878 - val_accuracy: 0.5278\n",
            "Epoch 386/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5281 - val_loss: 0.6901 - val_accuracy: 0.5118\n",
            "Epoch 387/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.5294 - val_loss: 0.6898 - val_accuracy: 0.5158\n",
            "Epoch 388/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5350 - val_loss: 0.6868 - val_accuracy: 0.5404\n",
            "Epoch 389/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5268 - val_loss: 0.6880 - val_accuracy: 0.5083\n",
            "Epoch 390/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5315 - val_loss: 0.6901 - val_accuracy: 0.5153\n",
            "Epoch 391/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5311 - val_loss: 0.6891 - val_accuracy: 0.5338\n",
            "Epoch 392/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5276 - val_loss: 0.6869 - val_accuracy: 0.5268\n",
            "Epoch 393/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5281 - val_loss: 0.6889 - val_accuracy: 0.5208\n",
            "Epoch 394/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5298 - val_loss: 0.6890 - val_accuracy: 0.5178\n",
            "Epoch 395/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5300 - val_loss: 0.6899 - val_accuracy: 0.5158\n",
            "Epoch 396/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5284 - val_loss: 0.6882 - val_accuracy: 0.5353\n",
            "Epoch 397/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5308 - val_loss: 0.6890 - val_accuracy: 0.5158\n",
            "Epoch 398/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5298 - val_loss: 0.6921 - val_accuracy: 0.5253\n",
            "Epoch 399/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5333 - val_loss: 0.6876 - val_accuracy: 0.5323\n",
            "Epoch 400/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5307 - val_loss: 0.6887 - val_accuracy: 0.5273\n",
            "Epoch 401/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5322 - val_loss: 0.6897 - val_accuracy: 0.5213\n",
            "Epoch 402/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5273 - val_loss: 0.6887 - val_accuracy: 0.5273\n",
            "Epoch 403/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5286 - val_loss: 0.6884 - val_accuracy: 0.5183\n",
            "Epoch 404/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5317 - val_loss: 0.6899 - val_accuracy: 0.5358\n",
            "Epoch 405/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5293 - val_loss: 0.6881 - val_accuracy: 0.5398\n",
            "Epoch 406/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5319 - val_loss: 0.6897 - val_accuracy: 0.5138\n",
            "Epoch 407/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5322 - val_loss: 0.6868 - val_accuracy: 0.5328\n",
            "Epoch 408/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5303 - val_loss: 0.6884 - val_accuracy: 0.5113\n",
            "Epoch 409/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5315 - val_loss: 0.6956 - val_accuracy: 0.5143\n",
            "Epoch 410/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5315 - val_loss: 0.6869 - val_accuracy: 0.5353\n",
            "Epoch 411/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5301 - val_loss: 0.6885 - val_accuracy: 0.5268\n",
            "Epoch 412/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5252 - val_loss: 0.6895 - val_accuracy: 0.5243\n",
            "Epoch 413/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5327 - val_loss: 0.6899 - val_accuracy: 0.5188\n",
            "Epoch 414/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5278 - val_loss: 0.6890 - val_accuracy: 0.5268\n",
            "Epoch 415/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5345 - val_loss: 0.6889 - val_accuracy: 0.5148\n",
            "Epoch 416/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5316 - val_loss: 0.6895 - val_accuracy: 0.5263\n",
            "Epoch 417/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5322 - val_loss: 0.6902 - val_accuracy: 0.5323\n",
            "Epoch 418/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5301 - val_loss: 0.6882 - val_accuracy: 0.5414\n",
            "Epoch 419/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5310 - val_loss: 0.6908 - val_accuracy: 0.5203\n",
            "Epoch 420/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5298 - val_loss: 0.6870 - val_accuracy: 0.5278\n",
            "Epoch 421/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5271 - val_loss: 0.6876 - val_accuracy: 0.5173\n",
            "Epoch 422/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5320 - val_loss: 0.6946 - val_accuracy: 0.5118\n",
            "Epoch 423/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5301 - val_loss: 0.6902 - val_accuracy: 0.5283\n",
            "Epoch 424/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5319 - val_loss: 0.6895 - val_accuracy: 0.5363\n",
            "Epoch 425/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5313 - val_loss: 0.6880 - val_accuracy: 0.5308\n",
            "Epoch 426/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5316 - val_loss: 0.6881 - val_accuracy: 0.5278\n",
            "Epoch 427/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5343 - val_loss: 0.6921 - val_accuracy: 0.5093\n",
            "Epoch 428/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5269 - val_loss: 0.6891 - val_accuracy: 0.5213\n",
            "Epoch 429/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5291 - val_loss: 0.6886 - val_accuracy: 0.5338\n",
            "Epoch 430/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5311 - val_loss: 0.6887 - val_accuracy: 0.5283\n",
            "Epoch 431/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5273 - val_loss: 0.6895 - val_accuracy: 0.5153\n",
            "Epoch 432/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5358 - val_loss: 0.7043 - val_accuracy: 0.5393\n",
            "Epoch 433/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5262 - val_loss: 0.6885 - val_accuracy: 0.5263\n",
            "Epoch 434/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5335 - val_loss: 0.6889 - val_accuracy: 0.5273\n",
            "Epoch 435/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5298 - val_loss: 0.6866 - val_accuracy: 0.5298\n",
            "Epoch 436/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5301 - val_loss: 0.6881 - val_accuracy: 0.5358\n",
            "Epoch 437/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5278 - val_loss: 0.6865 - val_accuracy: 0.5163\n",
            "Epoch 438/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5303 - val_loss: 0.6912 - val_accuracy: 0.5183\n",
            "Epoch 439/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5333 - val_loss: 0.6900 - val_accuracy: 0.5183\n",
            "Epoch 440/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5293 - val_loss: 0.6900 - val_accuracy: 0.5424\n",
            "Epoch 441/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5281 - val_loss: 0.6900 - val_accuracy: 0.5098\n",
            "Epoch 442/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5290 - val_loss: 0.6869 - val_accuracy: 0.5333\n",
            "Epoch 443/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5269 - val_loss: 0.6891 - val_accuracy: 0.5243\n",
            "Epoch 444/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5273 - val_loss: 0.6901 - val_accuracy: 0.5439\n",
            "Epoch 445/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5342 - val_loss: 0.6871 - val_accuracy: 0.5368\n",
            "Epoch 446/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5343 - val_loss: 0.6864 - val_accuracy: 0.5313\n",
            "Epoch 447/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5310 - val_loss: 0.6898 - val_accuracy: 0.5283\n",
            "Epoch 448/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5331 - val_loss: 0.6874 - val_accuracy: 0.5313\n",
            "Epoch 449/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5279 - val_loss: 0.6876 - val_accuracy: 0.5143\n",
            "Epoch 450/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6864 - accuracy: 0.5251 - val_loss: 0.6889 - val_accuracy: 0.5243\n",
            "Epoch 451/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5304 - val_loss: 0.6870 - val_accuracy: 0.5358\n",
            "Epoch 452/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5322 - val_loss: 0.6876 - val_accuracy: 0.5158\n",
            "Epoch 453/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5305 - val_loss: 0.6875 - val_accuracy: 0.5263\n",
            "Epoch 454/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5325 - val_loss: 0.6862 - val_accuracy: 0.5258\n",
            "Epoch 455/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5281 - val_loss: 0.6876 - val_accuracy: 0.5198\n",
            "Epoch 456/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5282 - val_loss: 0.6879 - val_accuracy: 0.5333\n",
            "Epoch 457/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5352 - val_loss: 0.6881 - val_accuracy: 0.5404\n",
            "Epoch 458/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5282 - val_loss: 0.6887 - val_accuracy: 0.5173\n",
            "Epoch 459/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5311 - val_loss: 0.6884 - val_accuracy: 0.5163\n",
            "Epoch 460/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5320 - val_loss: 0.6906 - val_accuracy: 0.5213\n",
            "Epoch 461/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5313 - val_loss: 0.6878 - val_accuracy: 0.5228\n",
            "Epoch 462/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5286 - val_loss: 0.6901 - val_accuracy: 0.5118\n",
            "Epoch 463/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5303 - val_loss: 0.6868 - val_accuracy: 0.5348\n",
            "Epoch 464/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5306 - val_loss: 0.6865 - val_accuracy: 0.5328\n",
            "Epoch 465/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5306 - val_loss: 0.6903 - val_accuracy: 0.5168\n",
            "Epoch 466/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5321 - val_loss: 0.6910 - val_accuracy: 0.5263\n",
            "Epoch 467/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5336 - val_loss: 0.6880 - val_accuracy: 0.5208\n",
            "Epoch 468/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5309 - val_loss: 0.6896 - val_accuracy: 0.5173\n",
            "Epoch 469/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5325 - val_loss: 0.6885 - val_accuracy: 0.5163\n",
            "Epoch 470/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5304 - val_loss: 0.6886 - val_accuracy: 0.5404\n",
            "Epoch 471/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5302 - val_loss: 0.6876 - val_accuracy: 0.5333\n",
            "Epoch 472/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5338 - val_loss: 0.6907 - val_accuracy: 0.5383\n",
            "Epoch 473/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5338 - val_loss: 0.6890 - val_accuracy: 0.5253\n",
            "Epoch 474/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5278 - val_loss: 0.6888 - val_accuracy: 0.5353\n",
            "Epoch 475/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5313 - val_loss: 0.6926 - val_accuracy: 0.5068\n",
            "Epoch 476/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5309 - val_loss: 0.6878 - val_accuracy: 0.5283\n",
            "Epoch 477/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5327 - val_loss: 0.6910 - val_accuracy: 0.5258\n",
            "Epoch 478/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5299 - val_loss: 0.6926 - val_accuracy: 0.5073\n",
            "Epoch 479/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5311 - val_loss: 0.6913 - val_accuracy: 0.5263\n",
            "Epoch 480/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5294 - val_loss: 0.6896 - val_accuracy: 0.5283\n",
            "Epoch 481/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5287 - val_loss: 0.6877 - val_accuracy: 0.5153\n",
            "Epoch 482/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5304 - val_loss: 0.6882 - val_accuracy: 0.5459\n",
            "Epoch 483/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5286 - val_loss: 0.6895 - val_accuracy: 0.5378\n",
            "Epoch 484/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5327 - val_loss: 0.6895 - val_accuracy: 0.5223\n",
            "Epoch 485/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5361 - val_loss: 0.6887 - val_accuracy: 0.5178\n",
            "Epoch 486/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5295 - val_loss: 0.6891 - val_accuracy: 0.5103\n",
            "Epoch 487/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5318 - val_loss: 0.6879 - val_accuracy: 0.5148\n",
            "Epoch 488/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5306 - val_loss: 0.6883 - val_accuracy: 0.5168\n",
            "Epoch 489/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5306 - val_loss: 0.6911 - val_accuracy: 0.5238\n",
            "Epoch 490/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5300 - val_loss: 0.6935 - val_accuracy: 0.5138\n",
            "Epoch 491/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5302 - val_loss: 0.6877 - val_accuracy: 0.5308\n",
            "Epoch 492/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5337 - val_loss: 0.6927 - val_accuracy: 0.5308\n",
            "Epoch 493/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5311 - val_loss: 0.6902 - val_accuracy: 0.5303\n",
            "Epoch 494/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5257 - val_loss: 0.6889 - val_accuracy: 0.5383\n",
            "Epoch 495/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5270 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
            "Epoch 496/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5340 - val_loss: 0.6900 - val_accuracy: 0.5243\n",
            "Epoch 497/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5347 - val_loss: 0.6868 - val_accuracy: 0.5213\n",
            "Epoch 498/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5316 - val_loss: 0.6863 - val_accuracy: 0.5258\n",
            "Epoch 499/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5278 - val_loss: 0.6893 - val_accuracy: 0.5313\n",
            "Epoch 500/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5316 - val_loss: 0.6892 - val_accuracy: 0.5228\n",
            "Epoch 501/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5324 - val_loss: 0.6916 - val_accuracy: 0.5218\n",
            "Epoch 502/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5294 - val_loss: 0.6900 - val_accuracy: 0.5138\n",
            "Epoch 503/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5311 - val_loss: 0.6898 - val_accuracy: 0.5233\n",
            "Epoch 504/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5298 - val_loss: 0.6901 - val_accuracy: 0.5158\n",
            "Epoch 505/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5283 - val_loss: 0.6895 - val_accuracy: 0.5178\n",
            "Epoch 506/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5267 - val_loss: 0.6915 - val_accuracy: 0.5328\n",
            "Epoch 507/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5303 - val_loss: 0.6879 - val_accuracy: 0.5228\n",
            "Epoch 508/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5338 - val_loss: 0.6872 - val_accuracy: 0.5238\n",
            "Epoch 509/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5325 - val_loss: 0.6900 - val_accuracy: 0.5148\n",
            "Epoch 510/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5294 - val_loss: 0.6898 - val_accuracy: 0.5118\n",
            "Epoch 511/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5301 - val_loss: 0.6924 - val_accuracy: 0.5273\n",
            "Epoch 512/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5311 - val_loss: 0.6886 - val_accuracy: 0.5153\n",
            "Epoch 513/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5319 - val_loss: 0.6888 - val_accuracy: 0.5378\n",
            "Epoch 514/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5345 - val_loss: 0.6903 - val_accuracy: 0.5213\n",
            "Epoch 515/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5278 - val_loss: 0.6887 - val_accuracy: 0.5148\n",
            "Epoch 516/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5284 - val_loss: 0.6897 - val_accuracy: 0.5328\n",
            "Epoch 517/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5301 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
            "Epoch 518/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5280 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
            "Epoch 519/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5283 - val_loss: 0.6891 - val_accuracy: 0.5143\n",
            "Epoch 520/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5311 - val_loss: 0.6901 - val_accuracy: 0.5233\n",
            "Epoch 521/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5318 - val_loss: 0.6899 - val_accuracy: 0.5248\n",
            "Epoch 522/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5332 - val_loss: 0.6893 - val_accuracy: 0.5168\n",
            "Epoch 523/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5305 - val_loss: 0.6888 - val_accuracy: 0.5208\n",
            "Epoch 524/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5287 - val_loss: 0.6909 - val_accuracy: 0.5188\n",
            "Epoch 525/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5311 - val_loss: 0.6879 - val_accuracy: 0.5398\n",
            "Epoch 526/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5309 - val_loss: 0.6899 - val_accuracy: 0.5313\n",
            "Epoch 527/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5273 - val_loss: 0.6880 - val_accuracy: 0.5273\n",
            "Epoch 528/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5306 - val_loss: 0.6892 - val_accuracy: 0.5383\n",
            "Epoch 529/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5294 - val_loss: 0.6881 - val_accuracy: 0.5218\n",
            "Epoch 530/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5300 - val_loss: 0.6910 - val_accuracy: 0.5118\n",
            "Epoch 531/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5333 - val_loss: 0.6901 - val_accuracy: 0.5353\n",
            "Epoch 532/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5326 - val_loss: 0.6896 - val_accuracy: 0.5218\n",
            "Epoch 533/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5291 - val_loss: 0.6914 - val_accuracy: 0.5278\n",
            "Epoch 534/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5287 - val_loss: 0.6908 - val_accuracy: 0.5173\n",
            "Epoch 535/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5316 - val_loss: 0.6876 - val_accuracy: 0.5253\n",
            "Epoch 536/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5361 - val_loss: 0.6893 - val_accuracy: 0.5213\n",
            "Epoch 537/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5294 - val_loss: 0.6954 - val_accuracy: 0.5243\n",
            "Epoch 538/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5322 - val_loss: 0.6921 - val_accuracy: 0.5263\n",
            "Epoch 539/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5324 - val_loss: 0.6891 - val_accuracy: 0.5098\n",
            "Epoch 540/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5296 - val_loss: 0.6878 - val_accuracy: 0.5278\n",
            "Epoch 541/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5370 - val_loss: 0.6914 - val_accuracy: 0.5388\n",
            "Epoch 542/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5289 - val_loss: 0.6895 - val_accuracy: 0.5203\n",
            "Epoch 543/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5328 - val_loss: 0.6877 - val_accuracy: 0.5183\n",
            "Epoch 544/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5308 - val_loss: 0.6865 - val_accuracy: 0.5328\n",
            "Epoch 545/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5293 - val_loss: 0.6950 - val_accuracy: 0.5278\n",
            "Epoch 546/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5290 - val_loss: 0.6908 - val_accuracy: 0.5323\n",
            "Epoch 547/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5325 - val_loss: 0.6909 - val_accuracy: 0.5138\n",
            "Epoch 548/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5301 - val_loss: 0.6883 - val_accuracy: 0.5208\n",
            "Epoch 549/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5278 - val_loss: 0.6895 - val_accuracy: 0.5143\n",
            "Epoch 550/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5283 - val_loss: 0.6886 - val_accuracy: 0.5283\n",
            "Epoch 551/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5269 - val_loss: 0.6886 - val_accuracy: 0.5313\n",
            "Epoch 552/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5306 - val_loss: 0.6879 - val_accuracy: 0.5193\n",
            "Epoch 553/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5312 - val_loss: 0.6898 - val_accuracy: 0.5188\n",
            "Epoch 554/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5292 - val_loss: 0.6897 - val_accuracy: 0.5213\n",
            "Epoch 555/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5307 - val_loss: 0.6901 - val_accuracy: 0.5193\n",
            "Epoch 556/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5302 - val_loss: 0.6881 - val_accuracy: 0.5288\n",
            "Epoch 557/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5285 - val_loss: 0.6882 - val_accuracy: 0.5238\n",
            "Epoch 558/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5279 - val_loss: 0.6882 - val_accuracy: 0.5238\n",
            "Epoch 559/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5319 - val_loss: 0.6896 - val_accuracy: 0.5243\n",
            "Epoch 560/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5304 - val_loss: 0.6928 - val_accuracy: 0.5283\n",
            "Epoch 561/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5259 - val_loss: 0.6912 - val_accuracy: 0.5108\n",
            "Epoch 562/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5313 - val_loss: 0.6912 - val_accuracy: 0.5444\n",
            "Epoch 563/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5294 - val_loss: 0.6876 - val_accuracy: 0.5178\n",
            "Epoch 564/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5321 - val_loss: 0.6894 - val_accuracy: 0.5288\n",
            "Epoch 565/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5314 - val_loss: 0.6899 - val_accuracy: 0.5123\n",
            "Epoch 566/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5300 - val_loss: 0.6872 - val_accuracy: 0.5303\n",
            "Epoch 567/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5305 - val_loss: 0.6892 - val_accuracy: 0.5373\n",
            "Epoch 568/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5303 - val_loss: 0.6861 - val_accuracy: 0.5273\n",
            "Epoch 569/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5348 - val_loss: 0.6868 - val_accuracy: 0.5098\n",
            "Epoch 570/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5304 - val_loss: 0.6923 - val_accuracy: 0.5198\n",
            "Epoch 571/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5320 - val_loss: 0.6898 - val_accuracy: 0.5183\n",
            "Epoch 572/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5278 - val_loss: 0.6895 - val_accuracy: 0.5198\n",
            "Epoch 573/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5320 - val_loss: 0.6859 - val_accuracy: 0.5293\n",
            "Epoch 574/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5305 - val_loss: 0.6888 - val_accuracy: 0.5193\n",
            "Epoch 575/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5328 - val_loss: 0.6911 - val_accuracy: 0.5113\n",
            "Epoch 576/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5301 - val_loss: 0.7146 - val_accuracy: 0.5243\n",
            "Epoch 577/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5325 - val_loss: 0.6888 - val_accuracy: 0.5253\n",
            "Epoch 578/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5306 - val_loss: 0.6872 - val_accuracy: 0.5273\n",
            "Epoch 579/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5308 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
            "Epoch 580/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5342 - val_loss: 0.6881 - val_accuracy: 0.5328\n",
            "Epoch 581/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5308 - val_loss: 0.6865 - val_accuracy: 0.5233\n",
            "Epoch 582/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5338 - val_loss: 0.6874 - val_accuracy: 0.5398\n",
            "Epoch 583/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5295 - val_loss: 0.6895 - val_accuracy: 0.5168\n",
            "Epoch 584/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5324 - val_loss: 0.6878 - val_accuracy: 0.5288\n",
            "Epoch 585/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5290 - val_loss: 0.6924 - val_accuracy: 0.5183\n",
            "Epoch 586/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5326 - val_loss: 0.6893 - val_accuracy: 0.5213\n",
            "Epoch 587/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5338 - val_loss: 0.6923 - val_accuracy: 0.5268\n",
            "Epoch 588/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5285 - val_loss: 0.6879 - val_accuracy: 0.5113\n",
            "Epoch 589/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5316 - val_loss: 0.6929 - val_accuracy: 0.5108\n",
            "Epoch 590/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5288 - val_loss: 0.6894 - val_accuracy: 0.5253\n",
            "Epoch 591/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5268 - val_loss: 0.6877 - val_accuracy: 0.5429\n",
            "Epoch 592/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5308 - val_loss: 0.6892 - val_accuracy: 0.5143\n",
            "Epoch 593/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5261 - val_loss: 0.6907 - val_accuracy: 0.5153\n",
            "Epoch 594/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5325 - val_loss: 0.6902 - val_accuracy: 0.5218\n",
            "Epoch 595/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5310 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
            "Epoch 596/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5304 - val_loss: 0.6887 - val_accuracy: 0.5173\n",
            "Epoch 597/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5291 - val_loss: 0.6890 - val_accuracy: 0.5163\n",
            "Epoch 598/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5330 - val_loss: 0.6869 - val_accuracy: 0.5183\n",
            "Epoch 599/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5308 - val_loss: 0.6902 - val_accuracy: 0.5238\n",
            "Epoch 600/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5283 - val_loss: 0.7018 - val_accuracy: 0.5353\n",
            "Epoch 601/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5284 - val_loss: 0.6878 - val_accuracy: 0.5098\n",
            "Epoch 602/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5299 - val_loss: 0.6897 - val_accuracy: 0.5323\n",
            "Epoch 603/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5345 - val_loss: 0.6872 - val_accuracy: 0.5318\n",
            "Epoch 604/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5302 - val_loss: 0.6903 - val_accuracy: 0.5088\n",
            "Epoch 605/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5273 - val_loss: 0.6899 - val_accuracy: 0.5088\n",
            "Epoch 606/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5295 - val_loss: 0.6886 - val_accuracy: 0.5338\n",
            "Epoch 607/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5369 - val_loss: 0.6887 - val_accuracy: 0.5238\n",
            "Epoch 608/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5292 - val_loss: 0.6881 - val_accuracy: 0.5288\n",
            "Epoch 609/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5305 - val_loss: 0.6890 - val_accuracy: 0.5118\n",
            "Epoch 610/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5270 - val_loss: 0.6902 - val_accuracy: 0.5143\n",
            "Epoch 611/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5301 - val_loss: 0.6892 - val_accuracy: 0.5243\n",
            "Epoch 612/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5343 - val_loss: 0.6919 - val_accuracy: 0.5298\n",
            "Epoch 613/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5291 - val_loss: 0.6887 - val_accuracy: 0.5404\n",
            "Epoch 614/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5354 - val_loss: 0.6894 - val_accuracy: 0.5163\n",
            "Epoch 615/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5318 - val_loss: 0.6880 - val_accuracy: 0.5113\n",
            "Epoch 616/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5328 - val_loss: 0.6886 - val_accuracy: 0.5178\n",
            "Epoch 617/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5298 - val_loss: 0.6909 - val_accuracy: 0.5173\n",
            "Epoch 618/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5283 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
            "Epoch 619/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5276 - val_loss: 0.6893 - val_accuracy: 0.5243\n",
            "Epoch 620/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5295 - val_loss: 0.6890 - val_accuracy: 0.5238\n",
            "Epoch 621/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5273 - val_loss: 0.6905 - val_accuracy: 0.5073\n",
            "Epoch 622/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5316 - val_loss: 0.6893 - val_accuracy: 0.5183\n",
            "Epoch 623/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5343 - val_loss: 0.6879 - val_accuracy: 0.5353\n",
            "Epoch 624/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5299 - val_loss: 0.6878 - val_accuracy: 0.5198\n",
            "Epoch 625/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5330 - val_loss: 0.6878 - val_accuracy: 0.5298\n",
            "Epoch 626/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5327 - val_loss: 0.6888 - val_accuracy: 0.5168\n",
            "Epoch 627/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5274 - val_loss: 0.6889 - val_accuracy: 0.5318\n",
            "Epoch 628/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5280 - val_loss: 0.6885 - val_accuracy: 0.5328\n",
            "Epoch 629/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5282 - val_loss: 0.6929 - val_accuracy: 0.5168\n",
            "Epoch 630/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.5304 - val_loss: 0.6873 - val_accuracy: 0.5238\n",
            "Epoch 631/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5338 - val_loss: 0.6901 - val_accuracy: 0.5183\n",
            "Epoch 632/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5289 - val_loss: 0.6888 - val_accuracy: 0.5203\n",
            "Epoch 633/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5358 - val_loss: 0.6948 - val_accuracy: 0.5183\n",
            "Epoch 634/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5330 - val_loss: 0.6881 - val_accuracy: 0.5148\n",
            "Epoch 635/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5314 - val_loss: 0.6888 - val_accuracy: 0.5268\n",
            "Epoch 636/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5334 - val_loss: 0.6888 - val_accuracy: 0.5168\n",
            "Epoch 637/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5290 - val_loss: 0.6903 - val_accuracy: 0.5248\n",
            "Epoch 638/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5282 - val_loss: 0.6904 - val_accuracy: 0.5223\n",
            "Epoch 639/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5312 - val_loss: 0.6881 - val_accuracy: 0.5203\n",
            "Epoch 640/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5346 - val_loss: 0.6900 - val_accuracy: 0.5118\n",
            "Epoch 641/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5336 - val_loss: 0.6905 - val_accuracy: 0.5208\n",
            "Epoch 642/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5313 - val_loss: 0.6937 - val_accuracy: 0.5273\n",
            "Epoch 643/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5288 - val_loss: 0.6886 - val_accuracy: 0.5338\n",
            "Epoch 644/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5272 - val_loss: 0.6894 - val_accuracy: 0.5208\n",
            "Epoch 645/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6915 - val_accuracy: 0.5238\n",
            "Epoch 646/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5315 - val_loss: 0.6879 - val_accuracy: 0.5243\n",
            "Epoch 647/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5297 - val_loss: 0.6892 - val_accuracy: 0.5108\n",
            "Epoch 648/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5310 - val_loss: 0.6905 - val_accuracy: 0.5063\n",
            "Epoch 649/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5318 - val_loss: 0.6892 - val_accuracy: 0.5148\n",
            "Epoch 650/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5328 - val_loss: 0.6895 - val_accuracy: 0.5283\n",
            "Epoch 651/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5326 - val_loss: 0.6908 - val_accuracy: 0.5093\n",
            "Epoch 652/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5303 - val_loss: 0.6870 - val_accuracy: 0.5333\n",
            "Epoch 653/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5298 - val_loss: 0.6911 - val_accuracy: 0.5223\n",
            "Epoch 654/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5335 - val_loss: 0.6922 - val_accuracy: 0.5313\n",
            "Epoch 655/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5337 - val_loss: 0.6898 - val_accuracy: 0.5158\n",
            "Epoch 656/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5296 - val_loss: 0.6893 - val_accuracy: 0.5123\n",
            "Epoch 657/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5319 - val_loss: 0.6897 - val_accuracy: 0.5258\n",
            "Epoch 658/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5331 - val_loss: 0.6901 - val_accuracy: 0.5123\n",
            "Epoch 659/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5273 - val_loss: 0.6912 - val_accuracy: 0.5118\n",
            "Epoch 660/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5322 - val_loss: 0.6892 - val_accuracy: 0.5148\n",
            "Epoch 661/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6912 - val_accuracy: 0.5223\n",
            "Epoch 662/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5282 - val_loss: 0.6932 - val_accuracy: 0.5223\n",
            "Epoch 663/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5299 - val_loss: 0.6914 - val_accuracy: 0.5268\n",
            "Epoch 664/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5298 - val_loss: 0.6890 - val_accuracy: 0.5123\n",
            "Epoch 665/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5324 - val_loss: 0.6968 - val_accuracy: 0.5103\n",
            "Epoch 666/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5296 - val_loss: 0.6919 - val_accuracy: 0.5203\n",
            "Epoch 667/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6900 - val_accuracy: 0.5048\n",
            "Epoch 668/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5284 - val_loss: 0.6868 - val_accuracy: 0.5278\n",
            "Epoch 669/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5274 - val_loss: 0.6877 - val_accuracy: 0.5223\n",
            "Epoch 670/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5269 - val_loss: 0.6886 - val_accuracy: 0.5168\n",
            "Epoch 671/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5303 - val_loss: 0.6883 - val_accuracy: 0.5168\n",
            "Epoch 672/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5330 - val_loss: 0.6883 - val_accuracy: 0.5253\n",
            "Epoch 673/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5303 - val_loss: 0.6868 - val_accuracy: 0.5238\n",
            "Epoch 674/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5312 - val_loss: 0.6938 - val_accuracy: 0.5213\n",
            "Epoch 675/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5340 - val_loss: 0.6885 - val_accuracy: 0.5018\n",
            "Epoch 676/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5303 - val_loss: 0.6878 - val_accuracy: 0.5173\n",
            "Epoch 677/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5301 - val_loss: 0.6894 - val_accuracy: 0.5298\n",
            "Epoch 678/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5304 - val_loss: 0.6893 - val_accuracy: 0.5198\n",
            "Epoch 679/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5275 - val_loss: 0.6903 - val_accuracy: 0.5123\n",
            "Epoch 680/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5313 - val_loss: 0.6913 - val_accuracy: 0.5248\n",
            "Epoch 681/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5337 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
            "Epoch 682/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5340 - val_loss: 0.6884 - val_accuracy: 0.5173\n",
            "Epoch 683/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5299 - val_loss: 0.6884 - val_accuracy: 0.5173\n",
            "Epoch 684/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5307 - val_loss: 0.6910 - val_accuracy: 0.5208\n",
            "Epoch 685/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5283 - val_loss: 0.6907 - val_accuracy: 0.5083\n",
            "Epoch 686/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5299 - val_loss: 0.6967 - val_accuracy: 0.5343\n",
            "Epoch 687/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5287 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
            "Epoch 688/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5315 - val_loss: 0.6907 - val_accuracy: 0.5208\n",
            "Epoch 689/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5291 - val_loss: 0.6931 - val_accuracy: 0.5143\n",
            "Epoch 690/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5322 - val_loss: 0.6901 - val_accuracy: 0.5273\n",
            "Epoch 691/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5306 - val_loss: 0.6945 - val_accuracy: 0.5253\n",
            "Epoch 692/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5277 - val_loss: 0.6915 - val_accuracy: 0.5308\n",
            "Epoch 693/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5282 - val_loss: 0.6887 - val_accuracy: 0.5253\n",
            "Epoch 694/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5289 - val_loss: 0.6880 - val_accuracy: 0.5343\n",
            "Epoch 695/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5312 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
            "Epoch 696/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5333 - val_loss: 0.6900 - val_accuracy: 0.5258\n",
            "Epoch 697/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5306 - val_loss: 0.6891 - val_accuracy: 0.5243\n",
            "Epoch 698/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5306 - val_loss: 0.6923 - val_accuracy: 0.5228\n",
            "Epoch 699/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5318 - val_loss: 0.6876 - val_accuracy: 0.5228\n",
            "Epoch 700/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5322 - val_loss: 0.6964 - val_accuracy: 0.5128\n",
            "Epoch 701/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5337 - val_loss: 0.6902 - val_accuracy: 0.5258\n",
            "Epoch 702/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5331 - val_loss: 0.6899 - val_accuracy: 0.5283\n",
            "Epoch 703/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5306 - val_loss: 0.6901 - val_accuracy: 0.5193\n",
            "Epoch 704/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5292 - val_loss: 0.6889 - val_accuracy: 0.5238\n",
            "Epoch 705/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5330 - val_loss: 0.7008 - val_accuracy: 0.5178\n",
            "Epoch 706/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5291 - val_loss: 0.6877 - val_accuracy: 0.5328\n",
            "Epoch 707/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5340 - val_loss: 0.6881 - val_accuracy: 0.5233\n",
            "Epoch 708/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5331 - val_loss: 0.6935 - val_accuracy: 0.5123\n",
            "Epoch 709/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5321 - val_loss: 0.6920 - val_accuracy: 0.5258\n",
            "Epoch 710/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5291 - val_loss: 0.6882 - val_accuracy: 0.5148\n",
            "Epoch 711/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5285 - val_loss: 0.6899 - val_accuracy: 0.5278\n",
            "Epoch 712/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5283 - val_loss: 0.6917 - val_accuracy: 0.5218\n",
            "Epoch 713/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5343 - val_loss: 0.6882 - val_accuracy: 0.5253\n",
            "Epoch 714/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5325 - val_loss: 0.6896 - val_accuracy: 0.5243\n",
            "Epoch 715/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5345 - val_loss: 0.6916 - val_accuracy: 0.5028\n",
            "Epoch 716/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5336 - val_loss: 0.6925 - val_accuracy: 0.5103\n",
            "Epoch 717/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5272 - val_loss: 0.6910 - val_accuracy: 0.5213\n",
            "Epoch 718/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5310 - val_loss: 0.6890 - val_accuracy: 0.5383\n",
            "Epoch 719/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5302 - val_loss: 0.6900 - val_accuracy: 0.5143\n",
            "Epoch 720/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5281 - val_loss: 0.6903 - val_accuracy: 0.5128\n",
            "Epoch 721/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5317 - val_loss: 0.6889 - val_accuracy: 0.5313\n",
            "Epoch 722/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6859 - accuracy: 0.5308 - val_loss: 0.6897 - val_accuracy: 0.5203\n",
            "Epoch 723/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5297 - val_loss: 0.6876 - val_accuracy: 0.5273\n",
            "Epoch 724/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5341 - val_loss: 0.6947 - val_accuracy: 0.5278\n",
            "Epoch 725/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5335 - val_loss: 0.6900 - val_accuracy: 0.5173\n",
            "Epoch 726/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5330 - val_loss: 0.6899 - val_accuracy: 0.5158\n",
            "Epoch 727/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5332 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
            "Epoch 728/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5291 - val_loss: 0.6894 - val_accuracy: 0.5268\n",
            "Epoch 729/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5371 - val_loss: 0.6884 - val_accuracy: 0.5093\n",
            "Epoch 730/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5328 - val_loss: 0.6886 - val_accuracy: 0.5368\n",
            "Epoch 731/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6891 - val_accuracy: 0.5188\n",
            "Epoch 732/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5300 - val_loss: 0.6943 - val_accuracy: 0.5023\n",
            "Epoch 733/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5312 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
            "Epoch 734/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5333 - val_loss: 0.6894 - val_accuracy: 0.5023\n",
            "Epoch 735/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5343 - val_loss: 0.6876 - val_accuracy: 0.5233\n",
            "Epoch 736/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5350 - val_loss: 0.6883 - val_accuracy: 0.5148\n",
            "Epoch 737/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5335 - val_loss: 0.6898 - val_accuracy: 0.5168\n",
            "Epoch 738/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5313 - val_loss: 0.6879 - val_accuracy: 0.5248\n",
            "Epoch 739/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5337 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
            "Epoch 740/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5301 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
            "Epoch 741/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5348 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
            "Epoch 742/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5357 - val_loss: 0.6900 - val_accuracy: 0.5098\n",
            "Epoch 743/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5307 - val_loss: 0.6882 - val_accuracy: 0.5313\n",
            "Epoch 744/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5289 - val_loss: 0.6868 - val_accuracy: 0.5218\n",
            "Epoch 745/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5278 - val_loss: 0.6885 - val_accuracy: 0.5243\n",
            "Epoch 746/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5299 - val_loss: 0.6898 - val_accuracy: 0.5168\n",
            "Epoch 747/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5336 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
            "Epoch 748/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5322 - val_loss: 0.6895 - val_accuracy: 0.5173\n",
            "Epoch 749/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6863 - accuracy: 0.5295 - val_loss: 0.6882 - val_accuracy: 0.5414\n",
            "Epoch 750/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5308 - val_loss: 0.6897 - val_accuracy: 0.5303\n",
            "Epoch 751/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5280 - val_loss: 0.6909 - val_accuracy: 0.5093\n",
            "Epoch 752/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5290 - val_loss: 0.6905 - val_accuracy: 0.5128\n",
            "Epoch 753/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5318 - val_loss: 0.6899 - val_accuracy: 0.5233\n",
            "Epoch 754/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5298 - val_loss: 0.6924 - val_accuracy: 0.5223\n",
            "Epoch 755/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5305 - val_loss: 0.6873 - val_accuracy: 0.5218\n",
            "Epoch 756/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5318 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
            "Epoch 757/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5310 - val_loss: 0.6896 - val_accuracy: 0.5128\n",
            "Epoch 758/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5326 - val_loss: 0.6915 - val_accuracy: 0.5213\n",
            "Epoch 759/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5320 - val_loss: 0.6940 - val_accuracy: 0.5233\n",
            "Epoch 760/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5318 - val_loss: 0.6903 - val_accuracy: 0.5248\n",
            "Epoch 761/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5259 - val_loss: 0.6886 - val_accuracy: 0.5318\n",
            "Epoch 762/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5300 - val_loss: 0.6884 - val_accuracy: 0.5228\n",
            "Epoch 763/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5311 - val_loss: 0.6873 - val_accuracy: 0.5248\n",
            "Epoch 764/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6861 - accuracy: 0.5303 - val_loss: 0.6898 - val_accuracy: 0.5368\n",
            "Epoch 765/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5321 - val_loss: 0.6899 - val_accuracy: 0.5118\n",
            "Epoch 766/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5321 - val_loss: 0.6884 - val_accuracy: 0.5198\n",
            "Epoch 767/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5313 - val_loss: 0.6896 - val_accuracy: 0.5263\n",
            "Epoch 768/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5312 - val_loss: 0.6908 - val_accuracy: 0.5298\n",
            "Epoch 769/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5343 - val_loss: 0.6892 - val_accuracy: 0.5323\n",
            "Epoch 770/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5291 - val_loss: 0.6899 - val_accuracy: 0.5103\n",
            "Epoch 771/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5308 - val_loss: 0.6940 - val_accuracy: 0.5213\n",
            "Epoch 772/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5296 - val_loss: 0.6923 - val_accuracy: 0.5118\n",
            "Epoch 773/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5308 - val_loss: 0.6926 - val_accuracy: 0.5078\n",
            "Epoch 774/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5299 - val_loss: 0.6898 - val_accuracy: 0.5258\n",
            "Epoch 775/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5304 - val_loss: 0.6994 - val_accuracy: 0.5183\n",
            "Epoch 776/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5270 - val_loss: 0.6916 - val_accuracy: 0.5283\n",
            "Epoch 777/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5303 - val_loss: 0.6897 - val_accuracy: 0.5263\n",
            "Epoch 778/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5304 - val_loss: 0.6976 - val_accuracy: 0.5078\n",
            "Epoch 779/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5341 - val_loss: 0.6880 - val_accuracy: 0.5178\n",
            "Epoch 780/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5319 - val_loss: 0.6996 - val_accuracy: 0.5113\n",
            "Epoch 781/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5339 - val_loss: 0.6924 - val_accuracy: 0.5023\n",
            "Epoch 782/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5289 - val_loss: 0.6907 - val_accuracy: 0.5148\n",
            "Epoch 783/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5333 - val_loss: 0.6908 - val_accuracy: 0.5173\n",
            "Epoch 784/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5325 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
            "Epoch 785/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5304 - val_loss: 0.6897 - val_accuracy: 0.5163\n",
            "Epoch 786/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5354 - val_loss: 0.6892 - val_accuracy: 0.5208\n",
            "Epoch 787/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5345 - val_loss: 0.6878 - val_accuracy: 0.5218\n",
            "Epoch 788/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5309 - val_loss: 0.6946 - val_accuracy: 0.5388\n",
            "Epoch 789/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5290 - val_loss: 0.6918 - val_accuracy: 0.5288\n",
            "Epoch 790/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5289 - val_loss: 0.6894 - val_accuracy: 0.5128\n",
            "Epoch 791/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5287 - val_loss: 0.6916 - val_accuracy: 0.5213\n",
            "Epoch 792/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5311 - val_loss: 0.6891 - val_accuracy: 0.5233\n",
            "Epoch 793/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5342 - val_loss: 0.6912 - val_accuracy: 0.5183\n",
            "Epoch 794/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5313 - val_loss: 0.6905 - val_accuracy: 0.5173\n",
            "Epoch 795/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5297 - val_loss: 0.6886 - val_accuracy: 0.5263\n",
            "Epoch 796/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5273 - val_loss: 0.6912 - val_accuracy: 0.5078\n",
            "Epoch 797/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5312 - val_loss: 0.6890 - val_accuracy: 0.5283\n",
            "Epoch 798/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5317 - val_loss: 0.6892 - val_accuracy: 0.5118\n",
            "Epoch 799/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5323 - val_loss: 0.6894 - val_accuracy: 0.5343\n",
            "Epoch 800/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5290 - val_loss: 0.6868 - val_accuracy: 0.5273\n",
            "Epoch 801/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5319 - val_loss: 0.6903 - val_accuracy: 0.5093\n",
            "Epoch 802/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5330 - val_loss: 0.6894 - val_accuracy: 0.5273\n",
            "Epoch 803/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5336 - val_loss: 0.6897 - val_accuracy: 0.5148\n",
            "Epoch 804/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5303 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
            "Epoch 805/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5328 - val_loss: 0.6885 - val_accuracy: 0.5243\n",
            "Epoch 806/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5342 - val_loss: 0.6920 - val_accuracy: 0.5253\n",
            "Epoch 807/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5342 - val_loss: 0.6891 - val_accuracy: 0.5328\n",
            "Epoch 808/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5291 - val_loss: 0.6897 - val_accuracy: 0.5198\n",
            "Epoch 809/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5308 - val_loss: 0.6883 - val_accuracy: 0.5158\n",
            "Epoch 810/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5248 - val_loss: 0.6888 - val_accuracy: 0.5328\n",
            "Epoch 811/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5328 - val_loss: 0.6907 - val_accuracy: 0.5253\n",
            "Epoch 812/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5366 - val_loss: 0.6922 - val_accuracy: 0.5248\n",
            "Epoch 813/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5286 - val_loss: 0.6912 - val_accuracy: 0.5223\n",
            "Epoch 814/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5291 - val_loss: 0.6889 - val_accuracy: 0.5168\n",
            "Epoch 815/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5304 - val_loss: 0.6896 - val_accuracy: 0.5158\n",
            "Epoch 816/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5315 - val_loss: 0.6909 - val_accuracy: 0.5073\n",
            "Epoch 817/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5306 - val_loss: 0.6895 - val_accuracy: 0.5138\n",
            "Epoch 818/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5297 - val_loss: 0.6903 - val_accuracy: 0.5163\n",
            "Epoch 819/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5319 - val_loss: 0.6892 - val_accuracy: 0.5218\n",
            "Epoch 820/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5276 - val_loss: 0.6913 - val_accuracy: 0.5068\n",
            "Epoch 821/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6856 - accuracy: 0.5301 - val_loss: 0.6875 - val_accuracy: 0.5138\n",
            "Epoch 822/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5306 - val_loss: 0.6904 - val_accuracy: 0.5103\n",
            "Epoch 823/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5327 - val_loss: 0.6932 - val_accuracy: 0.5278\n",
            "Epoch 824/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5304 - val_loss: 0.6900 - val_accuracy: 0.5278\n",
            "Epoch 825/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5289 - val_loss: 0.6930 - val_accuracy: 0.5238\n",
            "Epoch 826/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5291 - val_loss: 0.6906 - val_accuracy: 0.5153\n",
            "Epoch 827/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5288 - val_loss: 0.6915 - val_accuracy: 0.5123\n",
            "Epoch 828/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5341 - val_loss: 0.6909 - val_accuracy: 0.5268\n",
            "Epoch 829/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5284 - val_loss: 0.6887 - val_accuracy: 0.5318\n",
            "Epoch 830/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5301 - val_loss: 0.6956 - val_accuracy: 0.5048\n",
            "Epoch 831/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5237 - val_loss: 0.6898 - val_accuracy: 0.5163\n",
            "Epoch 832/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5308 - val_loss: 0.6931 - val_accuracy: 0.5103\n",
            "Epoch 833/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5318 - val_loss: 0.6945 - val_accuracy: 0.5168\n",
            "Epoch 834/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5302 - val_loss: 0.6892 - val_accuracy: 0.5223\n",
            "Epoch 835/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5333 - val_loss: 0.6871 - val_accuracy: 0.5378\n",
            "Epoch 836/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5303 - val_loss: 0.6911 - val_accuracy: 0.5113\n",
            "Epoch 837/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5312 - val_loss: 0.6949 - val_accuracy: 0.5223\n",
            "Epoch 838/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5292 - val_loss: 0.7003 - val_accuracy: 0.5043\n",
            "Epoch 839/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5333 - val_loss: 0.6913 - val_accuracy: 0.5128\n",
            "Epoch 840/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5297 - val_loss: 0.6900 - val_accuracy: 0.5263\n",
            "Epoch 841/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5308 - val_loss: 0.6894 - val_accuracy: 0.5178\n",
            "Epoch 842/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5308 - val_loss: 0.6940 - val_accuracy: 0.5288\n",
            "Epoch 843/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5289 - val_loss: 0.6909 - val_accuracy: 0.5148\n",
            "Epoch 844/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6845 - accuracy: 0.5316 - val_loss: 0.6916 - val_accuracy: 0.5138\n",
            "Epoch 845/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.5314 - val_loss: 0.6896 - val_accuracy: 0.5173\n",
            "Epoch 846/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.5313 - val_loss: 0.6910 - val_accuracy: 0.5228\n",
            "Epoch 847/1000\n",
            "561/561 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.5315 - val_loss: 0.6934 - val_accuracy: 0.5193\n",
            "Epoch 848/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5306 - val_loss: 0.6913 - val_accuracy: 0.5153\n",
            "Epoch 849/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5359 - val_loss: 0.6948 - val_accuracy: 0.5263\n",
            "Epoch 850/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5316 - val_loss: 0.6924 - val_accuracy: 0.5158\n",
            "Epoch 851/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5319 - val_loss: 0.6891 - val_accuracy: 0.5098\n",
            "Epoch 852/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5300 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
            "Epoch 853/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5322 - val_loss: 0.6889 - val_accuracy: 0.5218\n",
            "Epoch 854/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5276 - val_loss: 0.6894 - val_accuracy: 0.5439\n",
            "Epoch 855/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5340 - val_loss: 0.6991 - val_accuracy: 0.5038\n",
            "Epoch 856/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5318 - val_loss: 0.6930 - val_accuracy: 0.5303\n",
            "Epoch 857/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5332 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
            "Epoch 858/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5304 - val_loss: 0.6891 - val_accuracy: 0.5198\n",
            "Epoch 859/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5324 - val_loss: 0.6901 - val_accuracy: 0.5283\n",
            "Epoch 860/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5290 - val_loss: 0.6927 - val_accuracy: 0.5113\n",
            "Epoch 861/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6851 - accuracy: 0.5239 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
            "Epoch 862/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5298 - val_loss: 0.6891 - val_accuracy: 0.5163\n",
            "Epoch 863/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5327 - val_loss: 0.6881 - val_accuracy: 0.5238\n",
            "Epoch 864/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5343 - val_loss: 0.6885 - val_accuracy: 0.5178\n",
            "Epoch 865/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5291 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
            "Epoch 866/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5298 - val_loss: 0.6904 - val_accuracy: 0.5263\n",
            "Epoch 867/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5317 - val_loss: 0.6872 - val_accuracy: 0.5378\n",
            "Epoch 868/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5325 - val_loss: 0.6922 - val_accuracy: 0.5078\n",
            "Epoch 869/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5327 - val_loss: 0.6934 - val_accuracy: 0.5223\n",
            "Epoch 870/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5333 - val_loss: 0.6911 - val_accuracy: 0.5213\n",
            "Epoch 871/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5282 - val_loss: 0.6915 - val_accuracy: 0.5148\n",
            "Epoch 872/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5315 - val_loss: 0.6922 - val_accuracy: 0.5048\n",
            "Epoch 873/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5308 - val_loss: 0.6979 - val_accuracy: 0.5138\n",
            "Epoch 874/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5301 - val_loss: 0.6953 - val_accuracy: 0.5138\n",
            "Epoch 875/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5269 - val_loss: 0.6925 - val_accuracy: 0.5113\n",
            "Epoch 876/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5285 - val_loss: 0.6897 - val_accuracy: 0.5253\n",
            "Epoch 877/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5296 - val_loss: 0.6892 - val_accuracy: 0.5243\n",
            "Epoch 878/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5330 - val_loss: 0.6946 - val_accuracy: 0.5003\n",
            "Epoch 879/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5316 - val_loss: 0.6886 - val_accuracy: 0.5388\n",
            "Epoch 880/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5274 - val_loss: 0.6904 - val_accuracy: 0.5213\n",
            "Epoch 881/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5305 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
            "Epoch 882/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5335 - val_loss: 0.6910 - val_accuracy: 0.5298\n",
            "Epoch 883/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5339 - val_loss: 0.6894 - val_accuracy: 0.5223\n",
            "Epoch 884/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5327 - val_loss: 0.7004 - val_accuracy: 0.5118\n",
            "Epoch 885/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5342 - val_loss: 0.6915 - val_accuracy: 0.5158\n",
            "Epoch 886/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5343 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
            "Epoch 887/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5325 - val_loss: 0.6885 - val_accuracy: 0.5253\n",
            "Epoch 888/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5335 - val_loss: 0.6892 - val_accuracy: 0.5193\n",
            "Epoch 889/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5308 - val_loss: 0.6916 - val_accuracy: 0.5128\n",
            "Epoch 890/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5289 - val_loss: 0.6938 - val_accuracy: 0.5188\n",
            "Epoch 891/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5300 - val_loss: 0.6882 - val_accuracy: 0.5233\n",
            "Epoch 892/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5325 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
            "Epoch 893/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5346 - val_loss: 0.6966 - val_accuracy: 0.5353\n",
            "Epoch 894/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6858 - accuracy: 0.5307 - val_loss: 0.6906 - val_accuracy: 0.5138\n",
            "Epoch 895/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5320 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
            "Epoch 896/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5287 - val_loss: 0.6911 - val_accuracy: 0.5288\n",
            "Epoch 897/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5297 - val_loss: 0.6910 - val_accuracy: 0.5278\n",
            "Epoch 898/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5297 - val_loss: 0.6907 - val_accuracy: 0.5153\n",
            "Epoch 899/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5338 - val_loss: 0.6903 - val_accuracy: 0.5303\n",
            "Epoch 900/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5304 - val_loss: 0.6881 - val_accuracy: 0.5313\n",
            "Epoch 901/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5304 - val_loss: 0.6898 - val_accuracy: 0.5073\n",
            "Epoch 902/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5311 - val_loss: 0.6901 - val_accuracy: 0.5203\n",
            "Epoch 903/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5315 - val_loss: 0.6926 - val_accuracy: 0.5308\n",
            "Epoch 904/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5284 - val_loss: 0.6910 - val_accuracy: 0.5178\n",
            "Epoch 905/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5293 - val_loss: 0.6878 - val_accuracy: 0.5278\n",
            "Epoch 906/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5306 - val_loss: 0.6913 - val_accuracy: 0.5228\n",
            "Epoch 907/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5300 - val_loss: 0.6941 - val_accuracy: 0.5078\n",
            "Epoch 908/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5307 - val_loss: 0.6914 - val_accuracy: 0.5153\n",
            "Epoch 909/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5303 - val_loss: 0.6936 - val_accuracy: 0.5158\n",
            "Epoch 910/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5276 - val_loss: 0.6915 - val_accuracy: 0.5193\n",
            "Epoch 911/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5297 - val_loss: 0.6903 - val_accuracy: 0.5213\n",
            "Epoch 912/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5318 - val_loss: 0.6903 - val_accuracy: 0.5218\n",
            "Epoch 913/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5337 - val_loss: 0.6933 - val_accuracy: 0.5218\n",
            "Epoch 914/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5341 - val_loss: 0.6887 - val_accuracy: 0.5303\n",
            "Epoch 915/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5301 - val_loss: 0.6888 - val_accuracy: 0.5238\n",
            "Epoch 916/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5320 - val_loss: 0.6910 - val_accuracy: 0.5088\n",
            "Epoch 917/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6855 - accuracy: 0.5307 - val_loss: 0.6875 - val_accuracy: 0.5338\n",
            "Epoch 918/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5293 - val_loss: 0.6942 - val_accuracy: 0.5228\n",
            "Epoch 919/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5304 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
            "Epoch 920/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5280 - val_loss: 0.6910 - val_accuracy: 0.5148\n",
            "Epoch 921/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5319 - val_loss: 0.6923 - val_accuracy: 0.5253\n",
            "Epoch 922/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5292 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
            "Epoch 923/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5335 - val_loss: 0.6909 - val_accuracy: 0.5233\n",
            "Epoch 924/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5307 - val_loss: 0.6908 - val_accuracy: 0.5143\n",
            "Epoch 925/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5343 - val_loss: 0.6912 - val_accuracy: 0.5118\n",
            "Epoch 926/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5342 - val_loss: 0.6927 - val_accuracy: 0.5203\n",
            "Epoch 927/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5338 - val_loss: 0.6957 - val_accuracy: 0.5303\n",
            "Epoch 928/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5292 - val_loss: 0.6935 - val_accuracy: 0.5303\n",
            "Epoch 929/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5320 - val_loss: 0.6929 - val_accuracy: 0.5058\n",
            "Epoch 930/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5352 - val_loss: 0.6911 - val_accuracy: 0.5288\n",
            "Epoch 931/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5322 - val_loss: 0.6893 - val_accuracy: 0.5198\n",
            "Epoch 932/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5269 - val_loss: 0.6942 - val_accuracy: 0.5093\n",
            "Epoch 933/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6860 - accuracy: 0.5291 - val_loss: 0.6906 - val_accuracy: 0.5238\n",
            "Epoch 934/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5326 - val_loss: 0.6938 - val_accuracy: 0.5013\n",
            "Epoch 935/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5335 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
            "Epoch 936/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5316 - val_loss: 0.6897 - val_accuracy: 0.5183\n",
            "Epoch 937/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5313 - val_loss: 0.6902 - val_accuracy: 0.5093\n",
            "Epoch 938/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5354 - val_loss: 0.6886 - val_accuracy: 0.5258\n",
            "Epoch 939/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5330 - val_loss: 0.6947 - val_accuracy: 0.5128\n",
            "Epoch 940/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5297 - val_loss: 0.6925 - val_accuracy: 0.5088\n",
            "Epoch 941/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6854 - accuracy: 0.5303 - val_loss: 0.6922 - val_accuracy: 0.5218\n",
            "Epoch 942/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5311 - val_loss: 0.7011 - val_accuracy: 0.5088\n",
            "Epoch 943/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5311 - val_loss: 0.6933 - val_accuracy: 0.5093\n",
            "Epoch 944/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5312 - val_loss: 0.6892 - val_accuracy: 0.5138\n",
            "Epoch 945/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5290 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
            "Epoch 946/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6848 - accuracy: 0.5342 - val_loss: 0.6886 - val_accuracy: 0.5178\n",
            "Epoch 947/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6852 - accuracy: 0.5327 - val_loss: 0.6927 - val_accuracy: 0.5083\n",
            "Epoch 948/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5286 - val_loss: 0.6938 - val_accuracy: 0.5053\n",
            "Epoch 949/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5333 - val_loss: 0.6919 - val_accuracy: 0.5243\n",
            "Epoch 950/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5291 - val_loss: 0.6937 - val_accuracy: 0.5083\n",
            "Epoch 951/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5296 - val_loss: 0.6935 - val_accuracy: 0.5293\n",
            "Epoch 952/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5305 - val_loss: 0.6881 - val_accuracy: 0.5248\n",
            "Epoch 953/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5296 - val_loss: 0.6934 - val_accuracy: 0.5273\n",
            "Epoch 954/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5278 - val_loss: 0.6986 - val_accuracy: 0.5268\n",
            "Epoch 955/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5324 - val_loss: 0.6898 - val_accuracy: 0.5323\n",
            "Epoch 956/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5332 - val_loss: 0.6975 - val_accuracy: 0.5143\n",
            "Epoch 957/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5330 - val_loss: 0.6928 - val_accuracy: 0.5243\n",
            "Epoch 958/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5346 - val_loss: 0.6898 - val_accuracy: 0.5173\n",
            "Epoch 959/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6850 - accuracy: 0.5343 - val_loss: 0.6893 - val_accuracy: 0.5298\n",
            "Epoch 960/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6849 - accuracy: 0.5350 - val_loss: 0.6880 - val_accuracy: 0.5203\n",
            "Epoch 961/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5274 - val_loss: 0.6917 - val_accuracy: 0.5223\n",
            "Epoch 962/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5297 - val_loss: 0.6909 - val_accuracy: 0.5173\n",
            "Epoch 963/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5291 - val_loss: 0.6910 - val_accuracy: 0.5223\n",
            "Epoch 964/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5304 - val_loss: 0.6880 - val_accuracy: 0.5148\n",
            "Epoch 965/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5329 - val_loss: 0.6906 - val_accuracy: 0.5158\n",
            "Epoch 966/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5345 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
            "Epoch 967/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5308 - val_loss: 0.6935 - val_accuracy: 0.5228\n",
            "Epoch 968/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5328 - val_loss: 0.6887 - val_accuracy: 0.5318\n",
            "Epoch 969/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5375 - val_loss: 0.6911 - val_accuracy: 0.5118\n",
            "Epoch 970/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5312 - val_loss: 0.6901 - val_accuracy: 0.5323\n",
            "Epoch 971/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5360 - val_loss: 0.6892 - val_accuracy: 0.5003\n",
            "Epoch 972/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5291 - val_loss: 0.6942 - val_accuracy: 0.4997\n",
            "Epoch 973/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6862 - accuracy: 0.5277 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
            "Epoch 974/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5320 - val_loss: 0.6907 - val_accuracy: 0.5148\n",
            "Epoch 975/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5310 - val_loss: 0.6912 - val_accuracy: 0.5098\n",
            "Epoch 976/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5335 - val_loss: 0.6900 - val_accuracy: 0.5258\n",
            "Epoch 977/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5345 - val_loss: 0.6912 - val_accuracy: 0.5208\n",
            "Epoch 978/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6869 - accuracy: 0.5291 - val_loss: 0.6916 - val_accuracy: 0.5198\n",
            "Epoch 979/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5351 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
            "Epoch 980/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5307 - val_loss: 0.6899 - val_accuracy: 0.5258\n",
            "Epoch 981/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6837 - accuracy: 0.5316 - val_loss: 0.6879 - val_accuracy: 0.5298\n",
            "Epoch 982/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5331 - val_loss: 0.6885 - val_accuracy: 0.5193\n",
            "Epoch 983/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5302 - val_loss: 0.6904 - val_accuracy: 0.5273\n",
            "Epoch 984/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5350 - val_loss: 0.6901 - val_accuracy: 0.5173\n",
            "Epoch 985/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5301 - val_loss: 0.6901 - val_accuracy: 0.5183\n",
            "Epoch 986/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6857 - accuracy: 0.5296 - val_loss: 0.6914 - val_accuracy: 0.5173\n",
            "Epoch 987/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6847 - accuracy: 0.5335 - val_loss: 0.6917 - val_accuracy: 0.5303\n",
            "Epoch 988/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5318 - val_loss: 0.6964 - val_accuracy: 0.5183\n",
            "Epoch 989/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5287 - val_loss: 0.6899 - val_accuracy: 0.5268\n",
            "Epoch 990/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5309 - val_loss: 0.6901 - val_accuracy: 0.5233\n",
            "Epoch 991/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.5327 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
            "Epoch 992/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5304 - val_loss: 0.6899 - val_accuracy: 0.5353\n",
            "Epoch 993/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6841 - accuracy: 0.5340 - val_loss: 0.6932 - val_accuracy: 0.5208\n",
            "Epoch 994/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6846 - accuracy: 0.5301 - val_loss: 0.6902 - val_accuracy: 0.5103\n",
            "Epoch 995/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6843 - accuracy: 0.5329 - val_loss: 0.6932 - val_accuracy: 0.5103\n",
            "Epoch 996/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5324 - val_loss: 0.6913 - val_accuracy: 0.5278\n",
            "Epoch 997/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5303 - val_loss: 0.7007 - val_accuracy: 0.5188\n",
            "Epoch 998/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6842 - accuracy: 0.5361 - val_loss: 0.6914 - val_accuracy: 0.5223\n",
            "Epoch 999/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6839 - accuracy: 0.5330 - val_loss: 0.6910 - val_accuracy: 0.5093\n",
            "Epoch 1000/1000\n",
            "561/561 [==============================] - 1s 1ms/step - loss: 0.6840 - accuracy: 0.5303 - val_loss: 0.7034 - val_accuracy: 0.5283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2430d893d0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Nationwide_AAnalytics/Over_SMOTE.h5')"
      ],
      "metadata": {
        "id": "c1bjV0zu9YsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Accuracy = \", (acc * 100.0), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z78Sod-V9YnZ",
        "outputId": "9c5df756-d55b-48be-9992-c1cb1936a56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 0s 816us/step - loss: 0.6866 - accuracy: 0.5253\n",
            "Accuracy =  52.52707600593567 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4D8NhCyoWsR",
        "outputId": "254799cf-59fd-4889-92e4-e9917cf93db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.39580445e-21, 3.21709847e-15, 3.44984308e-08, 3.00522402e-06,\n",
              "       1.27748999e-05, 8.78252686e-05, 1.28805637e-04, 2.18698382e-03,\n",
              "       2.32675672e-03, 6.05234504e-03, 1.09890103e-02, 1.20739937e-02,\n",
              "       1.20740235e-02, 1.35968626e-02, 2.62373686e-02, 6.25653863e-02,\n",
              "       7.35212266e-02, 9.36597586e-02, 1.00864589e-01, 1.15992993e-01,\n",
              "       1.34149969e-01, 1.42153889e-01, 1.84721231e-01, 2.02027231e-01,\n",
              "       2.05835313e-01, 2.74047017e-01, 2.78883636e-01, 2.79428393e-01,\n",
              "       3.27060223e-01, 3.27399433e-01, 3.51361483e-01, 3.52316678e-01,\n",
              "       3.52616221e-01, 3.64263833e-01, 3.74495536e-01, 3.78539503e-01,\n",
              "       3.80928218e-01, 3.82527143e-01, 4.03791934e-01, 4.08526421e-01,\n",
              "       4.10817653e-01, 4.13999915e-01, 4.15439397e-01, 4.17286843e-01,\n",
              "       4.23647881e-01, 4.31955278e-01, 4.33300793e-01, 4.34082448e-01,\n",
              "       4.39060628e-01, 4.42523301e-01, 4.50047255e-01, 4.50969547e-01,\n",
              "       4.52334583e-01, 4.56009537e-01, 4.56636220e-01, 4.58482742e-01,\n",
              "       4.60078120e-01, 4.63586986e-01, 4.66448903e-01, 4.66905087e-01,\n",
              "       4.71008688e-01, 4.74594742e-01, 4.75092709e-01, 4.76983935e-01,\n",
              "       4.78716552e-01, 4.79454219e-01, 4.79844242e-01, 4.81889993e-01,\n",
              "       4.82045770e-01, 4.82045799e-01, 4.82758164e-01, 4.83501345e-01,\n",
              "       4.83783454e-01, 4.84537810e-01, 4.86429453e-01, 4.87231344e-01,\n",
              "       4.88809258e-01, 4.88809317e-01, 4.89170313e-01, 4.89175320e-01,\n",
              "       4.89265382e-01, 4.92980659e-01, 4.93399590e-01, 4.94557470e-01,\n",
              "       4.95492190e-01, 4.96534407e-01, 4.96534437e-01, 4.96937245e-01,\n",
              "       4.97072339e-01, 4.97965902e-01, 4.97992575e-01, 4.98037487e-01,\n",
              "       4.98037547e-01, 4.98654008e-01, 5.00011981e-01, 5.01176476e-01,\n",
              "       5.01176536e-01, 5.01208007e-01, 5.02195179e-01, 5.02318263e-01,\n",
              "       5.02352476e-01, 5.02425373e-01, 5.02550840e-01, 5.03283501e-01,\n",
              "       5.03283620e-01, 5.03520489e-01, 5.03544033e-01, 5.05127430e-01,\n",
              "       5.05369902e-01, 5.05410016e-01, 5.05994976e-01, 5.06081164e-01,\n",
              "       5.06419718e-01, 5.06940603e-01, 5.07536173e-01, 5.07568300e-01,\n",
              "       5.07957041e-01, 5.08080661e-01, 5.08981645e-01, 5.08998930e-01,\n",
              "       5.09306550e-01, 5.11026323e-01, 5.11026859e-01, 5.12315392e-01,\n",
              "       5.13346314e-01, 5.13348460e-01, 5.13419449e-01, 5.14025688e-01,\n",
              "       5.15102625e-01, 5.15119910e-01, 5.15145183e-01, 5.15203118e-01,\n",
              "       5.15239418e-01, 5.15330195e-01, 5.15426040e-01, 5.15426099e-01,\n",
              "       5.16227484e-01, 5.16227603e-01, 5.16382277e-01, 5.17240524e-01,\n",
              "       5.17324388e-01, 5.17324448e-01, 5.17424166e-01, 5.17431676e-01,\n",
              "       5.17903328e-01, 5.17903388e-01, 5.18690288e-01, 5.19132972e-01,\n",
              "       5.19674003e-01, 5.20023465e-01, 5.20101547e-01, 5.21289170e-01,\n",
              "       5.21320343e-01, 5.21333814e-01, 5.21717072e-01, 5.21979153e-01,\n",
              "       5.22042453e-01, 5.22042513e-01, 5.23297906e-01, 5.23578763e-01,\n",
              "       5.23934305e-01, 5.24863124e-01, 5.24863243e-01, 5.25350869e-01,\n",
              "       5.25550783e-01, 5.26955545e-01, 5.26958048e-01, 5.27386904e-01,\n",
              "       5.27570486e-01, 5.27570546e-01, 5.27682364e-01, 5.28156519e-01,\n",
              "       5.28156638e-01, 5.28182268e-01, 5.29039681e-01, 5.30118585e-01,\n",
              "       5.30386269e-01, 5.30386329e-01, 5.30446947e-01, 5.30841351e-01,\n",
              "       5.31345487e-01, 5.31345546e-01, 5.32059610e-01, 5.33309698e-01,\n",
              "       5.33425331e-01, 5.33906043e-01, 5.33926964e-01, 5.34504652e-01,\n",
              "       5.34572423e-01, 5.34629524e-01, 5.34872770e-01, 5.35509586e-01,\n",
              "       5.35780489e-01, 5.36336899e-01, 5.37135005e-01, 5.37326574e-01,\n",
              "       5.37375391e-01, 5.37440836e-01, 5.37558496e-01, 5.37571728e-01,\n",
              "       5.38731158e-01, 5.40856600e-01, 5.42343497e-01, 5.42620361e-01,\n",
              "       5.43141425e-01, 5.43175936e-01, 5.43865800e-01, 5.44120371e-01,\n",
              "       5.44120431e-01, 5.44708729e-01, 5.45210779e-01, 5.45210838e-01,\n",
              "       5.45479000e-01, 5.45766532e-01, 5.45937300e-01, 5.46474159e-01,\n",
              "       5.47941029e-01, 5.47992885e-01, 5.48082948e-01, 5.48345149e-01,\n",
              "       5.48651755e-01, 5.48799753e-01, 5.49886227e-01, 5.50086677e-01,\n",
              "       5.50188959e-01, 5.50239503e-01, 5.50239921e-01, 5.50973773e-01,\n",
              "       5.51207304e-01, 5.51549137e-01, 5.53262830e-01, 5.53262889e-01,\n",
              "       5.53877234e-01, 5.56048036e-01, 5.56456625e-01, 5.56504548e-01,\n",
              "       5.58110595e-01, 5.58287382e-01, 5.58390260e-01, 5.58606505e-01,\n",
              "       5.59006274e-01, 5.59219837e-01, 5.59219897e-01, 5.59315264e-01,\n",
              "       5.59778035e-01, 5.60208201e-01, 5.60712457e-01, 5.60767353e-01,\n",
              "       5.61287045e-01, 5.62925398e-01, 5.63375652e-01, 5.63932478e-01,\n",
              "       5.63932538e-01, 5.63947678e-01, 5.64274907e-01, 5.64442635e-01,\n",
              "       5.64595997e-01, 5.65491319e-01, 5.66103518e-01, 5.66646695e-01,\n",
              "       5.67750633e-01, 5.70693433e-01, 5.71337104e-01, 5.71925640e-01,\n",
              "       5.72711349e-01, 5.73260128e-01, 5.73451102e-01, 5.74003279e-01,\n",
              "       5.75854003e-01, 5.77327013e-01, 5.77382684e-01, 5.77754676e-01,\n",
              "       5.77908456e-01, 5.77944875e-01, 5.78106225e-01, 5.78481138e-01,\n",
              "       5.79771817e-01, 5.80148816e-01, 5.80565929e-01, 5.80634356e-01,\n",
              "       5.80786526e-01, 5.81732869e-01, 5.81913710e-01, 5.82760096e-01,\n",
              "       5.83362758e-01, 5.84985375e-01, 5.85617423e-01, 5.85672140e-01,\n",
              "       5.86018026e-01, 5.86305559e-01, 5.86305618e-01, 5.87195575e-01,\n",
              "       5.87999344e-01, 5.88549078e-01, 5.88549137e-01, 5.89380383e-01,\n",
              "       5.89948237e-01, 5.90060413e-01, 5.90384543e-01, 5.91056645e-01,\n",
              "       5.92116475e-01, 5.93015790e-01, 5.93085587e-01, 5.94013453e-01,\n",
              "       5.94171643e-01, 5.94171703e-01, 5.95405459e-01, 5.96418738e-01,\n",
              "       5.96462250e-01, 5.96462369e-01, 5.96795261e-01, 5.97026944e-01,\n",
              "       5.97292721e-01, 5.98990858e-01, 5.99083602e-01, 6.00107253e-01,\n",
              "       6.01156116e-01, 6.01630986e-01, 6.01670086e-01, 6.01670146e-01,\n",
              "       6.01800442e-01, 6.01989686e-01, 6.02182508e-01, 6.02755249e-01,\n",
              "       6.03717446e-01, 6.03717506e-01, 6.03796840e-01, 6.04107559e-01,\n",
              "       6.04985356e-01, 6.05031013e-01, 6.06361628e-01, 6.06875062e-01,\n",
              "       6.07268393e-01, 6.07516527e-01, 6.07608438e-01, 6.08103693e-01,\n",
              "       6.09755993e-01, 6.10196650e-01, 6.10206127e-01, 6.10398531e-01,\n",
              "       6.11007929e-01, 6.12410903e-01, 6.13160908e-01, 6.15278244e-01,\n",
              "       6.15772605e-01, 6.18189812e-01, 6.20491743e-01, 6.20891452e-01,\n",
              "       6.21679306e-01, 6.27361536e-01, 6.27682209e-01, 6.28120124e-01,\n",
              "       6.28581882e-01, 6.28926635e-01, 6.30740106e-01, 6.31022811e-01,\n",
              "       6.31967843e-01, 6.33596122e-01, 6.34870589e-01, 6.35685146e-01,\n",
              "       6.35789633e-01, 6.38197064e-01, 6.38216317e-01, 6.38264239e-01,\n",
              "       6.40717208e-01, 6.40861034e-01, 6.44350111e-01, 6.47111118e-01,\n",
              "       6.47111177e-01, 6.50671422e-01, 6.56673789e-01, 6.57499969e-01,\n",
              "       6.67518497e-01, 6.68068767e-01, 6.68599248e-01, 6.69074595e-01,\n",
              "       6.72620595e-01, 6.79894865e-01, 6.80466652e-01, 6.99691057e-01,\n",
              "       7.03288436e-01, 7.09791839e-01, 7.65439987e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "np.unique(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvnDaT5coWo9",
        "outputId": "b6df245d-dfd2-41ca-a78c-1908eba98720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tFCvG64ooYo4",
        "outputId": "813238ae-a753-4a3f-ecf7-cfdeabad4f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rzv7PezwobNh",
        "outputId": "7d2499de-b2ab-4e3b-9918-d065386c9196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.55      0.28      0.37      1106\\n           1       0.52      0.77      0.62      1110\\n\\n    accuracy                           0.53      2216\\n   macro avg       0.53      0.52      0.49      2216\\nweighted avg       0.53      0.53      0.50      2216\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test with unbalanced data\n",
        "y_pred = model.predict(X_ts)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "cm = confusion_matrix(Y_ts, y_pred)\n",
        "f = sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "VFZoZP7cpbTw",
        "outputId": "77cd062c-3c6e-449d-bcb0-c60a3a1d24a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test with Test SET**"
      ],
      "metadata": {
        "id": "CIbuK1WDm_Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCvqYdTqmpvl",
        "outputId": "f071f2df-3083-4ec9-c981-1b31e4b5ca63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7505 entries, 0 to 7504\n",
            "Data columns (total 27 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   RESTAURANT_SERIAL_NUMBER  7505 non-null   object \n",
            " 1   RESTAURANT_PERMIT_NUMBER  7505 non-null   object \n",
            " 2   RESTAURANT_NAME           7505 non-null   object \n",
            " 3   RESTAURANT_LOCATION       7504 non-null   object \n",
            " 4   RESTAURANT_CATEGORY       7505 non-null   object \n",
            " 5   ADDRESS                   7503 non-null   object \n",
            " 6   CITY                      7502 non-null   object \n",
            " 7   STATE                     7505 non-null   object \n",
            " 8   ZIP                       7503 non-null   object \n",
            " 9   CURRENT_DEMERITS          7505 non-null   int64  \n",
            " 10  CURRENT_GRADE             7503 non-null   object \n",
            " 11  INSPECTION_TIME           7502 non-null   object \n",
            " 12  INSPECTION_TYPE           7505 non-null   object \n",
            " 13  INSPECTION_DEMERITS       7505 non-null   int64  \n",
            " 14  VIOLATIONS_RAW            7505 non-null   object \n",
            " 15  RECORD_UPDATED            7505 non-null   object \n",
            " 16  LAT_LONG_RAW              7505 non-null   object \n",
            " 17  FIRST_VIOLATION           7505 non-null   float64\n",
            " 18  SECOND_VIOLATION          7505 non-null   int64  \n",
            " 19  THIRD_VIOLATION           7505 non-null   int64  \n",
            " 20  FIRST_VIOLATION_TYPE      7505 non-null   object \n",
            " 21  SECOND_VIOLATION_TYPE     7505 non-null   object \n",
            " 22  THIRD_VIOLATION_TYPE      7505 non-null   object \n",
            " 23  NUMBER_OF_VIOLATIONS      7505 non-null   int64  \n",
            " 24  EMPLOYEE_COUNT            7505 non-null   float64\n",
            " 25  MEDIAN_EMPLOYEE_AGE       7505 non-null   float64\n",
            " 26  MEDIAN_EMPLOYEE_TENURE    7505 non-null   float64\n",
            "dtypes: float64(4), int64(5), object(18)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_2['CURRENT_GRADE'].value_counts())\n",
        "df_2 = df_2.drop(df_2[df_2['CURRENT_GRADE'] == 'VVVVVV' ].index)\n",
        "df_2 = df_2.drop(df_2[df_2['CURRENT_GRADE'] == 'Elephant' ].index)\n",
        "df_2['CURRENT_GRADE']= df_2['CURRENT_GRADE'].apply(lambda x :5 if x == \"A\" else 4 if x == 'B' else 3 if x == \"C\" else 2 if x == \"X\" else 1 if x == \"O\" else 0 if x == \"N\" else np.nan )\n",
        "print(df_2['CURRENT_GRADE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSjpeqwEnyvL",
        "outputId": "413399b7-3d4a-4ac3-918a-5b1b80bf82f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    6142\n",
            "B     107\n",
            "C      49\n",
            "X      25\n",
            "O      19\n",
            "N       7\n",
            "Name: CURRENT_GRADE, dtype: int64\n",
            "5    6142\n",
            "4     107\n",
            "3      49\n",
            "2      25\n",
            "1      19\n",
            "0       7\n",
            "Name: CURRENT_GRADE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_2['THIRD_VIOLATION_TYPE'].value_counts())\n",
        "df_2 = df_2.drop(df_2[df_2['THIRD_VIOLATION_TYPE'] == 'Ilogical' ].index)\n",
        "df_2['THIRD_VIOLATION_TYPE']= df_2['THIRD_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\" else np.nan )\n",
        "print(df_2['THIRD_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRkD_oSan99b",
        "outputId": "d1e76c75-c4fc-46e8-c8d7-3515a0ee6a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-Major                 3013\n",
            "Major                     2943\n",
            "Critical                   372\n",
            "Imminent Health Hazard      22\n",
            "Name: THIRD_VIOLATION_TYPE, dtype: int64\n",
            "2    3013\n",
            "3    2943\n",
            "4     372\n",
            "5      22\n",
            "Name: THIRD_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_2['SECOND_VIOLATION_TYPE'].value_counts())\n",
        "df_2 = df_2.drop(df_2[df_2['SECOND_VIOLATION_TYPE'] == 'Confusing' ].index)\n",
        "df_2['SECOND_VIOLATION_TYPE']= df_2['SECOND_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\" else np.nan )\n",
        "print(df_2['SECOND_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZpTh9HoCDn",
        "outputId": "194626ad-33ee-4a1a-bcf1-d00b31c8863a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major                     3285\n",
            "Non-Major                 1873\n",
            "Critical                  1191\n",
            "Imminent Health Hazard       1\n",
            "Name: SECOND_VIOLATION_TYPE, dtype: int64\n",
            "3    3285\n",
            "2    1873\n",
            "4    1191\n",
            "5       1\n",
            "Name: SECOND_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_2['FIRST_VIOLATION_TYPE'].value_counts())\n",
        "df_2 = df_2.drop(df_2[df_2['FIRST_VIOLATION_TYPE'] == '1' ].index)\n",
        "df_2 = df_2.drop(df_2[df_2['FIRST_VIOLATION_TYPE'] == 'Fuzzy' ].index)\n",
        "df_2['FIRST_VIOLATION_TYPE']= df_2['FIRST_VIOLATION_TYPE'].apply(lambda x :5 if x == \"Imminent Health Hazard\" else 4 if x == 'Critical' else 3 if x == \"Major\" else 2 if x == \"Non-Major\" else np.nan )\n",
        "print(df_2['FIRST_VIOLATION_TYPE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhoWSNApoCu9",
        "outputId": "30ed7efe-0fad-4c53-d9bc-b0a9b8e38fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critical     2955\n",
            "Major        2725\n",
            "1            1154\n",
            "Non-Major     670\n",
            "Fuzzy           1\n",
            "Name: FIRST_VIOLATION_TYPE, dtype: int64\n",
            "4    2955\n",
            "3    2725\n",
            "2     670\n",
            "Name: FIRST_VIOLATION_TYPE, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_t = df_2.loc[:,['NUMBER_OF_VIOLATIONS','CURRENT_GRADE',\t'INSPECTION_DEMERITS',\t'THIRD_VIOLATION_TYPE',\t'SECOND_VIOLATION_TYPE',\t'FIRST_VIOLATION_TYPE']]\n",
        "print(f_t.isnull().sum())\n",
        "f_t = f_t.dropna()\n",
        "print(f_t.isnull().sum())\n",
        "f_t = f_t.apply(pd.to_numeric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FSgjLD3nPtC",
        "outputId": "94fe16fd-7080-4f0b-a596-146fd10db7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMBER_OF_VIOLATIONS     0\n",
            "CURRENT_GRADE            0\n",
            "INSPECTION_DEMERITS      0\n",
            "THIRD_VIOLATION_TYPE     0\n",
            "SECOND_VIOLATION_TYPE    0\n",
            "FIRST_VIOLATION_TYPE     0\n",
            "dtype: int64\n",
            "NUMBER_OF_VIOLATIONS     0\n",
            "CURRENT_GRADE            0\n",
            "INSPECTION_DEMERITS      0\n",
            "THIRD_VIOLATION_TYPE     0\n",
            "SECOND_VIOLATION_TYPE    0\n",
            "FIRST_VIOLATION_TYPE     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load all the models\n",
        "o_S = load_model('/content/drive/MyDrive/Nationwide_AAnalytics/Over_SMOTE.h5')\n",
        "o_R = load_model('/content/drive/MyDrive/Nationwide_AAnalytics/Over_Randon.h5')\n",
        "u_R = load_model('/content/drive/MyDrive/Nationwide_AAnalytics/Under.h5')"
      ],
      "metadata": {
        "id": "Ck-cyZ7tqPi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with load set\n",
        "p_os = o_S.predict(f_t)\n",
        "p_os = np.where(p_os > 0.5, 1, 0)\n",
        "unique, counts = np.unique(p_os, return_counts=True)\n",
        "print( np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeMGYyj-pg-j",
        "outputId": "3c4a54af-8c2f-49d3-97a7-cd42a7419f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    1]\n",
            " [1883 4466]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with load set\n",
        "p_or = o_R.predict(f_t)\n",
        "p_or = np.where(p_or > 0.5, 1, 0)\n",
        "unique, counts = np.unique(p_or, return_counts=True)\n",
        "print( np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-iaFI_krDUn",
        "outputId": "6c5e3f16-981e-484a-96a8-c4ad44a235df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0 3611]\n",
            " [   1 2738]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with load set\n",
        "p_u = u_R.predict(f_t)\n",
        "p_u = np.where(p_u > 0.5, 1, 0)\n",
        "unique, counts = np.unique(p_u, return_counts=True)\n",
        "print( np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYC3E7lftBVX",
        "outputId": "d7bd0a0f-e567-460e-b5f8-2db10a5af8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0 2168]\n",
            " [   1 4181]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "48mHT5ahtOXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}